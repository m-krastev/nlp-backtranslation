{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Backtranslation Notebook to Rule Over Them All\n",
    "Please do ignore the title, I just wanted to make it sound cool. This notebook is a simple demonstration of how to use backtranslation to improve the performance of a machine learning model. The notebook is divided into the following sections:\n",
    "1. Introduction and Simple Generation\n",
    "2. Applying Data Preparation/Filtering\n",
    "3. Investigating Iterative Backtranslation\n",
    "4. Applying a similar pipeline to a more complex model (ALMA-R)\n",
    "5. Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Matey/project/nlp2/.venv/lib/python3.11/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# First cell in the notebook to enable autoreload of modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of FSMTForConditionalGeneration were not initialized from the model checkpoint at facebook/wmt19-de-en and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,179,648 || all params: 273,027,072 || trainable%: 0.4320626490841172\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from transformers import FSMTForConditionalGeneration, FSMTTokenizer\n",
    "from utils.data import TranslationDataModule\n",
    "from utils.models import TranslationLightning\n",
    "from pytorch_lightning import Trainer\n",
    "from peft import LoraConfig, get_peft_model\n",
    "# Isn't it so nice and clean now? I went through FOUR different ways of doing this before I thought of this one. WDWFDGFEQWDQWFGA\n",
    "\n",
    "SRC = \"de\"\n",
    "TGT = \"en\"\n",
    "BATCH_SIZE = 8\n",
    "MAX_LENGTH = 512\n",
    "\n",
    "cwd = Path.cwd()\n",
    "data_dir = cwd / \"Data\"\n",
    "\n",
    "it_parallel = \"it-parallel\"\n",
    "news_dataset = \"train-euro-news-big\"\n",
    "it_mono = \"it-mono\"\n",
    "\n",
    "test_folder = cwd / \"tests\"\n",
    "\n",
    "mname = f\"facebook/wmt19-{SRC}-{TGT}\"\n",
    "tokenizer = FSMTTokenizer.from_pretrained(mname)\n",
    "model = FSMTForConditionalGeneration.from_pretrained(mname)\n",
    "\n",
    "config = LoraConfig(\n",
    "    r = 16,\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0.2,\n",
    "    target_modules = [\"v_proj\", \"q_proj\"]\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "print(model.print_trainable_parameters())\n",
    "\n",
    "# input_ids = tokenizer.encode( \"Maschinelles Lernen ist gro√üartig, oder?\", return_tensors=\"pt\")\n",
    "# outputs = model.generate(input_ids)\n",
    "# decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "# print(decoded)  # Machine Learning is great, isn't it?\n",
    "\n",
    "# Copying settings from the original file though probably unneeded..\n",
    "model.generation_config.length_penalty = 1.2\n",
    "model.generation_config.num_beams = 5\n",
    "\n",
    "model_pl = TranslationLightning(model, tokenizer, lr=3e-4, adam_beta=(0.9, 0.98), weight_decay=1e-4, test_folder = test_folder)\n",
    "\n",
    "trainer = Trainer(max_steps=10,  gradient_clip_val=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Generation\n",
    "Here we simply load a pre-trained model and run inference on the test set. The model loaded is a pre-trained model from the [Hugging Face Transformers](https://huggingface.co/transformers/) library. \n",
    "\n",
    "TODO: Evaluate the model on the NEWS set and report the BLEU score.\n",
    "\n",
    "| Model | it-parallel | NEWS |\n",
    "| --- | --- | --- |\n",
    "| Base | 0.0 | 0.0 |\n",
    "| FT on IT-parallel | 0.0 | 0.0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = TranslationDataModule(data_dir / it_parallel, SRC, TGT, tokenizer, batch_size=BATCH_SIZE, max_length=MAX_LENGTH)\n",
    "\n",
    "\n",
    "# results = trainer.predict(model_pl, datamodule=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name  | Type                         | Params\n",
      "-------------------------------------------------------\n",
      "0 | model | FSMTForConditionalGeneration | 271 M \n",
      "-------------------------------------------------------\n",
      "269 M     Trainable params\n",
      "2.1 M     Non-trainable params\n",
      "271 M     Total params\n",
      "1,087.390 Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6ed585c41f9467280e3a6dd5d5e5b7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Matey/project/nlp2/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "STAGE:2024-05-28 09:53:51 7995:5666521 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "/Users/Matey/project/nlp2/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a6ec1e3f9dc4934bf78552e0e3d8eab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Matey/project/nlp2/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         2443325 function calls (2367887 primitive calls) in 937.271 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "     4008  417.684    0.104  417.684    0.104 {method 'index_select' of 'torch._C.TensorBase' objects}\n",
      "        1  156.843  156.843  156.843  156.843 {method 'run_backward' of 'torch._C._EngineBase' objects}\n",
      "     8376  107.402    0.013  107.402    0.013 {built-in method torch._C._nn.linear}\n",
      "     4068   77.233    0.019   77.233    0.019 {built-in method torch.bmm}\n",
      "     2004   65.097    0.032  482.782    0.241 modeling_fsmt.py:845(_reorder_buffer)\n",
      "     1033   21.096    0.020   21.096    0.020 {method 'masked_fill' of 'torch._C.TensorBase' objects}\n",
      "        1   17.680   17.680   17.680   17.680 {built-in method torch._C._nn.cross_entropy_loss}\n",
      "     2147   17.524    0.008   17.524    0.008 {built-in method torch.cat}\n",
      "     2034   16.484    0.008  187.982    0.092 modeling_fsmt.py:881(forward)\n",
      "     2034    8.931    0.004    8.931    0.004 {method 'softmax' of 'torch._C.TensorBase' objects}\n",
      "        2    4.373    2.187  616.018  308.009 utils.py:2911(_beam_search)\n",
      "     1026    3.623    0.004    3.623    0.004 {built-in method torch.relu}\n",
      "16372/170    2.667    0.000  284.220    1.672 module.py:1513(_call_impl)\n",
      "      167    2.443    0.015    2.443    0.015 {built-in method torch.topk}\n",
      "       18    2.429    0.135   72.934    4.052 modeling_fsmt.py:420(forward)\n",
      "     1008    1.839    0.002  169.327    0.168 modeling_fsmt.py:601(forward)\n",
      "      342    1.196    0.003    1.196    0.003 {built-in method torch.embedding}\n",
      "    16484    1.144    0.000    1.144    0.000 {built-in method torch._ops.profiler._record_function_enter_new}\n",
      "        1    0.986    0.986  120.911  120.911 strategy.py:380(training_step)\n",
      "     3060    0.897    0.000    0.897    0.000 {built-in method torch.layer_norm}\n",
      "     6160    0.839    0.000    0.839    0.000 {method 'contiguous' of 'torch._C.TensorBase' objects}\n",
      "        2    0.498    0.249  656.258  328.129 utils.py:1283(generate)\n",
      "      168    0.473    0.003  192.356    1.145 modeling_fsmt.py:695(forward)\n",
      "      167    0.424    0.003    0.424    0.003 {method 'log_softmax' of 'torch._C.TensorBase' objects}\n",
      " 5354/338    0.345    0.000    0.348    0.001 {built-in method _abc._abc_subclasscheck}\n",
      "    16483    0.341    0.000    0.341    0.000 {built-in method torch._ops.profiler.}\n",
      "    16371    0.339    0.000    1.682    0.000 pytorch.py:70(_start_recording_forward)\n",
      "      167    0.298    0.002    0.440    0.003 beam_search.py:215(process)\n",
      "    36663    0.279    0.000    0.637    0.000 tokenization_utils_base.py:1324(all_special_tokens_extended)\n",
      "        3    0.274    0.091   73.411   24.470 modeling_fsmt.py:477(forward)\n",
      "    16483    0.211    0.000    0.604    0.000 profiler.py:610(__exit__)\n",
      "    16932    0.181    0.000    0.181    0.000 {method 'view' of 'torch._C.TensorBase' objects}\n",
      "     2206    0.157    0.000    0.157    0.000 {method 'unbind' of 'torch._C.TensorBase' objects}\n",
      "      226    0.151    0.001    0.153    0.001 {built-in method marshal.loads}\n",
      "312538/311636    0.149    0.000    0.176    0.000 {built-in method builtins.getattr}\n",
      "    36663    0.146    0.000    0.258    0.000 tokenization_utils_base.py:1308(special_tokens_map_extended)\n",
      "        6    0.140    0.023    0.140    0.023 {method 'repeat_interleave' of 'torch._C.TensorBase' objects}\n",
      "    37367    0.129    0.000    0.239    0.000 tokenization_utils.py:630(convert_tokens_to_ids)\n",
      "     6291    0.112    0.000    0.191    0.000 functional.py:1252(dropout)\n",
      "    40777    0.091    0.000    0.091    0.000 module.py:1675(__getattr__)\n",
      "    16484    0.090    0.000    0.131    0.000 profiler.py:593(__init__)\n",
      "     8868    0.086    0.000    0.086    0.000 {method 'transpose' of 'torch._C.TensorBase' objects}\n",
      "16372/170    0.083    0.000  284.222    1.672 module.py:1507(_wrapped_call_impl)\n",
      "    28003    0.082    0.000    0.082    0.000 {method 'get' of 'dict' objects}\n",
      "246622/244051    0.071    0.000    0.440    0.000 {built-in method builtins.isinstance}\n",
      "      227    0.071    0.000    0.071    0.000 {method 'read' of '_io.BufferedReader' objects}\n",
      "     8376    0.070    0.000  107.492    0.013 linear.py:115(forward)\n",
      "    16484    0.064    0.000    1.240    0.000 profiler.py:604(__enter__)\n",
      "   148678    0.063    0.000    0.082    0.000 tokenization_utils.py:652(_convert_token_to_id_with_added_voc)\n",
      "    18610    0.050    0.000    0.050    0.000 {built-in method torch._C._get_tracing_state}\n",
      "    36663    0.049    0.000    0.725    0.000 tokenization_utils_base.py:1345(all_special_tokens)\n",
      "     6291    0.049    0.000    0.049    0.000 {built-in method torch.dropout}\n",
      "    16371    0.048    0.000    0.632    0.000 pytorch.py:77(_stop_recording_forward)\n",
      "      171    0.046    0.000    0.118    0.001 modeling_fsmt.py:1359(make_positions)\n",
      "    76559    0.045    0.000    0.062    0.000 {method 'items' of 'collections.OrderedDict' objects}\n",
      "      205    0.045    0.000    0.045    0.000 {built-in method torch.tensor}\n",
      "17379/17337    0.045    0.000    0.061    0.000 typing.py:349(inner)\n",
      "        1    0.043    0.043  937.276  937.276 call.py:31(_call_and_handle_interrupt)\n",
      "   146652    0.040    0.000    0.040    0.000 {method 'update' of 'set' objects}\n",
      "    36663    0.039    0.000    0.039    0.000 tokenization_utils_base.py:1352(<listcomp>)\n",
      "      4/3    0.039    0.010  934.204  311.401 _contextlib.py:112(decorate_context)\n",
      "    36599    0.037    0.000    0.978    0.000 tokenization_utils_base.py:1355(all_special_ids)\n",
      "      171    0.036    0.000    0.036    0.000 {built-in method torch.cumsum}\n",
      "    16483    0.035    0.000    0.376    0.000 _ops.py:512(__call__)\n",
      "       64    0.034    0.001    0.999    0.016 tokenization_utils.py:953(convert_ids_to_tokens)\n",
      "      346    0.034    0.000    0.034    0.000 {method 'clone' of 'torch._C.TensorBase' objects}\n",
      "     2016    0.033    0.000   17.563    0.009 modeling_fsmt.py:986(_use_saved_state)\n",
      "    16484    0.032    0.000    1.177    0.000 _ops.py:750(__call__)\n",
      "     3060    0.032    0.000    0.971    0.000 normalization.py:200(forward)\n",
      "      172    0.030    0.000    0.030    0.000 {method 'eq' of 'torch._C.TensorBase' objects}\n",
      "    11726    0.029    0.000    0.029    0.000 {method 'size' of 'torch._C.TensorBase' objects}\n",
      "   173315    0.029    0.000    0.029    0.000 {method 'append' of 'list' objects}\n",
      "   152862    0.027    0.000    0.027    0.000 {method 'extend' of 'list' objects}\n",
      "      168    0.027    0.000  244.548    1.456 modeling_fsmt.py:1185(forward)\n",
      "     4122    0.024    0.000    0.089    0.000 modeling_fsmt.py:878(_shape)\n",
      "     3060    0.024    0.000    0.931    0.000 functional.py:2531(layer_norm)\n",
      "      149    0.023    0.000    0.023    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "     2233    0.020    0.000    0.020    0.000 {method 'unsqueeze' of 'torch._C.TensorBase' objects}\n",
      "    152/9    0.019    0.000    0.299    0.033 apply_func.py:84(_apply_to_collection_slow)\n",
      "     1061    0.019    0.000    0.196    0.000 {built-in method _abc._abc_instancecheck}\n",
      "        3    0.019    0.006    0.579    0.193 module.py:371(log)\n",
      "     3705    0.018    0.000    0.020    0.000 generic.py:438(__setattr__)\n",
      "      215    0.018    0.000    0.039    0.000 inspect.py:2333(_signature_from_function)\n",
      "        3    0.017    0.006    0.058    0.019 {built-in method _warnings.warn}\n",
      "     1208    0.017    0.000    0.081    0.000 tokenization_fsmt.py:279(bpe)\n",
      "      507    0.017    0.000    0.042    0.000 generic.py:363(__post_init__)\n",
      "        8    0.017    0.002    0.101    0.013 arrow_writer.py:161(__arrow_array__)\n",
      "        2    0.016    0.008  657.974  328.987 models.py:71(validation_step)\n",
      "  414/215    0.016    0.000    0.069    0.000 inspect.py:2428(_signature_from_callable)\n",
      "      165    0.016    0.000    0.045    0.000 stopping_criteria.py:154(__call__)\n",
      "        2    0.016    0.008    0.038    0.019 beam_search.py:318(finalize)\n",
      "        1    0.016    0.016  119.925  119.925 models.py:59(training_step)\n",
      "       52    0.016    0.000    0.016    0.000 {built-in method posix.listdir}\n",
      "        1    0.015    0.015    0.015    0.015 {built-in method _posixsubprocess.fork_exec}\n",
      "     1347    0.015    0.000    0.015    0.000 generic.py:444(__setitem__)\n",
      "      227    0.015    0.000    0.015    0.000 {built-in method io.open_code}\n",
      "     1002    0.015    0.000  482.797    0.482 modeling_fsmt.py:1294(<dictcomp>)\n",
      "     6291    0.015    0.000    0.026    0.000 _VF.py:26(__getattr__)\n",
      "     1004    0.015    0.000    0.015    0.000 {built-in method posix.stat}\n",
      "       61    0.014    0.000    0.043    0.001 tokenize.py:686(tokenize)\n",
      "      167    0.014    0.000    0.014    0.000 {built-in method torch.div}\n",
      "      167    0.014    0.000    0.014    0.000 {method 'expand_as' of 'torch._C.TensorBase' objects}\n",
      "  483/482    0.014    0.000    0.018    0.000 module.py:1690(__setattr__)\n",
      "      174    0.013    0.000    0.013    0.000 {method 'ne' of 'torch._C.TensorBase' objects}\n",
      "  358/341    0.013    0.000    0.082    0.000 {built-in method builtins.__build_class__}\n",
      "     6530    0.013    0.000    0.043    0.000 __init__.py:272(_compile)\n",
      "        1    0.013    0.013  156.863  156.863 __init__.py:164(backward)\n",
      "      104    0.013    0.000    0.096    0.001 pytorch.py:442(stop)\n",
      "      172    0.013    0.000    0.013    0.000 {method 'type_as' of 'torch._C.TensorBase' objects}\n",
      "     7589    0.013    0.000    0.020    0.000 {method 'sub' of 're.Pattern' objects}\n",
      "4099/2936    0.012    0.000    0.235    0.000 {built-in method builtins.hasattr}\n",
      "      167    0.012    0.000  482.811    2.891 modeling_fsmt.py:1289(_reorder_cache)\n",
      "       98    0.012    0.000    0.022    0.000 ipkernel.py:775(_clean_thread_parent_frames)\n",
      "18530/2366    0.012    0.000    0.013    0.000 module.py:2333(named_modules)\n",
      "        1    0.012    0.012    0.038    0.038 profiler.py:129(start_trace)\n",
      "    30/14    0.012    0.000    0.047    0.003 features.py:265(_cast_to_python_objects)\n",
      "31262/27811    0.012    0.000    0.016    0.000 {built-in method builtins.len}\n",
      "       48    0.012    0.000    0.238    0.005 data.py:20(__getitem__)\n",
      "     1256    0.011    0.000    0.104    0.000 {built-in method builtins.all}\n",
      "      171    0.011    0.000    0.011    0.000 {method 'int' of 'torch._C.TensorBase' objects}\n",
      "        3    0.011    0.004    0.012    0.004 module.py:451(__init__)\n",
      "        1    0.011    0.011   17.691   17.691 functional.py:2969(cross_entropy)\n",
      "      337    0.010    0.000    0.012    0.000 beam_search.py:946(add)\n",
      "      330    0.010    0.000    0.010    0.000 {built-in method torch.full}\n",
      "       11    0.010    0.001    0.010    0.001 {method 'squeeze' of 'torch._C.TensorBase' objects}\n",
      "      683    0.010    0.000    0.010    0.000 {method 'max' of 'torch._C.TensorBase' objects}\n",
      "      506    0.010    0.000    0.010    0.000 {built-in method torch.zeros}\n",
      "        2    0.009    0.005    0.009    0.005 {method 'min' of 'torch._C.TensorBase' objects}\n",
      "       75    0.009    0.000    0.009    0.000 socket.py:626(send)\n",
      "     2206    0.009    0.000    0.173    0.000 _tensor.py:1012(__iter__)\n",
      "       75    0.009    0.000    0.009    0.000 {method 'detach' of 'torch._C.TensorBase' objects}\n",
      "    239/1    0.009    0.000  937.288  937.288 {built-in method builtins.exec}\n",
      "        1    0.009    0.009    0.043    0.043 tensorboard.py:295(finalize)\n",
      "     2034    0.009    0.000    8.941    0.004 functional.py:1828(softmax)\n",
      "        5    0.009    0.002    0.010    0.002 distributed_c10d.py:948(is_initialized)\n",
      "      171    0.009    0.000    1.157    0.007 modeling_fsmt.py:1373(forward)\n",
      "        1    0.009    0.009    0.010    0.010 {built-in method _imp.create_dynamic}\n",
      "      168    0.009    0.000  226.745    1.350 modeling_fsmt.py:1059(forward)\n",
      "       23    0.009    0.000    0.009    0.000 tokenize.py:359(islower)\n",
      "        1    0.008    0.008  658.363  658.363 evaluation_loop.py:108(run)\n",
      "      165    0.008    0.000    0.017    0.000 stopping_criteria.py:147(__call__)\n",
      "      167    0.008    0.000    0.008    0.000 {method 'all' of 'torch._C.TensorBase' objects}\n",
      "     4796    0.008    0.000    0.008    0.000 {method 'item' of 'torch._C.TensorBase' objects}\n",
      "      133    0.008    0.000    0.118    0.001 contextlib.py:141(__exit__)\n",
      "      588    0.008    0.000    0.009    0.000 {built-in method builtins.setattr}\n",
      "       68    0.008    0.000    0.008    0.000 {built-in method sys.intern}\n",
      "        3    0.008    0.003    0.053    0.018 module.py:642(__to_tensor)\n",
      "    16483    0.008    0.000    0.008    0.000 {method '__exit__' of 'torch._C.DisableTorchFunctionSubclass' objects}\n",
      "      167    0.008    0.000    0.062    0.000 logits_process.py:72(__call__)\n",
      "     16/8    0.008    0.000    0.016    0.002 module.py:733(_enforce_nested_string_type)\n",
      "        4    0.007    0.002    0.007    0.002 {method 'copy_' of 'torch._C.StorageBase' objects}\n",
      "       64    0.007    0.000    1.095    0.017 tokenization_utils.py:991(_decode)\n",
      "    37365    0.007    0.000    0.007    0.000 {method 'values' of 'dict' objects}\n",
      "        4    0.007    0.002    0.042    0.011 _tensor.py:82(__deepcopy__)\n",
      "      165    0.007    0.000    0.007    0.000 {built-in method torch.isin}\n",
      "       87    0.007    0.000    0.010    0.000 __init__.py:1467(debug)\n",
      "    11236    0.007    0.000    0.046    0.000 tokenization_fsmt.py:289(<lambda>)\n",
      "        8    0.007    0.001    0.007    0.001 {method 'splitlines' of 'str' objects}\n",
      "     9557    0.007    0.000    0.007    0.000 {built-in method torch._C._has_torch_function_unary}\n",
      "        1    0.007    0.007    0.010    0.010 modeling_fsmt.py:305(triu_onnx)\n",
      "        1    0.007    0.007   17.698   17.698 loss.py:1178(forward)\n",
      "       32    0.007    0.000    0.007    0.000 beam_search.py:359(<listcomp>)\n",
      "        6    0.007    0.001    0.011    0.002 {method 'read' of '_io.TextIOWrapper' objects}\n",
      "        1    0.007    0.007    0.007    0.007 {built-in method torch._C._autograd._enable_profiler}\n",
      "        2    0.007    0.003    0.082    0.041 module.py:381(_finalize)\n",
      "      543    0.007    0.000    0.015    0.000 dataclasses.py:1233(fields)\n",
      "       18    0.006    0.000    0.205    0.011 call.py:183(_call_callback_hooks)\n",
      "        1    0.006    0.006    0.006    0.006 {built-in method torch._C._autograd._prepare_profiler}\n",
      "        2    0.006    0.003    0.025    0.013 metric.py:101(__init__)\n",
      "    16750    0.006    0.000    0.006    0.000 _jit_internal.py:1120(is_scripting)\n",
      "3165/2213    0.006    0.000    0.042    0.000 traitlets.py:630(get)\n",
      "      167    0.006    0.000    0.007    0.000 utils.py:636(_update_model_kwargs_for_generation)\n",
      "     3034    0.006    0.000    0.008    0.000 tokenization_fsmt.py:37(get_pairs)\n",
      "       88    0.006    0.000    0.006    0.000 {method 'tolist' of 'torch._C.TensorBase' objects}\n",
      "     1026    0.006    0.000    3.634    0.004 activation.py:100(forward)\n",
      "        2    0.006    0.003    0.024    0.012 arrow_writer.py:296(__init__)\n",
      "        3    0.006    0.002    0.016    0.005 writer.py:146(flush)\n",
      "       33    0.006    0.000    0.008    0.000 trainer.py:1392(training)\n",
      "        8    0.006    0.001    0.009    0.001 arrow_writer.py:406(schema)\n",
      " 1073/208    0.006    0.000    0.053    0.000 copy.py:128(deepcopy)\n",
      "       11    0.006    0.001  935.871   85.079 call.py:292(_call_strategy_hook)\n",
      "     4084    0.006    0.000    0.052    0.000 {built-in method builtins.min}\n",
      "        1    0.006    0.006    0.006    0.006 {built-in method torch.ones_like}\n",
      "        4    0.006    0.001    0.015    0.004 iostream.py:655(write)\n",
      "    28/20    0.006    0.000    0.363    0.018 apply_func.py:23(apply_to_collection)\n",
      "        1    0.006    0.006    0.006    0.006 automatic.py:59(from_training_step_output)\n",
      "   196/64    0.006    0.000    0.009    0.000 _compiler.py:37(_compile)\n",
      "       61    0.005    0.000    0.050    0.001 tokenization_fsmt.py:253(moses_detokenize)\n",
      "        2    0.005    0.003    0.027    0.013 eval_frame.py:406(__call__)\n",
      "        2    0.005    0.003    0.020    0.010 arrow_writer.py:574(write_table)\n",
      "      819    0.005    0.000    0.012    0.000 inspect.py:2686(__init__)\n",
      "        1    0.005    0.005    0.006    0.006 optimizer.py:788(zero_grad)\n",
      "        4    0.005    0.001    0.009    0.002 _tensor.py:241(_typed_storage)\n",
      "        2    0.005    0.003    0.143    0.072 arrow_writer.py:531(write_batch)\n",
      "       96    0.005    0.000    0.008    0.000 tokenization_fsmt.py:93(remove_non_printing_char)\n",
      "       96    0.005    0.000    0.006    0.000 tokenization_utils.py:93(split)\n",
      "        4    0.005    0.001    0.005    0.001 LexerAction.py:91(__init__)\n",
      "     3060    0.005    0.000    0.008    0.000 __init__.py:36(__get__)\n",
      "        2    0.005    0.002    0.009    0.004 functional.py:305(create_dynamic_map)\n",
      "      315    0.005    0.000    0.048    0.000 <frozen importlib._bootstrap_external>:1604(find_spec)\n",
      "        2    0.005    0.002    0.014    0.007 ATNDeserializer.py:200(readEdges)\n",
      "        2    0.005    0.002    0.013    0.007 skipfiles.py:371(check_verbose)\n",
      "        2    0.005    0.002    0.021    0.010 writer.py:1247(flush)\n",
      "        4    0.005    0.001    0.005    0.001 {method 'set_' of 'torch._C.TensorBase' objects}\n",
      "    16484    0.005    0.000    0.005    0.000 __init__.py:126(annotate)\n",
      "        1    0.005    0.005    0.026    0.026 modeling_fsmt.py:316(_prepare_fsmt_decoder_inputs)\n",
      "      266    0.005    0.000    0.176    0.001 typing.py:1572(__subclasscheck__)\n",
      "      425    0.005    0.000    0.005    0.000 threading.py:1161(ident)\n",
      "       64    0.005    0.000    1.125    0.018 tokenization_utils_base.py:3781(decode)\n",
      "      236    0.005    0.000    0.060    0.000 <frozen importlib._bootstrap>:1054(_find_spec)\n",
      "        5    0.004    0.001    0.020    0.004 pathlib.py:868(__new__)\n",
      "        7    0.004    0.001    0.004    0.001 result.py:538(_get_default_dtype)\n",
      "      400    0.004    0.000    0.007    0.000 inspect.py:2972(__init__)\n",
      "     1026    0.004    0.000    3.628    0.004 functional.py:1462(relu)\n",
      "        1    0.004    0.004  936.568  936.568 trainer.py:1018(_run_stage)\n",
      "       18    0.004    0.000    0.004    0.000 {built-in method torch.rand}\n",
      "        1    0.004    0.004  937.281  937.281 trainer.py:504(fit)\n",
      " 5354/338    0.004    0.000    0.351    0.001 <frozen abc>:121(__subclasscheck__)\n",
      "       52    0.004    0.000    0.021    0.000 <frozen importlib._bootstrap_external>:1655(_fill_cache)\n",
      "        1    0.004    0.004  277.916  277.916 optimizer.py:368(wrapper)\n",
      "        1    0.004    0.004  156.878  156.878 strategy.py:192(backward)\n",
      "        1    0.004    0.004    0.004    0.004 {built-in method torch.randperm}\n",
      "     4816    0.004    0.000    0.021    0.000 __init__.py:178(sub)\n",
      "        8    0.004    0.001    0.012    0.002 pathlib.py:56(parse_parts)\n",
      "       64    0.004    0.000    0.006    0.000 helpers.py:7(extract_all_word_ngrams)\n",
      "     2052    0.004    0.000    0.014    0.000 module.py:2157(_named_members)\n",
      "      444    0.004    0.000    0.004    0.000 {method 'to' of 'torch._C.TensorBase' objects}\n",
      "        9    0.004    0.000    0.004    0.000 {built-in method torch.stack}\n",
      "        1    0.004    0.004    0.004    0.004 pandas_compat.py:1(<module>)\n",
      "      342    0.004    0.000    1.204    0.004 sparse.py:162(forward)\n",
      "    59/49    0.004    0.000    0.006    0.000 {built-in method builtins.repr}\n",
      "   210/42    0.004    0.000    0.016    0.000 _dill.py:31(save)\n",
      "        1    0.004    0.004    0.021    0.021 requirements.py:100(__init__)\n",
      "      359    0.004    0.000    0.004    0.000 hooks.py:23(__init__)\n",
      "    30/27    0.004    0.000  277.962   10.295 call.py:135(_call_lightning_module_hook)\n",
      "      201    0.004    0.000    0.065    0.000 inspect.py:3278(signature)\n",
      "       25    0.004    0.000    0.004    0.000 {built-in method _abc._abc_init}\n",
      "       93    0.004    0.000    0.006    0.000 traitlets.py:1914(traits)\n",
      " 1013/342    0.004    0.000    0.008    0.000 generic.py:431(__getitem__)\n",
      "     4438    0.004    0.000    0.004    0.000 dataclasses.py:1248(<genexpr>)\n",
      "     11/7    0.004    0.000    0.303    0.043 rank_zero.py:36(wrapped_fn)\n",
      "        2    0.004    0.002    0.061    0.030 module.py:625(_init_writer)\n",
      "        4    0.004    0.001    0.014    0.004 storage.py:108(__deepcopy__)\n",
      "        6    0.004    0.001    0.004    0.001 {built-in method _codecs.utf_8_decode}\n",
      "      364    0.004    0.000    0.007    0.000 <frozen _collections_abc>:941(update)\n",
      "      142    0.004    0.000    0.005    0.000 enums.py:81(__eq__)\n",
      "     1492    0.004    0.000    0.004    0.000 enum.py:1091(__new__)\n",
      "     6320    0.004    0.000    0.004    0.000 ATNDeserializer.py:431(readInt)\n",
      "        3    0.004    0.001    0.004    0.001 data.py:91(has_len_all_ranks)\n",
      "        2    0.004    0.002    0.008    0.004 ipc.py:83(__init__)\n",
      "        1    0.004    0.004    0.008    0.008 seed.py:117(_set_rng_states)\n",
      "     1492    0.004    0.000    0.007    0.000 enum.py:685(__call__)\n",
      "      452    0.004    0.000    0.008    0.000 <frozen importlib._bootstrap_external>:437(cache_from_source)\n",
      "        3    0.004    0.001    0.062    0.021 profiler.py:640(step)\n",
      "     6320    0.003    0.000    0.004    0.000 ATNDeserializer.py:88(adjust)\n",
      "    16174    0.003    0.000    0.006    0.000 {method 'add' of 'set' objects}\n",
      "        2    0.003    0.002    0.004    0.002 keyhash.py:90(__init__)\n",
      "   145/36    0.003    0.000    0.202    0.006 {built-in method builtins.__import__}\n",
      "        2    0.003    0.002    0.280    0.140 module.py:488(add_batch)\n",
      "        1    0.003    0.003    0.003    0.003 {method 'gather' of 'torch._C.TensorBase' objects}\n",
      "       12    0.003    0.000    0.005    0.000 py_utils.py:322(zip_dict)\n",
      "        1    0.003    0.003  156.872  156.872 precision.py:52(backward)\n",
      "3803/2421    0.003    0.000    0.045    0.000 traitlets.py:677(__get__)\n",
      "      260    0.003    0.000    0.005    0.000 encoder.py:205(iterencode)\n",
      "        1    0.003    0.003    0.046    0.046 module.py:1305(optimizer_zero_grad)\n",
      "       96    0.003    0.000    0.021    0.000 normalize.py:182(normalize)\n",
      "        3    0.003    0.001    0.168    0.056 result.py:357(log)\n",
      "        1    0.003    0.003    0.104    0.104 evaluation_loop.py:247(on_run_end)\n",
      "        1    0.003    0.003  156.866  156.866 _tensor.py:463(backward)\n",
      "        2    0.003    0.002    0.414    0.207 module.py:415(compute)\n",
      "     3060    0.003    0.000    0.003    0.000 {built-in method torch._C._get_cudnn_enabled}\n",
      "        1    0.003    0.003    0.014    0.014 profiler.py:235(_get_distributed_info)\n",
      "     3202    0.003    0.000    0.004    0.000 beam_search.py:940(__len__)\n",
      "     1486    0.003    0.000    0.024    0.000 __init__.py:173(search)\n",
      "        1    0.003    0.003    0.005    0.005 trainer.py:1388(interrupted)\n",
      "       64    0.003    0.000    0.025    0.000 generic.py:257(to_py_obj)\n",
      "        1    0.003    0.003    0.047    0.047 tensorboard.py:223(finalize)\n",
      "     5019    0.003    0.000    0.003    0.000 {method 'search' of 're.Pattern' objects}\n",
      "       49    0.003    0.000    0.003    0.000 threading.py:1494(enumerate)\n",
      "       75    0.003    0.000    0.015    0.000 iostream.py:259(schedule)\n",
      "      107    0.003    0.000    0.003    0.000 apply_func.py:11(is_namedtuple)\n",
      "       10    0.003    0.000    0.003    0.000 {built-in method torch._C._log_api_usage_once}\n",
      "       82    0.003    0.000    0.003    0.000 types.py:237(is_string)\n",
      "      544    0.003    0.000    0.003    0.000 {built-in method torch._C._set_grad_enabled}\n",
      "   239/10    0.003    0.000    0.488    0.049 <frozen importlib._bootstrap>:1165(_find_and_load)\n",
      "       14    0.003    0.000    0.018    0.001 signature_utils.py:18(is_param_in_hook_signature)\n",
      "        2    0.003    0.001    0.034    0.017 module.py:277(_create_cache_file)\n",
      "        2    0.003    0.001    0.004    0.002 ATNDeserializer.py:378(verifyATN)\n",
      "      201    0.003    0.000    0.061    0.000 inspect.py:3024(from_callable)\n",
      "        1    0.003    0.003  937.097  937.097 trainer.py:910(_run)\n",
      "     3441    0.003    0.000    0.003    0.000 {method 'dim' of 'torch._C.TensorBase' objects}\n",
      "        2    0.003    0.001    0.091    0.045 result.py:187(__init__)\n",
      "        3    0.003    0.001    0.003    0.001 {method 'any' of 'torch._C.TensorBase' objects}\n",
      "       26    0.003    0.000    0.013    0.001 trainer.py:1653(_results)\n",
      "     1846    0.003    0.000    0.007    0.000 <frozen importlib._bootstrap_external>:126(_path_join)\n",
      "   121/68    0.003    0.000    0.007    0.000 _parser.py:507(_parse)\n",
      "      203    0.003    0.000    0.004    0.000 inspect.py:735(unwrap)\n",
      "        2    0.003    0.001    0.045    0.023 _compile.py:20(inner)\n",
      "        3    0.003    0.001    0.003    0.001 pathlib.py:971(absolute)\n",
      "       92    0.003    0.000    0.003    0.000 result.py:294(__setattr__)\n",
      "     5076    0.003    0.000    0.003    0.000 {method 'join' of 'str' objects}\n",
      "      226    0.003    0.000    0.254    0.001 <frozen importlib._bootstrap_external>:1007(get_code)\n",
      "        8    0.003    0.000    0.012    0.002 data.py:357(_replace_dunder_methods)\n",
      "      202    0.003    0.000    0.136    0.001 profiler.py:55(profile)\n",
      "       61    0.003    0.000    0.004    0.000 tokenize.py:681(unescape_xml)\n",
      "        4    0.003    0.001    0.011    0.003 storage.py:124(clone)\n",
      "       34    0.003    0.000    0.003    0.000 overrides.py:10(is_overridden)\n",
      "       64    0.003    0.000    0.005    0.000 _compiler.py:509(_compile_info)\n",
      "        2    0.003    0.001    0.007    0.004 ATNDeserializer.py:91(<listcomp>)\n",
      "        4    0.003    0.001    0.006    0.001 version.py:43(parse)\n",
      "        2    0.003    0.001    0.003    0.001 utils.py:741(getfile)\n",
      "        2    0.003    0.001    0.032    0.016 decorators.py:32(disable)\n",
      "       14    0.003    0.000    0.015    0.001 inspect.py:1336(getfullargspec)\n",
      "        1    0.003    0.003  278.126  278.126 fit_loop.py:196(run)\n",
      "     1766    0.003    0.000    0.171    0.000 {built-in method builtins.issubclass}\n",
      "     3403    0.003    0.000    0.003    0.000 {built-in method torch._C._has_torch_function_variadic}\n",
      "        2    0.003    0.001    0.038    0.019 arrow_dataset.py:671(__init__)\n",
      "        4    0.003    0.001    0.003    0.001 {method 'new_empty' of 'torch._C.TensorBase' objects}\n",
      "       60    0.003    0.000    0.003    0.000 _compiler.py:241(_optimize_charset)\n",
      "      185    0.003    0.000    0.005    0.000 inspect.py:3040(replace)\n",
      "       48    0.003    0.000    0.003    0.000 __init__.py:2656(key)\n",
      "       93    0.003    0.000    0.003    0.000 __init__.py:3139(__hash__)\n",
      "        5    0.003    0.001    0.003    0.001 record_writer.py:42(flush)\n",
      "    70/66    0.003    0.000    0.005    0.000 features.py:1232(encode_nested_example)\n",
      "        1    0.003    0.003    0.003    0.003 profiler.py:508(__init__)\n",
      "      303    0.003    0.000    0.003    0.000 <frozen importlib._bootstrap>:179(_get_module_lock)\n",
      "        2    0.003    0.001    0.005    0.003 inspect.py:936(getsourcefile)\n",
      "      185    0.003    0.000    0.009    0.000 inspect.py:2039(_signature_bound_method)\n",
      "     2011    0.003    0.000    0.004    0.000 parameter.py:8(__instancecheck__)\n",
      "      342    0.003    0.000    1.199    0.004 functional.py:2127(embedding)\n",
      "        4    0.003    0.001    1.127    0.282 tokenization_utils_base.py:3771(<listcomp>)\n",
      "  583/564    0.003    0.000    0.005    0.000 {built-in method __new__ of type object at 0x10ed21da8}\n",
      "        2    0.002    0.001    0.031    0.016 concurrent.py:29(_executor_map)\n",
      "     1402    0.002    0.000    0.003    0.000 __init__.py:315(_subx)\n",
      "        2    0.002    0.001    0.048    0.024 fit_loop.py:213(setup_data)\n",
      "     44/1    0.002    0.000    0.012    0.012 core.py:776(_parseNoCache)\n",
      "      336    0.002    0.000    0.006    0.000 generic.py:457(to_tuple)\n",
      "        1    0.002    0.002    0.060    0.060 result.py:276(wrapped_func)\n",
      "        4    0.002    0.001    0.009    0.002 event_file_writer.py:180(flush)\n",
      "        2    0.002    0.001    0.018    0.009 _api.py:197(acquire)\n",
      "        8    0.002    0.000    0.015    0.002 pathlib.py:484(_parse_args)\n",
      "        3    0.002    0.001    0.004    0.001 fx_validator.py:191(check_logging_and_get_default_levels)\n",
      "      266    0.002    0.000    0.178    0.001 typing.py:1297(__instancecheck__)\n",
      "       96    0.002    0.000    0.142    0.001 tokenization_fsmt.py:323(_tokenize)\n",
      "        2    0.002    0.001    0.036    0.018 arrow_reader.py:191(_read_files)\n",
      "       14    0.002    0.000    0.002    0.000 {built-in method torch.linspace}\n",
      "    237/8    0.002    0.000    0.485    0.061 <frozen importlib._bootstrap>:1120(_find_and_load_unlocked)\n",
      "        9    0.002    0.000    0.002    0.000 {built-in method io.open}\n",
      "2684/2676    0.002    0.000    0.008    0.000 {built-in method builtins.iter}\n",
      "        3    0.002    0.001    0.035    0.012 warnings.py:20(_showwarnmsg_impl)\n",
      "    228/9    0.002    0.000    0.470    0.052 <frozen importlib._bootstrap>:666(_load_unlocked)\n",
      "        2    0.002    0.001    0.002    0.001 {built-in method torch.ones}\n",
      "        2    0.002    0.001    0.026    0.013 display_functions.py:105(display)\n",
      "      132    0.002    0.000    0.003    0.000 __init__.py:1734(isEnabledFor)\n",
      "       16    0.002    0.000    0.002    0.000 __init__.py:3034(_dep_map)\n",
      "        3    0.002    0.001    0.002    0.001 {built-in method torch.arange}\n",
      "        2    0.002    0.001    0.009    0.005 ATNDeserializer.py:115(readStates)\n",
      "      173    0.002    0.000    0.002    0.000 {method 'long' of 'torch._C.TensorBase' objects}\n",
      "       22    0.002    0.000    0.005    0.000 uuid.py:721(uuid4)\n",
      "        1    0.002    0.002    0.014    0.014 core.py:1076(parse_string)\n",
      "        9    0.002    0.000    0.030    0.003 notebook.py:144(display)\n",
      "       11    0.002    0.000    0.005    0.000 apply_func.py:71(move_data_to_device)\n",
      "        1    0.002    0.002  277.926  277.926 automatic.py:161(run)\n",
      "        1    0.002    0.002  277.909  277.909 optimizer.py:239(step)\n",
      "        3    0.002    0.001    0.002    0.001 {method 'random_' of 'torch._C.TensorBase' objects}\n",
      "        4    0.002    0.001    0.003    0.001 version.py:184(__init__)\n",
      "        1    0.002    0.002    0.002    0.002 {method 'set_state' of 'torch._C.Generator' objects}\n",
      "     11/1    0.002    0.000    0.011    0.011 core.py:3861(parseImpl)\n",
      "        1    0.002    0.002    0.023    0.023 __init__.py:3100(__init__)\n",
      "        2    0.002    0.001    0.002    0.001 {numpy.random.mtrand.seed}\n",
      "     9408    0.002    0.000    0.002    0.000 {method 'startswith' of 'str' objects}\n",
      "        8    0.002    0.000    0.003    0.000 module.py:618(_feature_names)\n",
      "        1    0.002    0.002    0.054    0.054 imports.py:128(_check_requirement)\n",
      "     1021    0.002    0.000    0.002    0.000 {method 'numel' of 'torch._C.TensorBase' objects}\n",
      "     1354    0.002    0.000    0.003    0.000 _parser.py:1090(expand_template)\n",
      "       49    0.002    0.000    0.007    0.000 ipkernel.py:790(<setcomp>)\n",
      "      215    0.002    0.000    0.004    0.000 inspect.py:167(get_annotations)\n",
      "        5    0.002    0.000    0.003    0.001 std.py:837(__init__)\n",
      "       32    0.002    0.000    0.007    0.000 specifiers.py:722(contains)\n",
      "        1    0.002    0.002    0.010    0.010 profiler.py:113(prepare_trace)\n",
      "      265    0.002    0.000    0.004    0.000 grad_mode.py:83(__exit__)\n",
      "        9    0.002    0.000    0.002    0.000 {built-in method torch.get_default_dtype}\n",
      "        8    0.002    0.000    0.002    0.000 <string>:2(__init__)\n",
      "        1    0.002    0.002  278.016  278.016 training_epoch_loop.py:135(run)\n",
      "     17/9    0.002    0.000    0.005    0.001 copy.py:259(_reconstruct)\n",
      "        2    0.002    0.001    0.071    0.035 module.py:591(_infer_feature_from_batch)\n",
      "      167    0.002    0.000  482.814    2.891 utils.py:2878(_temporary_reorder_cache)\n",
      "  481/422    0.002    0.000    0.395    0.001 {built-in method builtins.next}\n",
      "      288    0.002    0.000    0.005    0.000 tokenization_utils_base.py:2646(_get_padding_truncation_strategies)\n",
      "     1528    0.002    0.000    0.005    0.000 model_summary.py:450(_is_lazy_weight_tensor)\n",
      "     1846    0.002    0.000    0.003    0.000 <frozen importlib._bootstrap_external>:128(<listcomp>)\n",
      "        2    0.002    0.001    0.008    0.004 thread.py:161(submit)\n",
      "        4    0.002    0.001    0.002    0.001 inspect.py:896(getfile)\n",
      "        6    0.002    0.000    0.002    0.000 eval_frame.py:261(innermost_fn)\n",
      "      104    0.002    0.000    0.037    0.000 pytorch.py:412(start)\n",
      "        4    0.002    0.001    0.002    0.001 formatting.py:147(extract_column)\n",
      "       60    0.002    0.000    0.025    0.000 comm.py:24(publish_msg)\n",
      "      165    0.002    0.000    0.004    0.000 stopping_criteria.py:66(__call__)\n",
      "      167    0.002    0.000    0.426    0.003 functional.py:1926(log_softmax)\n",
      "     1034    0.002    0.000    0.002    0.000 inspect.py:3019(<genexpr>)\n",
      "     4736    0.002    0.000    0.002    0.000 {method 'items' of 'dict' objects}\n",
      "        2    0.002    0.001    0.004    0.002 skipfiles.py:304(check_file)\n",
      "        1    0.002    0.002    0.002    0.002 _config_module.py:142(__getattr__)\n",
      "        1    0.002    0.002    0.015    0.015 tqdm_progress.py:323(on_validation_end)\n",
      "   210/42    0.002    0.000    0.010    0.000 pickle.py:535(save)\n",
      "        2    0.002    0.001    0.015    0.007 _unix.py:36(_acquire)\n",
      "        1    0.002    0.002  658.423  658.423 trainer.py:1037(_run_sanity_check)\n",
      "       24    0.002    0.000    0.004    0.000 formatters.py:396(lookup_by_type)\n",
      "        1    0.002    0.002  278.014  278.014 training_epoch_loop.py:192(advance)\n",
      "       61    0.002    0.000    0.045    0.001 tokenize.py:839(detokenize)\n",
      "    62/26    0.002    0.000    0.002    0.000 features.py:1199(get_nested_type)\n",
      "        1    0.002    0.002    0.052    0.052 __init__.py:900(require)\n",
      "       22    0.002    0.000    0.002    0.000 {built-in method posix.urandom}\n",
      "        2    0.002    0.001    0.010    0.005 eval_frame.py:454(_fn)\n",
      "        3    0.002    0.001    0.004    0.001 result.py:207(update)\n",
      "        1    0.002    0.002  156.868  156.868 module.py:1073(backward)\n",
      "        4    0.002    0.000    0.010    0.003 event_file_writer.py:119(flush)\n",
      "     1610    0.002    0.000    0.019    0.000 tokenization_fsmt.py:362(_convert_token_to_id)\n",
      "        2    0.002    0.001    0.004    0.002 grad_mode.py:138(__exit__)\n",
      "      228    0.002    0.000    0.011    0.000 <frozen importlib._bootstrap>:493(_init_module_attrs)\n",
      "        1    0.002    0.002    0.045    0.045 __init__.py:724(resolve)\n",
      "      109    0.002    0.000    0.009    0.000 typing.py:653(Union)\n",
      "        5    0.002    0.000    0.005    0.001 asyncio.py:23(__init__)\n",
      "        2    0.002    0.001    0.010    0.005 inspect.py:3232(__str__)\n",
      "       42    0.002    0.000    0.002    0.000 logger.py:127(trace_setup)\n",
      "     3705    0.002    0.000    0.002    0.000 generic.py:373(<genexpr>)\n",
      "       42    0.002    0.000    0.021    0.000 _dill.py:418(dump)\n",
      "        2    0.002    0.001    0.002    0.001 {built-in method posix.open}\n",
      "        2    0.002    0.001    0.032    0.016 sacrebleu.py:140(_compute)\n",
      "  192/190    0.002    0.000    0.002    0.000 configuration_utils.py:260(__getattribute__)\n",
      "     4044    0.002    0.000    0.002    0.000 {method 'keys' of 'collections.OrderedDict' objects}\n",
      "        4    0.002    0.000    0.010    0.002 core.py:343(url_to_fs)\n",
      "      679    0.002    0.000    0.004    0.000 beam_search.py:971(is_done)\n",
      "        1    0.002    0.002    0.008    0.008 modeling_fsmt.py:383(shift_tokens_right)\n",
      "        1    0.002    0.002  277.920  277.920 optimizer.py:83(step)\n",
      "      236    0.002    0.000    0.002    0.000 {method '__exit__' of '_io._IOBase' objects}\n",
      "        1    0.002    0.002    0.003    0.003 checkpoint_connector.py:112(_parse_ckpt_path)\n",
      "        1    0.002    0.002    0.008    0.008 loss.py:20(__init__)\n",
      "       32    0.002    0.000    0.004    0.000 bleu.py:373(_compute_segment_statistics)\n",
      "        6    0.002    0.000    0.002    0.000 queue.py:122(put)\n",
      "       96    0.002    0.000    0.023    0.000 tokenize.py:431(tokenize)\n",
      "      230    0.002    0.000    0.006    0.000 typing.py:1346(__init__)\n",
      "        1    0.002    0.002    0.010    0.010 event_file_writer.py:238(stop)\n",
      "        2    0.002    0.001    0.002    0.001 trainer.py:1148(local_rank)\n",
      "       96    0.002    0.000    0.002    0.000 tokenization_utils_base.py:3657(_pad)\n",
      "        2    0.002    0.001    0.015    0.008 skipfiles.py:404(check)\n",
      "   108/64    0.002    0.000    0.008    0.000 _parser.py:447(_parse_sub)\n",
      "       34    0.002    0.000    0.003    0.000 traitlets.py:1297(setup_instance)\n",
      "        2    0.002    0.001    0.006    0.003 dataloader.py:226(__init__)\n",
      "       15    0.002    0.000    0.002    0.000 trainer.py:1601(loggers)\n",
      "      106    0.002    0.000    0.005    0.000 apply_func.py:17(is_dataclass_instance)\n",
      "       96    0.002    0.000    0.048    0.000 tokenization_utils_base.py:3397(prepare_for_model)\n",
      "       64    0.002    0.000    0.007    0.000 generic.py:263(<lambda>)\n",
      "        5    0.002    0.000    0.085    0.017 notebook.py:206(__init__)\n",
      "     1230    0.002    0.000    0.002    0.000 inspect.py:2751(kind)\n",
      "        2    0.002    0.001    0.033    0.016 concurrent.py:54(thread_map)\n",
      "      226    0.002    0.000    0.003    0.000 <frozen importlib._bootstrap_external>:642(_classify_pyc)\n",
      "        2    0.002    0.001    0.002    0.001 context.py:253(get_start_method)\n",
      "        4    0.002    0.000    0.062    0.015 result.py:432(_get_cache)\n",
      "        1    0.002    0.002    0.002    0.002 {method 'sum' of 'torch._C.TensorBase' objects}\n",
      "        4    0.002    0.000    1.130    0.282 tokenization_utils_base.py:3747(batch_decode)\n",
      "       14    0.002    0.000    0.048    0.003 features.py:428(cast_to_python_objects)\n",
      "       45    0.001    0.000    0.001    0.000 {method 'AddSerializedFile' of 'google._upb._message.DescriptorPool' objects}\n",
      "      171    0.001    0.000    0.002    0.000 container.py:315(__iter__)\n",
      "        2    0.001    0.001    0.050    0.025 notebook.py:99(status_printer)\n",
      "       80    0.001    0.000    0.002    0.000 threading.py:1185(is_alive)\n",
      "     1213    0.001    0.000    0.001    0.000 {method 'copy' of 'dict' objects}\n",
      "        4    0.001    0.000    0.006    0.001 core.py:312(_un_chain)\n",
      "        1    0.001    0.001    0.007    0.007 __init__.py:59(_make_grads)\n",
      "    24/14    0.001    0.000    0.002    0.000 inheritance.py:11(recurse)\n",
      "       64    0.001    0.000    0.001    0.000 {method 'cpu' of 'torch._C.TensorBase' objects}\n",
      "       62    0.001    0.000    0.022    0.000 session.py:754(send)\n",
      "       61    0.001    0.000    0.053    0.001 tokenization_fsmt.py:370(convert_tokens_to_string)\n",
      "     1727    0.001    0.000    0.003    0.000 typing.py:1290(__setattr__)\n",
      "       10    0.001    0.000    0.002    0.000 std.py:352(format_meter)\n",
      "       42    0.001    0.000    0.024    0.001 _dill.py:101(dump)\n",
      "       68    0.001    0.000    0.003    0.000 generic.py:101(_get_frameworks_and_test_func)\n",
      "       10    0.001    0.000    0.003    0.000 notebook.py:196(colour)\n",
      "        2    0.001    0.001    0.001    0.001 _api.py:103(__init__)\n",
      "     6672    0.001    0.000    0.001    0.000 {method 'replace' of 'str' objects}\n",
      "        8    0.001    0.000    0.001    0.000 storage.py:498(__new__)\n",
      "        6    0.001    0.000    0.005    0.001 features.py:1682(arrow_schema)\n",
      "        3    0.001    0.000    0.002    0.001 memory.py:24(recursive_detach)\n",
      "       64    0.001    0.000    0.025    0.000 _compiler.py:738(compile)\n",
      "       96    0.001    0.000    0.013    0.000 tokenize.py:368(handles_nonbreaking_prefixes)\n",
      "        4    0.001    0.000    0.046    0.011 metric.py:196(add_state)\n",
      "        1    0.001    0.001    0.008    0.008 profiler.py:286(_start_trace)\n",
      "     4272    0.001    0.000    0.001    0.000 {method 'index' of 'tuple' objects}\n",
      "     4610    0.001    0.000    0.002    0.000 _tensor.py:1034(__hash__)\n",
      "      808    0.001    0.000    0.002    0.000 ATNState.py:136(addTransition)\n",
      "        2    0.001    0.001    0.002    0.001 accelerator_connector.py:643(is_distributed)\n",
      "      227    0.001    0.000    0.089    0.000 <frozen importlib._bootstrap_external>:1127(get_data)\n",
      "        8    0.001    0.000    0.001    0.000 storage.py:570(__init__)\n",
      "      418    0.001    0.000    0.004    0.000 typing.py:168(_type_check)\n",
      "        2    0.001    0.001    0.002    0.001 _filelock.py:44(hash_filename_if_too_long)\n",
      "       34    0.001    0.000    0.004    0.000 model_helpers.py:29(is_overridden)\n",
      "        1    0.001    0.001    0.001    0.001 sampler.py:132(__init__)\n",
      "        1    0.001    0.001    0.009    0.009 automatic.py:280(_on_before_zero_grad)\n",
      "       65    0.001    0.000    0.002    0.000 version.py:261(__init__)\n",
      "        2    0.001    0.001  658.067  329.033 evaluation_loop.py:351(_evaluation_step)\n",
      "        2    0.001    0.001    0.003    0.001 base_comm.py:93(close)\n",
      "       96    0.001    0.000    0.006    0.000 tokenization_utils_base.py:3184(pad)\n",
      "     2769    0.001    0.000    0.001    0.000 tokenization_utils_base.py:1060(unk_token)\n",
      "        1    0.001    0.001    0.012    0.012 loss.py:29(__init__)\n",
      "        7    0.001    0.000    0.224    0.032 logger.py:105(experiment)\n",
      "       68    0.001    0.000    0.002    0.000 features.py:511(encode_example)\n",
      "      227    0.001    0.000    0.006    0.000 <frozen importlib._bootstrap_external>:567(_get_cached)\n",
      "       46    0.001    0.000    0.002    0.000 enum_type_wrapper.py:95(values)\n",
      "     1159    0.001    0.000    0.018    0.000 tokenization_fsmt.py:366(_convert_id_to_token)\n",
      "       22    0.001    0.000    0.015    0.001 base_comm.py:24(__init__)\n",
      "      195    0.001    0.000    0.035    0.000 tokenization_utils_base.py:681(convert_to_tensors)\n",
      "        3    0.001    0.000    0.006    0.002 metric.py:476(wrapped_func)\n",
      "        1    0.001    0.001    0.007    0.007 model_helpers.py:75(restore)\n",
      "    180/1    0.001    0.000    0.007    0.007 module.py:799(_apply)\n",
      "       52    0.001    0.000    0.002    0.000 <frozen importlib._bootstrap_external>:1684(<setcomp>)\n",
      "        8    0.001    0.000    0.003    0.000 _dill.py:1750(save_type)\n",
      "        2    0.001    0.001    0.005    0.003 thread.py:180(_adjust_thread_count)\n",
      "      364    0.001    0.000    0.008    0.000 __init__.py:1109(__init__)\n",
      "      227    0.001    0.000    0.002    0.000 <frozen importlib._bootstrap_external>:778(spec_from_file_location)\n",
      "       18    0.001    0.000    0.002    0.000 model_checkpoint.py:257(state_key)\n",
      "       21    0.001    0.000    0.001    0.000 local.py:211(_strip_protocol)\n",
      "      666    0.001    0.000    0.004    0.000 ATNDeserializer.py:496(stateFactory)\n",
      "       96    0.001    0.000    0.224    0.002 tokenization_utils_base.py:2985(encode_plus)\n",
      "     1778    0.001    0.000    0.001    0.000 {method 'split' of 'str' objects}\n",
      "       28    0.001    0.000    0.001    0.000 features.py:116(string_to_arrow)\n",
      "        3    0.001    0.000    0.004    0.001 warnings.py:57(_is_path_in_lightning)\n",
      "        3    0.001    0.000    0.060    0.020 rank_zero.py:76(rank_zero_warn)\n",
      "        4    0.001    0.000    0.071    0.018 result.py:478(metrics)\n",
      "        8    0.001    0.000    0.002    0.000 table.py:1960(cast_array_to_feature)\n",
      "        4    0.001    0.000    0.050    0.012 profiler.py:662(_transit_action)\n",
      "        1    0.001    0.001  277.917  277.917 precision.py:112(optimizer_step)\n",
      "        1    0.001    0.001  156.912  156.912 automatic.py:238(backward_fn)\n",
      "    59/45    0.001    0.000    0.034    0.001 widget.py:589(get_state)\n",
      "        1    0.001    0.001  120.930  120.930 automatic.py:305(_training_step)\n",
      "        2    0.001    0.001    0.008    0.004 bleu.py:154(__init__)\n",
      "        1    0.001    0.001    0.001    0.001 record_writer.py:45(close)\n",
      "        1    0.001    0.001    0.001    0.001 {method 'masked_fill_' of 'torch._C.TensorBase' objects}\n",
      "       16    0.001    0.000    0.001    0.000 __init__.py:2886(insert_on)\n",
      "      738    0.001    0.000    0.005    0.000 ATNDeserializer.py:474(edgeFactory)\n",
      "        3    0.001    0.000    0.001    0.000 {built-in method torch.empty}\n",
      "     7523    0.001    0.000    0.001    0.000 {built-in method builtins.ord}\n",
      "        1    0.001    0.001  277.906  277.906 precision.py:95(_wrap_closure)\n",
      "       66    0.001    0.000    0.024    0.000 widget.py:691(notify_change)\n",
      "       26    0.001    0.000    0.010    0.000 trainer.py:1575(_active_loop)\n",
      "        4    0.001    0.000    0.024    0.006 {method 'throw' of 'generator' objects}\n",
      "        2    0.001    0.001    0.011    0.005 _filelock.py:34(__init__)\n",
      "       42    0.001    0.000    0.002    0.000 _dill.py:351(__init__)\n",
      "       96    0.001    0.000    0.221    0.002 tokenization_utils.py:663(_encode_plus)\n",
      "        1    0.001    0.001    0.001    0.001 import_utils.py:1494(__getattr__)\n",
      "      272    0.001    0.000    0.006    0.000 traitlets.py:1529(_notify_observers)\n",
      "        4    0.001    0.000    0.004    0.001 py_utils.py:242(temp_seed)\n",
      "      728    0.001    0.000    0.002    0.000 {built-in method builtins.max}\n",
      "        6    0.001    0.000    0.009    0.001 notebook.py:276(close)\n",
      "       18    0.001    0.000    0.001    0.000 event_file_writer.py:206(_check_worker_status)\n",
      "        2    0.001    0.001    0.001    0.001 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "       18    0.001    0.000    0.001    0.000 skipfiles.py:308(<genexpr>)\n",
      "        2    0.001    0.001    0.016    0.008 formatters.py:90(format)\n",
      "       11    0.001    0.000    0.056    0.005 imports.py:154(_check_available)\n",
      "        5    0.001    0.000    0.002    0.000 __init__.py:9(is_available)\n",
      "        1    0.001    0.001  277.921  277.921 module.py:1264(optimizer_step)\n",
      "        2    0.001    0.001    0.027    0.013 fingerprint.py:249(generate_fingerprint)\n",
      "  237/236    0.001    0.000    0.052    0.000 <frozen importlib._bootstrap_external>:1464(_get_spec)\n",
      "      289    0.001    0.000    0.001    0.000 typing.py:1657(__eq__)\n",
      "      678    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap_external>:84(_unpack_uint32)\n",
      "        4    0.001    0.000    0.001    0.000 {method 'new' of 'torch._C.TensorBase' objects}\n",
      "     1061    0.001    0.000    0.197    0.000 <frozen abc>:117(__instancecheck__)\n",
      "        1    0.001    0.001    0.003    0.003 _config_module.py:343(__getattr__)\n",
      "       10    0.001    0.000    0.004    0.000 py_utils.py:192(asdict)\n",
      "       96    0.001    0.000    0.003    0.000 tokenization_fsmt.py:50(replace_unicode_punct)\n",
      "        4    0.001    0.000    0.003    0.001 arrow_writer.py:270(__init__)\n",
      "        1    0.001    0.001    0.012    0.012 event_file_writer.py:196(close)\n",
      "        2    0.001    0.001    0.030    0.015 compat.py:9(corpus_bleu)\n",
      "     5759    0.001    0.000    0.001    0.000 {built-in method unicodedata.category}\n",
      "     6484    0.001    0.000    0.001    0.000 {built-in method builtins.id}\n",
      "     7255    0.001    0.000    0.001    0.000 typing.py:2246(cast)\n",
      "        6    0.001    0.000    0.001    0.000 typing.py:1665(__repr__)\n",
      "       12    0.001    0.000    0.002    0.000 utils.py:264(_screen_shape_linux)\n",
      "        2    0.001    0.001    0.151    0.075 result.py:417(register_key)\n",
      "      579    0.001    0.000    0.001    0.000 enum.py:1243(value)\n",
      "      182    0.001    0.000    0.001    0.000 traitlets.py:1876(_get_trait_default_generator)\n",
      "       68    0.001    0.000    0.001    0.000 generic.py:83(infer_framework_from_repr)\n",
      "        3    0.001    0.000    0.019    0.006 data.py:75(load_dataset)\n",
      "      257    0.001    0.000    0.001    0.000 {built-in method torch._has_compatible_shallow_copy_type}\n",
      "      632    0.001    0.000    0.004    0.000 traitlets.py:1945(trait_metadata)\n",
      "        1    0.001    0.001  277.918  277.918 strategy.py:220(optimizer_step)\n",
      "        2    0.001    0.001    0.004    0.002 combined_loader.py:284(__init__)\n",
      "      167    0.001    0.000    0.001    0.000 logits_process.py:1480(__call__)\n",
      "     2052    0.001    0.000    0.016    0.000 module.py:2171(parameters)\n",
      "      167    0.001    0.000    0.009    0.000 beam_search.py:211(is_done)\n",
      "      579    0.001    0.000    0.002    0.000 enum.py:192(__get__)\n",
      "        7    0.001    0.000    0.001    0.000 result.py:90(_generate_sync_fn)\n",
      "  228/227    0.001    0.000    0.022    0.000 <frozen importlib._bootstrap>:566(module_from_spec)\n",
      "        3    0.001    0.000    0.018    0.006 warnings.py:117(_formatwarnmsg)\n",
      "       17    0.001    0.000    0.001    0.000 results.py:200(__setitem__)\n",
      "       96    0.001    0.000    0.150    0.002 tokenization_utils.py:541(tokenize)\n",
      "      180    0.001    0.000    0.003    0.000 module.py:1421(register_forward_hook)\n",
      "        3    0.001    0.000    0.003    0.001 local.py:291(__init__)\n",
      "     1864    0.001    0.000    0.002    0.000 typing.py:1238(_is_dunder)\n",
      "      144    0.001    0.000    0.001    0.000 trainer.py:1189(lightning_module)\n",
      "        2    0.001    0.001    0.003    0.001 bleu.py:303(_compute_score_from_stats)\n",
      "        2    0.001    0.000    0.003    0.001 _pytree.py:18(_tree_flatten)\n",
      "      666    0.001    0.000    0.001    0.000 ATN.py:75(addState)\n",
      "   210/42    0.001    0.000    0.011    0.000 _dill.py:367(save)\n",
      "  582/143    0.001    0.000    0.189    0.001 <frozen importlib._bootstrap>:1207(_handle_fromlist)\n",
      "     1354    0.001    0.000    0.004    0.000 __init__.py:321(filter)\n",
      "        4    0.001    0.000    0.002    0.001 spec.py:63(__call__)\n",
      "        2    0.001    0.000    0.010    0.005 data_connector.py:299(dataloader)\n",
      "      128    0.001    0.000    0.001    0.000 enum.py:1515(__and__)\n",
      "        5    0.001    0.000    0.001    0.000 threading.py:849(__init__)\n",
      "        2    0.001    0.000    0.013    0.007 arrow_writer.py:381(_build_writer)\n",
      "      237    0.001    0.000    0.002    0.000 <frozen importlib._bootstrap>:173(__exit__)\n",
      "      513    0.001    0.000    0.001    0.000 pytorch.py:451(<genexpr>)\n",
      "        2    0.001    0.000    0.005    0.003 tqdm.py:111(__init__)\n",
      "       48    0.001    0.000    0.226    0.005 tokenization_utils_base.py:2784(__call__)\n",
      "      453    0.001    0.000    0.002    0.000 <frozen importlib._bootstrap_external>:132(_path_split)\n",
      "        2    0.001    0.000    0.001    0.001 _pytree.py:457(_get_node_type)\n",
      "       39    0.001    0.000    0.001    0.000 results.py:136(__new__)\n",
      "    226/9    0.001    0.000    0.467    0.052 <frozen importlib._bootstrap_external>:934(exec_module)\n",
      "      237    0.001    0.000    0.005    0.000 <frozen importlib._bootstrap>:169(__enter__)\n",
      "     1007    0.001    0.000    0.003    0.000 generic.py:461(<genexpr>)\n",
      "        2    0.001    0.000    0.001    0.001 utils.py:1049(_validate_model_class)\n",
      "        1    0.001    0.001    0.001    0.001 profiler.py:176(__init__)\n",
      "      955    0.001    0.000    0.001    0.000 <frozen _collections_abc>:409(__subclasshook__)\n",
      "        2    0.001    0.000    0.001    0.000 _flagvalues.py:88(__init__)\n",
      "        1    0.001    0.001    0.001    0.001 utilities.py:25(_version)\n",
      "        1    0.001    0.001    0.001    0.001 evaluation_loop.py:338(_store_dataloader_outputs)\n",
      "        2    0.001    0.000    0.003    0.001 metric.py:475(_wrap_update)\n",
      "        2    0.001    0.000    0.001    0.001 core.py:5417(postParse)\n",
      "     1024    0.001    0.000    0.001    0.000 generic.py:377(<genexpr>)\n",
      "        2    0.001    0.000    0.059    0.029 result.py:306(to)\n",
      "       32    0.001    0.000    0.001    0.000 __init__.py:2697(version)\n",
      "      195    0.001    0.000    0.038    0.000 tokenization_utils_base.py:204(__init__)\n",
      "      563    0.001    0.000    0.001    0.000 Transition.py:108(__init__)\n",
      "      260    0.001    0.000    0.008    0.000 __init__.py:183(dumps)\n",
      "        4    0.001    0.000    0.001    0.000 {built-in method torch._C._has_storage}\n",
      "        1    0.001    0.001    0.002    0.002 __init__.py:3086(parse_requirements)\n",
      "      260    0.001    0.000    0.006    0.000 encoder.py:183(encode)\n",
      "      226    0.001    0.000    0.154    0.001 <frozen importlib._bootstrap_external>:727(_compile_bytecode)\n",
      "       50    0.001    0.000    0.004    0.000 specifiers.py:749(<genexpr>)\n",
      "       16    0.001    0.000    0.002    0.000 __init__.py:691(add)\n",
      "        1    0.001    0.001    0.002    0.002 anomaly_mode.py:110(__init__)\n",
      "        3    0.001    0.000    0.250    0.083 dataloader.py:673(_next_data)\n",
      "        2    0.001    0.000    0.001    0.000 table.py:2280(table_cast)\n",
      "      124    0.001    0.000    0.001    0.000 {method 'isoformat' of 'datetime.datetime' objects}\n",
      "       94    0.001    0.000    0.001    0.000 {built-in method builtins.sorted}\n",
      "       14    0.001    0.000    0.001    0.000 {method '__subclasses__' of 'type' objects}\n",
      "      900    0.001    0.000    0.001    0.000 util.py:97(is_cjk)\n",
      "      303    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:100(acquire)\n",
      "       19    0.001    0.000    0.001    0.000 specifiers.py:149(operator)\n",
      "       37    0.001    0.000    0.019    0.001 widget.py:570(send_state)\n",
      "     22/8    0.001    0.000    0.039    0.005 widget.py:500(__init__)\n",
      "        3    0.001    0.000    0.001    0.000 {built-in method builtins.eval}\n",
      "        3    0.001    0.000    0.058    0.019 rank_zero.py:72(_warn)\n",
      "     1886    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:244(_verbose_message)\n",
      "       32    0.001    0.000    0.011    0.000 __init__.py:3127(__contains__)\n",
      "       42    0.001    0.000    0.001    0.000 pickle.py:409(__init__)\n",
      "        1    0.001    0.001    0.003    0.003 random.py:9(set_rng_state)\n",
      "      4/3    0.001    0.000    0.005    0.002 spec.py:1252(open)\n",
      "  152/110    0.001    0.000    0.011    0.000 typing.py:476(__getitem__)\n",
      "      171    0.001    0.000    0.031    0.000 modeling_fsmt.py:299(invert_mask)\n",
      "       68    0.001    0.000    0.002    0.000 generic.py:163(is_torch_tensor)\n",
      "      303    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap>:125(release)\n",
      "        1    0.001    0.001    0.008    0.008 pytorch.py:81(__enter__)\n",
      "        3    0.001    0.000    0.001    0.000 pytorch.py:358(_total_steps)\n",
      "        4    0.001    0.000    0.003    0.001 features.py:1693(from_arrow_schema)\n",
      "       81    0.001    0.000    0.001    0.000 _parser.py:222(__init__)\n",
      "       61    0.001    0.000    0.001    0.000 tokenization_fsmt.py:374(<listcomp>)\n",
      "        1    0.001    0.001    0.002    0.002 result.py:246(compute)\n",
      "        2    0.001    0.000    0.001    0.000 thread.py:123(__init__)\n",
      "        2    0.001    0.000    0.001    0.000 {built-in method torch._C._nn._parse_to}\n",
      "       26    0.001    0.000    0.001    0.000 uuid.py:139(__init__)\n",
      "        2    0.001    0.000    0.001    0.000 bleu.py:89(__init__)\n",
      "        2    0.001    0.000    0.069    0.034 module.py:598(_infer_feature_from_example)\n",
      "        3    0.001    0.000    0.017    0.006 warnings.py:40(_custom_format_warning)\n",
      "     2052    0.001    0.000    0.015    0.000 module.py:2196(named_parameters)\n",
      "   182/10    0.001    0.000    0.003    0.000 py_utils.py:204(_asdict_inner)\n",
      "     1140    0.001    0.000    0.001    0.000 __init__.py:1126(__setitem__)\n",
      "        5    0.001    0.000    0.023    0.005 std.py:551(__new__)\n",
      "        2    0.001    0.000    0.001    0.000 eval_frame.py:592(__init__)\n",
      "      666    0.001    0.000    0.001    0.000 ATNState.py:109(__init__)\n",
      "        5    0.001    0.000    0.016    0.003 pathlib.py:504(_from_parts)\n",
      "       44    0.001    0.000    0.001    0.000 <frozen posixpath>:71(join)\n",
      "        5    0.001    0.000    0.001    0.000 distributed_c10d.py:583(WORLD)\n",
      "    69/59    0.001    0.000    0.001    0.000 widget.py:87(_separate_buffers)\n",
      "        2    0.001    0.000    0.011    0.005 _util.py:36(ensure_directory_exists)\n",
      "      293    0.001    0.000    0.001    0.000 {method 'format' of 'str' objects}\n",
      "     1445    0.001    0.000    0.001    0.000 module.py:2224(<lambda>)\n",
      "      194    0.001    0.000    0.001    0.000 {built-in method _struct.pack}\n",
      "        3    0.001    0.000    0.002    0.001 result.py:342(_extract_batch_size)\n",
      "        8    0.001    0.000    0.002    0.000 registry.py:215(get_filesystem_class)\n",
      "      768    0.001    0.000    0.011    0.000 model_summary.py:252(<genexpr>)\n",
      "       83    0.001    0.000    0.006    0.000 threading.py:1118(_wait_for_tstate_lock)\n",
      "      236    0.001    0.000    0.001    0.000 {method 'update' of 'dict' objects}\n",
      "        2    0.001    0.000    0.052    0.026 features.py:1912(encode_example)\n",
      "       31    0.001    0.000    0.001    0.000 {method '__reduce_ex__' of 'object' objects}\n",
      "        2    0.001    0.000    0.009    0.004 base.py:311(_cache_references)\n",
      "       34    0.001    0.000    0.005    0.000 traitlets.py:1282(__new__)\n",
      "      345    0.001    0.000    0.008    0.000 <frozen importlib._bootstrap_external>:159(_path_isfile)\n",
      "       75    0.001    0.000    0.001    0.000 threading.py:1446(current_thread)\n",
      "  301/289    0.001    0.000    0.003    0.000 traitlets.py:720(_validate)\n",
      "   182/98    0.001    0.000    0.036    0.000 traitlets.py:1888(trait_defaults)\n",
      "        2    0.001    0.000    0.001    0.000 profiler.py:262(config)\n",
      "       59    0.001    0.000    0.001    0.000 traitlets.py:194(parse_notifier_name)\n",
      "        5    0.001    0.000    0.001    0.000 {built-in method _thread.start_new_thread}\n",
      "       62    0.001    0.000    0.011    0.000 session.py:690(serialize)\n",
      "        1    0.001    0.001    0.003    0.003 module.py:493(register_buffer)\n",
      "        3    0.001    0.000    0.251    0.084 dataloader.py:626(__next__)\n",
      "        2    0.001    0.000    0.004    0.002 arrow_dataset.py:621(update_metadata_with_features)\n",
      "      177    0.001    0.000    0.001    0.000 import_utils.py:290(is_torch_available)\n",
      "       60    0.001    0.000    0.001    0.000 _dill.py:123(<genexpr>)\n",
      "       59    0.001    0.000    0.002    0.000 widget.py:132(_remove_buffers)\n",
      "        3    0.001    0.000    0.001    0.000 {built-in method torch.numel}\n",
      "        1    0.001    0.001    0.008    0.008 evaluation_loop.py:300(_on_evaluation_model_train)\n",
      "        8    0.001    0.000    0.001    0.000 table.py:1840(array_cast)\n",
      "        3    0.001    0.000    0.001    0.000 grad_mode.py:192(__enter__)\n",
      "        3    0.001    0.000    0.004    0.001 local.py:176(_open)\n",
      "       64    0.001    0.000    0.001    0.000 tokenization_utils_base.py:1118(additional_special_tokens)\n",
      "      265    0.001    0.000    0.002    0.000 grad_mode.py:79(__enter__)\n",
      "        4    0.001    0.000    0.001    0.000 utils.py:306(tokenize)\n",
      "      534    0.001    0.000    0.002    0.000 grad_mode.py:183(__init__)\n",
      "        1    0.001    0.001    0.001    0.001 anomaly_mode.py:118(__exit__)\n",
      "       96    0.001    0.000    0.225    0.002 tokenization_utils_base.py:2873(_call_one)\n",
      "       24    0.001    0.000    0.001    0.000 py_utils.py:326(<genexpr>)\n",
      "        3    0.001    0.000    0.001    0.000 fx_validator.py:166(get_default_logging_levels)\n",
      "       22    0.001    0.000    0.001    0.000 module.py:112(features)\n",
      "        1    0.001    0.001    0.003    0.003 specifiers.py:621(__init__)\n",
      "       96    0.001    0.000    0.001    0.000 tokenization_utils.py:518(num_special_tokens_to_add)\n",
      "      124    0.001    0.000    0.002    0.000 jsonutil.py:107(json_default)\n",
      "       12    0.001    0.000    0.001    0.000 table.py:420(column_names)\n",
      "  233/104    0.001    0.000    0.001    0.000 _parser.py:172(getwidth)\n",
      "        2    0.001    0.000    0.002    0.001 bleu.py:210(compute_bleu)\n",
      "       22    0.001    0.000    0.016    0.001 ipkernel.py:48(_create_comm)\n",
      "        4    0.001    0.000    0.001    0.000 features.py:1407(generate_from_arrow_type)\n",
      "        4    0.001    0.000    0.001    0.000 iostream.py:505(parent_header)\n",
      "        1    0.001    0.001  278.019  278.019 fit_loop.py:350(advance)\n",
      "        2    0.001    0.000    0.001    0.000 {built-in method numpy.asarray}\n",
      "       64    0.001    0.000    0.007    0.000 bleu.py:294(_preprocess_segment)\n",
      "       13    0.001    0.000    0.001    0.000 pathlib.py:536(__str__)\n",
      "        1    0.001    0.001  277.905  277.905 automatic.py:142(__call__)\n",
      "      963    0.001    0.000    0.014    0.000 <frozen importlib._bootstrap_external>:140(_path_stat)\n",
      "        3    0.001    0.000    0.238    0.079 fetch.py:51(<listcomp>)\n",
      "      833    0.001    0.000    0.001    0.000 {method '__contains__' of 'frozenset' objects}\n",
      "      133    0.001    0.000    0.001    0.000 contextlib.py:104(__init__)\n",
      "      868    0.001    0.000    0.001    0.000 _parser.py:231(__next)\n",
      "        1    0.001    0.001    0.002    0.002 precision.py:45(pre_backward)\n",
      "      128    0.001    0.000    0.001    0.000 _compiler.py:568(isstring)\n",
      "        2    0.001    0.000    0.003    0.002 formatters.py:907(__call__)\n",
      "     4251    0.001    0.000    0.001    0.000 {method 'rstrip' of 'str' objects}\n",
      "      995    0.001    0.000    0.001    0.000 _parser.py:162(__getitem__)\n",
      "        3    0.001    0.000    0.001    0.000 {built-in method torch.is_floating_point}\n",
      "     2024    0.001    0.000    0.001    0.000 {method 'endswith' of 'str' objects}\n",
      "      512    0.001    0.000    0.006    0.000 model_summary.py:142(<genexpr>)\n",
      "        4    0.001    0.000    0.009    0.002 iostream.py:577(_schedule_flush)\n",
      "        1    0.001    0.001    0.009    0.009 tensorboard.py:241(_get_next_version)\n",
      "       26    0.001    0.000    0.001    0.000 enum.py:825(__setattr__)\n",
      "        1    0.001    0.001    0.002    0.002 progress_bar.py:210(get_standard_metrics)\n",
      "        1    0.001    0.001    0.003    0.003 configuration_validator.py:25(_verify_loop_configurations)\n",
      "        2    0.001    0.000    0.021    0.011 std.py:89(__init__)\n",
      "        2    0.001    0.000    0.001    0.000 {method 'cumsum' of 'numpy.ndarray' objects}\n",
      "       94    0.001    0.000    0.001    0.000 threading.py:568(is_set)\n",
      "      325    0.001    0.000    0.003    0.000 <frozen importlib._bootstrap_external>:1421(_path_importer_cache)\n",
      "        1    0.001    0.001  937.101  937.101 trainer.py:548(_fit_impl)\n",
      "     2368    0.001    0.000    0.001    0.000 {method 'group' of 're.Match' objects}\n",
      "        4    0.001    0.000    0.001    0.000 {method 'untyped_storage' of 'torch._C.TensorBase' objects}\n",
      "      160    0.001    0.000    0.001    0.000 beam_search.py:360(<lambda>)\n",
      "        1    0.001    0.001    0.013    0.013 loss.py:1172(__init__)\n",
      "        2    0.001    0.000    0.001    0.000 _api.py:82(__new__)\n",
      "        8    0.001    0.000    0.010    0.001 tensorboard.py:124(version)\n",
      "        2    0.001    0.000    0.001    0.000 dataloader.py:74(create_fetcher)\n",
      "       19    0.001    0.000    0.001    0.000 core.py:757(preParse)\n",
      "        2    0.001    0.000    0.001    0.000 {built-in method torch._C._is_tracing}\n",
      "        2    0.001    0.000    0.004    0.002 fingerprint.py:450(wrapper)\n",
      "        1    0.001    0.001  277.924  277.924 automatic.py:243(_optimizer_step)\n",
      "        1    0.001    0.001    0.001    0.001 __init__.py:530(yield_lines)\n",
      "       16    0.001    0.000    0.001    0.000 version.py:203(<genexpr>)\n",
      "    39/38    0.001    0.000    0.002    0.000 results.py:159(__init__)\n",
      "       22    0.001    0.000    0.001    0.000 inspect.py:2892(apply_defaults)\n",
      "        2    0.001    0.000    0.023    0.012 widget_float.py:23(__init__)\n",
      "        1    0.001    0.001    0.001    0.001 random.py:170(setstate)\n",
      "        1    0.001    0.001  658.364  658.364 utilities.py:158(_decorator)\n",
      "       32    0.001    0.000    0.001    0.000 _tensor.py:996(__len__)\n",
      "        4    0.001    0.000    0.001    0.000 config.py:99(apply_config)\n",
      "        3    0.001    0.000    0.082    0.027 tqdm_progress.py:40(__init__)\n",
      "        3    0.001    0.000    0.001    0.000 {method 'get_state' of 'numpy.random.mtrand.RandomState' objects}\n",
      "      265    0.001    0.000    0.001    0.000 grad_mode.py:74(__init__)\n",
      "        2    0.001    0.000    0.003    0.002 bleu.py:318(_aggregate_and_compute)\n",
      "        1    0.001    0.001    0.001    0.001 _reduction.py:7(get_enum)\n",
      "       60    0.001    0.000    0.001    0.000 _compiler.py:214(_compile_charset)\n",
      "        1    0.001    0.001    0.013    0.013 event_file_writer.py:127(close)\n",
      "        3    0.001    0.000    0.001    0.000 fx_validator.py:177(check_logging_levels)\n",
      "        2    0.001    0.000    0.004    0.002 utils.py:1230(_prepare_generation_config)\n",
      "       12    0.001    0.000    0.001    0.000 {built-in method fcntl.ioctl}\n",
      "        8    0.001    0.000    0.001    0.000 trainer.py:1478(current_epoch)\n",
      "        3    0.001    0.000    0.001    0.000 _weakrefset.py:39(_remove)\n",
      "      227    0.001    0.000    0.002    0.000 <frozen importlib._bootstrap_external>:1599(_get_spec)\n",
      "        1    0.001    0.001    0.001    0.001 strategy.py:583(on_exception)\n",
      "     2054    0.001    0.000    0.001    0.000 {method 'lower' of 'str' objects}\n",
      "        1    0.001    0.001    0.007    0.007 data.py:62(train_dataloader)\n",
      "      248    0.001    0.000    0.007    0.000 session.py:92(json_packer)\n",
      "        6    0.001    0.000    0.001    0.000 base.py:125(__instancecheck__)\n",
      "        4    0.001    0.000    0.001    0.000 core.py:2854(parseImpl)\n",
      "        3    0.001    0.000    0.006    0.002 version.py:1(<module>)\n",
      "    22/16    0.001    0.000    0.001    0.000 widget.py:48(_widget_to_json)\n",
      "        2    0.001    0.000    0.001    0.000 {built-in method torch.set_anomaly_enabled}\n",
      "    40/38    0.001    0.000    0.001    0.000 dataloader.py:417(__setattr__)\n",
      "     14/8    0.001    0.000    0.005    0.001 _dill.py:72(_batch_setitems)\n",
      "        2    0.001    0.000    0.001    0.000 tqdm_progress.py:173(is_disabled)\n",
      "        1    0.001    0.001    0.001    0.001 std.py:1262(close)\n",
      "        3    0.001    0.000    0.001    0.000 training_epoch_loop.py:99(global_step)\n",
      "       14    0.001    0.000    0.026    0.002 trait_types.py:408(make_dynamic_default)\n",
      "       19    0.001    0.000    0.002    0.000 enum.py:241(__set_name__)\n",
      "        2    0.001    0.000    0.170    0.085 combined_loader.py:128(__next__)\n",
      "        1    0.001    0.001    0.005    0.005 pytorch.py:526(_create_profiler)\n",
      "        3    0.001    0.000    0.001    0.000 threading.py:1044(_stop)\n",
      "        1    0.001    0.001    0.001    0.001 spec.py:1512(listdir)\n",
      "        2    0.001    0.000    0.001    0.000 fingerprint.py:360(<listcomp>)\n",
      "        9    0.001    0.000    0.001    0.000 dtypes.py:639(as_dtype)\n",
      "    35/23    0.001    0.000    0.004    0.000 copy.py:227(_deepcopy_dict)\n",
      "        1    0.001    0.001    0.001    0.001 specifiers.py:95(__init__)\n",
      "       12    0.001    0.000    0.001    0.000 py_utils.py:296(unique_values)\n",
      "        3    0.001    0.000    0.001    0.000 {method 'set_state' of 'numpy.random.mtrand.RandomState' objects}\n",
      "      722    0.001    0.000    0.001    0.000 module.py:2286(named_children)\n",
      "        2    0.001    0.000    0.023    0.012 data_connector.py:330(_request_dataloader)\n",
      "       20    0.001    0.000    0.001    0.000 threading.py:279(_is_owned)\n",
      "      8/6    0.001    0.000    0.001    0.000 copy.py:210(_deepcopy_tuple)\n",
      "      801    0.001    0.000    0.001    0.000 {built-in method torch.is_grad_enabled}\n",
      "        2    0.001    0.000    0.008    0.004 apply_func.py:113(convert_tensors_to_scalars)\n",
      "        3    0.001    0.000    0.001    0.000 {method 'getvalue' of '_io.StringIO' objects}\n",
      "      108    0.001    0.000    0.001    0.000 typing.py:1662(__hash__)\n",
      "       12    0.001    0.000    0.001    0.000 single_device.py:71(root_device)\n",
      "      384    0.001    0.000    0.007    0.000 <frozen importlib._bootstrap_external>:150(_path_is_mode_type)\n",
      "        5    0.001    0.000    0.001    0.000 configuration_validator.py:158(<genexpr>)\n",
      "       10    0.001    0.000    0.002    0.000 pathlib.py:546(__fspath__)\n",
      "       42    0.001    0.000    0.025    0.001 fingerprint.py:226(hash)\n",
      "       16    0.001    0.000    0.001    0.000 __init__.py:12(escape)\n",
      "        2    0.001    0.000    0.001    0.000 arrow_dataset.py:164(__init__)\n",
      "        4    0.001    0.000    0.001    0.000 fingerprint.py:210(__init__)\n",
      "        6    0.001    0.000    0.001    0.000 gfile.py:812(flush)\n",
      "        2    0.001    0.000    0.009    0.004 _base.py:583(map)\n",
      "   591/20    0.001    0.000    0.408    0.020 <frozen importlib._bootstrap>:233(_call_with_frames_removed)\n",
      "       46    0.001    0.000    0.001    0.000 enum_type_wrapper.py:102(<listcomp>)\n",
      "        4    0.001    0.000    0.011    0.003 notebook.py:251(__iter__)\n",
      "        1    0.001    0.001    0.001    0.001 local.py:64(<listcomp>)\n",
      "       10    0.001    0.000    0.001    0.000 __init__.py:228(_acquireLock)\n",
      "     1551    0.001    0.000    0.001    0.000 inspect.py:2739(name)\n",
      "        1    0.001    0.001    0.001    0.001 <string>:2(__eq__)\n",
      "        2    0.001    0.000    0.006    0.003 combined_loader.py:347(__iter__)\n",
      "        4    0.001    0.000    0.001    0.000 core.py:505(split_protocol)\n",
      "      4/2    0.001    0.000    0.008    0.004 data.py:287(wrapper)\n",
      "        4    0.001    0.000    0.001    0.000 import_utils.py:635(is_torchdynamo_compiling)\n",
      "      317    0.001    0.000    0.004    0.000 dataclasses.py:1256(is_dataclass)\n",
      "        1    0.001    0.001    0.001    0.001 _ops.py:42(__init__)\n",
      "        3    0.001    0.000    0.006    0.002 result.py:264(forward)\n",
      "        4    0.000    0.000    0.001    0.000 concurrent.py:15(ensure_lock)\n",
      "        2    0.000    0.000    0.005    0.003 zmqshell.py:64(_flush_streams)\n",
      "       46    0.000    0.000    0.004    0.000 functools.py:35(update_wrapper)\n",
      "        1    0.000    0.000    0.007    0.007 profiler.py:627(start)\n",
      "        1    0.000    0.000    0.004    0.004 widget.py:558(close)\n",
      "        3    0.000    0.000    0.001    0.000 result.py:148(sync)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._get_operation_overload}\n",
      "        1    0.000    0.000    0.000    0.000 configuration_utils.py:385(use_return_dict)\n",
      "       68    0.000    0.000    0.000    0.000 types.py:120(is_floating)\n",
      "        1    0.000    0.000    0.001    0.001 std.py:1399(set_postfix)\n",
      "        1    0.000    0.000    0.001    0.001 modeling_fsmt.py:396(make_padding_mask)\n",
      "        1    0.000    0.000    0.003    0.003 progress_bar.py:177(get_metrics)\n",
      "        3    0.000    0.000    0.000    0.000 {method 'groupdict' of 're.Match' objects}\n",
      "       11    0.000    0.000    0.000    0.000 pathlib.py:523(_format_parsed_parts)\n",
      "       67    0.000    0.000    0.001    0.000 {built-in method builtins.delattr}\n",
      "        2    0.000    0.000    0.001    0.000 functools.py:818(dispatch)\n",
      "       23    0.000    0.000    0.000    0.000 _compiler.py:465(_get_charset_prefix)\n",
      "      167    0.000    0.000    0.000    0.000 utils.py:621(_extract_past_from_model_output)\n",
      "        2    0.000    0.000    0.001    0.000 result.py:256(reset)\n",
      "        4    0.000    0.000    0.038    0.010 call.py:165(_call_lightning_datamodule_hook)\n",
      "       62    0.000    0.000    0.003    0.000 session.py:675(sign)\n",
      "       18    0.000    0.000    0.000    0.000 specifiers.py:138(_get_operator)\n",
      "       14    0.000    0.000    0.001    0.000 utils.py:70(__getattr__)\n",
      "        2    0.000    0.000    0.002    0.001 _pytree.py:6(_is_leaf_or_primitive_container)\n",
      "        2    0.000    0.000    0.002    0.001 functools.py:904(wrapper)\n",
      "     1531    0.000    0.000    0.000    0.000 {method 'rpartition' of 'str' objects}\n",
      "      221    0.000    0.000    0.000    0.000 trainer.py:1136(strategy)\n",
      "      256    0.000    0.000    0.001    0.000 typing.py:245(_collect_parameters)\n",
      "       43    0.000    0.000    0.000    0.000 enum.py:1224(__hash__)\n",
      "        2    0.000    0.000    0.000    0.000 __init__.py:50(is_remote_filesystem)\n",
      "        1    0.000    0.000    0.000    0.000 {function Random.setstate at 0x10f54d8a0}\n",
      "        1    0.000    0.000    0.001    0.001 fit_loop.py:189(skip)\n",
      "      808    0.000    0.000    0.000    0.000 Transition.py:59(__init__)\n",
      "      493    0.000    0.000    0.002    0.000 ATNDeserializer.py:453(<lambda>)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:549(_)\n",
      "        4    0.000    0.000    0.001    0.000 core.py:287(wrapper)\n",
      "        1    0.000    0.000    0.006    0.006 pytorch.py:512(_create_profilers)\n",
      "       66    0.000    0.000    0.000    0.000 {built-in method _collections._count_elements}\n",
      "        4    0.000    0.000    0.000    0.000 features.py:1714(<dictcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 tqdm_progress.py:46(format_num)\n",
      "        1    0.000    0.000    0.000    0.000 data_connector.py:148(attach_datamodule)\n",
      "       36    0.000    0.000    0.650    0.018 __init__.py:1(<module>)\n",
      "      118    0.000    0.000    0.001    0.000 pickle.py:851(save_str)\n",
      "        4    0.000    0.000    0.000    0.000 results.py:436(<listcomp>)\n",
      "      257    0.000    0.000    0.000    0.000 {method 'is_floating_point' of 'torch._C.TensorBase' objects}\n",
      "        2    0.000    0.000    0.001    0.000 ATNDeserializer.py:156(readRules)\n",
      "      337    0.000    0.000    0.001    0.000 <frozen importlib._bootstrap>:405(parent)\n",
      "        1    0.000    0.000    0.001    0.001 version.py:301(Version)\n",
      "      906    0.000    0.000    0.001    0.000 <frozen importlib._bootstrap_external>:134(<genexpr>)\n",
      "       66    0.000    0.000    0.000    0.000 copy.py:243(_keep_alive)\n",
      "      107    0.000    0.000    0.030    0.000 traitlets.py:690(set)\n",
      "        1    0.000    0.000    0.019    0.019 evaluation_loop.py:309(_on_evaluation_end)\n",
      "      968    0.000    0.000    0.001    0.000 <frozen importlib._bootstrap>:1030(__exit__)\n",
      "        4    0.000    0.000    0.001    0.000 pytorch.py:192(__call__)\n",
      "        1    0.000    0.000    0.001    0.001 compile.py:119(_maybe_unwrap_optimized)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:526(_nonblank)\n",
      "        1    0.000    0.000    0.002    0.002 _ops.py:704(__getattr__)\n",
      "      179    0.000    0.000    0.003    0.000 module.py:1357(register_forward_pre_hook)\n",
      "      968    0.000    0.000    0.001    0.000 <frozen importlib._bootstrap>:1026(__enter__)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'nbytes' of 'torch._C.StorageBase' objects}\n",
      "       62    0.000    0.000    0.000    0.000 {method 'copy' of '_hashlib.HMAC' objects}\n",
      "        1    0.000    0.000    0.000    0.000 base_comm.py:63(__del__)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._get_schema}\n",
      "        2    0.000    0.000    0.000    0.000 thread.py:47(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 logger_connector.py:190(epoch_end_reached)\n",
      "       16    0.000    0.000    0.000    0.000 {built-in method builtins.compile}\n",
      "        3    0.000    0.000    0.002    0.001 module.py:343(_apply_batch_transfer_handler)\n",
      "      384    0.000    0.000    0.001    0.000 tokenization_utils_base.py:1215(pad_token_id)\n",
      "        1    0.000    0.000    0.000    0.000 model_checkpoint.py:414(_should_skip_saving_checkpoint)\n",
      "        3    0.000    0.000    0.000    0.000 _pytree.py:540(tree_unflatten)\n",
      "        6    0.000    0.000    0.001    0.000 evaluation_loop.py:77(num_dataloaders)\n",
      "     2023    0.000    0.000    0.000    0.000 {function _ParameterMeta.__instancecheck__ at 0x11d2aede0}\n",
      "        1    0.000    0.000    0.005    0.005 histogram_pb2.py:1(<module>)\n",
      "       64    0.000    0.000    0.000    0.000 {built-in method now}\n",
      "       96    0.000    0.000    0.001    0.000 tokenize.py:409(escape_xml)\n",
      "        1    0.000    0.000    0.018    0.018 callback_connector.py:157(_attach_model_callbacks)\n",
      "        4    0.000    0.000    0.000    0.000 tqdm_progress.py:169(is_enabled)\n",
      "    60/12    0.000    0.000    0.003    0.000 configurable.py:138(_find_my_config)\n",
      "     1666    0.000    0.000    0.000    0.000 ATNDeserializer.py:425(checkCondition)\n",
      "        3    0.000    0.000    0.000    0.000 strategy.py:102(optimizers)\n",
      "      234    0.000    0.000    0.001    0.000 <frozen importlib._bootstrap>:198(cb)\n",
      "      192    0.000    0.000    0.032    0.000 tokenization_utils_base.py:718(as_tensor)\n",
      "      508    0.000    0.000    0.000    0.000 {built-in method _thread.allocate_lock}\n",
      "        2    0.000    0.000    0.006    0.003 widget_box.py:62(__init__)\n",
      "      7/5    0.000    0.000    0.001    0.000 <frozen importlib._bootstrap_external>:1297(_recalculate)\n",
      "      120    0.000    0.000    0.001    0.000 configurable.py:132(<listcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 _pytree.py:446(_is_namedtuple_instance)\n",
      "        2    0.000    0.000    0.003    0.001 utils.py:509(_prepare_decoder_input_ids_for_generation)\n",
      "      436    0.000    0.000    0.000    0.000 inspect.py:378(isfunction)\n",
      "       96    0.000    0.000    0.025    0.000 tokenization_fsmt.py:245(moses_tokenize)\n",
      "      133    0.000    0.000    0.002    0.000 contextlib.py:287(helper)\n",
      "      503    0.000    0.000    0.000    0.000 __init__.py:1119(__getitem__)\n",
      "     1336    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}\n",
      "      143    0.000    0.000    0.005    0.000 {built-in method builtins.any}\n",
      "       68    0.000    0.000    0.000    0.000 generic.py:157(_is_torch)\n",
      "       96    0.000    0.000    0.172    0.002 tokenization_utils.py:684(get_input_ids)\n",
      "      252    0.000    0.000    0.001    0.000 pickle.py:217(commit_frame)\n",
      "      318    0.000    0.000    0.001    0.000 ATNState.py:149(__init__)\n",
      "       42    0.000    0.000    0.017    0.000 pickle.py:476(dump)\n",
      "      236    0.000    0.000    0.053    0.000 <frozen importlib._bootstrap_external>:1496(find_spec)\n",
      "      226    0.000    0.000    0.001    0.000 <frozen importlib._bootstrap_external>:675(_validate_timestamp_pyc)\n",
      "        2    0.000    0.000    0.000    0.000 dataloader.py:486(check_worker_number_rationality)\n",
      "       62    0.000    0.000    0.001    0.000 hmac.py:122(copy)\n",
      "     1505    0.000    0.000    0.000    0.000 {built-in method _imp.release_lock}\n",
      "       64    0.000    0.000    0.009    0.000 _parser.py:970(parse)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'is_conj' of 'torch._C.TensorBase' objects}\n",
      "       96    0.000    0.000    0.033    0.000 tokenization_fsmt.py:259(moses_pipeline)\n",
      "       16    0.000    0.000    0.000    0.000 combined_loader.py:308(flattened)\n",
      "        7    0.000    0.000    0.001    0.000 plugin_data_pb2.py:1(<module>)\n",
      "      720    0.000    0.000    0.001    0.000 module.py:2277(children)\n",
      "       62    0.000    0.000    0.002    0.000 session.py:649(msg)\n",
      "      638    0.000    0.000    0.001    0.000 _parser.py:252(get)\n",
      "     1591    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\n",
      "      167    0.000    0.000    0.000    0.000 modeling_fsmt.py:1262(prepare_inputs_for_generation)\n",
      "      456    0.000    0.000    0.001    0.000 loader.py:219(_is_section_key)\n",
      "      672    0.000    0.000    0.000    0.000 tokenization_utils_base.py:1083(pad_token)\n",
      "      453    0.000    0.000    0.007    0.000 <frozen importlib._bootstrap>:392(cached)\n",
      "      226    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:599(_check_name_wrapper)\n",
      "       10    0.000    0.000    0.000    0.000 {built-in method posix.getcwd}\n",
      "        3    0.000    0.000    0.002    0.001 __init__.py:348(namedtuple)\n",
      "     1505    0.000    0.000    0.000    0.000 {built-in method _imp.acquire_lock}\n",
      "    180/1    0.000    0.000    0.002    0.002 module.py:2375(train)\n",
      "        1    0.000    0.000    0.001    0.001 writer.py:181(__init__)\n",
      "      109    0.000    0.000    0.001    0.000 typing.py:311(_remove_dups_flatten)\n",
      "        1    0.000    0.000    0.004    0.004 omegaconf.py:818(_create_impl)\n",
      "        3    0.000    0.000    0.000    0.000 {method 'close' of '_io.BufferedWriter' objects}\n",
      "       62    0.000    0.000    0.000    0.000 {method 'hexdigest' of '_hashlib.HMAC' objects}\n",
      "       22    0.000    0.000    0.001    0.000 inspect.py:3076(_bind)\n",
      "      230    0.000    0.000    0.002    0.000 typing.py:1251(__init__)\n",
      "        3    0.000    0.000    0.000    0.000 fit_loop.py:140(_results)\n",
      "       18    0.000    0.000    0.020    0.001 {built-in method builtins.sum}\n",
      "      315    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:67(_relax_case)\n",
      "      267    0.000    0.000    0.000    0.000 _contextlib.py:149(__new__)\n",
      "        4    0.000    0.000    0.000    0.000 formatting.py:81(_query_table)\n",
      "       96    0.000    0.000    0.000    0.000 tokenization_utils.py:246(cut_text)\n",
      "       19    0.000    0.000    0.000    0.000 threading.py:236(__init__)\n",
      "       88    0.000    0.000    0.028    0.000 traitlets.py:1514(_notify_trait)\n",
      "      231    0.000    0.000    0.000    0.000 {method 'values' of 'mappingproxy' objects}\n",
      "       96    0.000    0.000    0.001    0.000 traitlets.py:729(_cross_validate)\n",
      "        1    0.000    0.000    0.004    0.004 module.py:2438(zero_grad)\n",
      "      854    0.000    0.000    0.000    0.000 {method 'isidentifier' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'expand' of 'torch._C.TensorBase' objects}\n",
      "      582    0.000    0.000    0.000    0.000 {method 'encode' of 'str' objects}\n",
      "       67    0.000    0.000    0.001    0.000 ATNState.py:165(__init__)\n",
      "      456    0.000    0.000    0.001    0.000 loader.py:311(_has_section)\n",
      "      234    0.000    0.000    0.001    0.000 <frozen importlib._bootstrap>:71(__init__)\n",
      "      102    0.000    0.000    0.001    0.000 Transition.py:79(makeLabel)\n",
      "       62    0.000    0.000    0.001    0.000 session.py:600(msg_id)\n",
      "        1    0.000    0.000    0.020    0.020 synchronize.py:50(__init__)\n",
      "        3    0.000    0.000    0.015    0.005 dataclasses.py:884(_process_class)\n",
      "      318    0.000    0.000    0.001    0.000 ATNDeserializer.py:482(<lambda>)\n",
      "       34    0.000    0.000    0.004    0.000 traitlets.py:1325(setup_instance)\n",
      "       18    0.000    0.000    0.001    0.000 callback.py:48(_generate_state_key)\n",
      "      226    0.000    0.000    0.002    0.000 <frozen importlib._bootstrap_external>:1146(path_stats)\n",
      "       60    0.000    0.000    0.001    0.000 kernelbase.py:655(get_parent)\n",
      "      101    0.000    0.000    0.031    0.000 traitlets.py:709(__set__)\n",
      "       75    0.000    0.000    0.000    0.000 iostream.py:138(_event_pipe)\n",
      "      288    0.000    0.000    0.001    0.000 tokenization_utils_base.py:1205(sep_token_id)\n",
      "      254    0.000    0.000    0.003    0.000 model_summary.py:256(<genexpr>)\n",
      "      240    0.000    0.000    0.002    0.000 formatters.py:552(_in_deferred_types)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method posix.remove}\n",
      "       10    0.000    0.000    0.005    0.001 std.py:1443(format_dict)\n",
      "       62    0.000    0.000    0.006    0.000 tokenizer_re.py:27(__call__)\n",
      "       30    0.000    0.000    0.000    0.000 emitter.py:120(need_more_events)\n",
      "       11    0.000    0.000    0.002    0.000 apply_func.py:91(batch_to)\n",
      "     22/8    0.000    0.000    0.037    0.005 widget.py:522(open)\n",
      "      741    0.000    0.000    0.000    0.000 typing.py:1358(__eq__)\n",
      "      468    0.000    0.000    0.000    0.000 loader.py:298(__contains__)\n",
      "      360    0.000    0.000    0.000    0.000 _parser.py:158(__len__)\n",
      "      248    0.000    0.000    0.000    0.000 {method 'update' of '_hashlib.HMAC' objects}\n",
      "       59    0.000    0.000    0.003    0.000 typing.py:1556(__getitem__)\n",
      "       34    0.000    0.000    0.001    0.000 traitlets.py:3481(validate)\n",
      "        1    0.000    0.000    0.000    0.000 optimizer.py:858(add_param_group)\n",
      "       47    0.000    0.000    0.001    0.000 typing.py:1796(__class_getitem__)\n",
      "      384    0.000    0.000    0.000    0.000 tokenization_utils_base.py:243(__getitem__)\n",
      "       29    0.000    0.000    0.000    0.000 <frozen os>:674(__getitem__)\n",
      "      257    0.000    0.000    0.001    0.000 module.py:804(compute_should_use_set_data)\n",
      "       23    0.000    0.000    0.000    0.000 widget.py:537(_comm_changed)\n",
      "       66    0.000    0.000    0.001    0.000 __init__.py:585(__init__)\n",
      "      793    0.000    0.000    0.000    0.000 traitlets.py:225(__call__)\n",
      "        3    0.000    0.000    0.000    0.000 profiler.py:1000(increment_step)\n",
      "       62    0.000    0.000    0.006    0.000 tokenizer_13a.py:14(__call__)\n",
      "        1    0.000    0.000    0.003    0.003 saved_object_graph_pb2.py:1(<module>)\n",
      "       37    0.000    0.000    0.001    0.000 widget.py:739(_should_send_property)\n",
      "       62    0.000    0.000    0.006    0.000 iostream.py:271(send_multipart)\n",
      "      203    0.000    0.000    0.000    0.000 inspect.py:755(_is_wrapper)\n",
      "        7    0.000    0.000    0.000    0.000 emitter.py:626(analyze_scalar)\n",
      "        2    0.000    0.000    0.002    0.001 arrow_writer.py:592(finalize)\n",
      "      500    0.000    0.000    0.000    0.000 inspect.py:3032(parameters)\n",
      "        2    0.000    0.000    0.001    0.000 result.py:273(_wrap_compute)\n",
      "      474    0.000    0.000    0.001    0.000 typing.py:159(_type_convert)\n",
      "      227    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:48(_new_module)\n",
      "        1    0.000    0.000    0.000    0.000 cost_graph_pb2.py:1(<module>)\n",
      "   154/84    0.000    0.000    0.026    0.000 traitlets.py:592(default)\n",
      "       64    0.000    0.000    0.000    0.000 tokenization_utils_base.py:3858(clean_up_tokenization)\n",
      "      814    0.000    0.000    0.000    0.000 {built-in method posix.fspath}\n",
      "     12/3    0.000    0.000    0.005    0.002 collate.py:88(collate)\n",
      "       96    0.000    0.000    0.001    0.000 tokenize.py:345(replace_multidots)\n",
      "        4    0.000    0.000    0.000    0.000 features.py:52(_arrow_to_datasets_dtype)\n",
      "      540    0.000    0.000    0.000    0.000 hooks.py:32(<genexpr>)\n",
      "        2    0.000    0.000    0.021    0.011 base.py:401(corpus_score)\n",
      "       37    0.000    0.000    0.002    0.000 <frozen importlib._bootstrap_external>:1408(_path_hooks)\n",
      "      236    0.000    0.000    0.000    0.000 __init__.py:89(find_spec)\n",
      "        2    0.000    0.000    0.068    0.034 _utils.py:1(<module>)\n",
      "        4    0.000    0.000    0.002    0.000 {built-in method posix.mkdir}\n",
      "      364    0.000    0.000    0.000    0.000 pickle.py:241(write)\n",
      "       65    0.000    0.000    0.000    0.000 version.py:444(_cmpkey)\n",
      "        2    0.000    0.000    0.000    0.000 utils.py:758(_get_logits_processor)\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method torch._C._dynamo.eval_frame.set_eval_frame}\n",
      "       42    0.000    0.000    0.025    0.001 fingerprint.py:230(update)\n",
      "       34    0.000    0.000    0.001    0.000 traitlets.py:1339(__init__)\n",
      "        9    0.000    0.000    0.004    0.000 collate.py:155(collate_tensor_fn)\n",
      "      493    0.000    0.000    0.000    0.000 {method 'rfind' of 'str' objects}\n",
      "      133    0.000    0.000    0.000    0.000 traitlets.py:2307(validate)\n",
      "  262/255    0.000    0.000    0.000    0.000 typing.py:1364(__hash__)\n",
      "      236    0.000    0.000    0.001    0.000 <frozen importlib._bootstrap>:920(find_spec)\n",
      "       96    0.000    0.000    0.022    0.000 tokenization_fsmt.py:239(moses_punct_norm)\n",
      "      239    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:357(__init__)\n",
      "        3    0.000    0.000    0.001    0.000 result.py:57(__post_init__)\n",
      "       16    0.000    0.000    0.019    0.001 threading.py:288(wait)\n",
      "       37    0.000    0.000    0.016    0.000 widget.py:822(_send)\n",
      "        2    0.000    0.000    0.000    0.000 ATNDeserializer.py:362(markPrecedenceDecisions)\n",
      "       37    0.000    0.000    0.001    0.000 <frozen zipimport>:64(__init__)\n",
      "       90    0.000    0.000    0.006    0.000 traitlets.py:1525(notify_change)\n",
      "        4    0.000    0.000    0.001    0.000 generic.py:122(is_tensor)\n",
      "      308    0.000    0.000    0.001    0.000 corpus.py:122(words)\n",
      "     16/8    0.000    0.000    0.003    0.000 table.py:1800(wrapper)\n",
      "       49    0.000    0.000    0.000    0.000 enum.py:364(__setitem__)\n",
      "        2    0.000    0.000    0.016    0.008 base.py:348(_extract_corpus_statistics)\n",
      "      192    0.000    0.000    0.001    0.000 tokenization_fsmt.py:380(build_inputs_with_special_tokens)\n",
      "       17    0.000    0.000    0.000    0.000 _parser.py:997(parse_template)\n",
      "      186    0.000    0.000    0.001    0.000 py_utils.py:200(_is_dataclass_instance)\n",
      "    71/63    0.000    0.000    0.000    0.000 _compiler.py:434(_get_literal_prefix)\n",
      "      162    0.000    0.000    0.000    0.000 IntervalSet.py:38(addRange)\n",
      "      250    0.000    0.000    0.000    0.000 encoder.py:105(__init__)\n",
      "       62    0.000    0.000    0.006    0.000 iostream.py:343(send_multipart)\n",
      "       62    0.000    0.000    0.002    0.000 session.py:645(msg_header)\n",
      "      236    0.000    0.000    0.000    0.000 {built-in method _imp.is_builtin}\n",
      "        1    0.000    0.000    0.245    0.245 call.py:74(_call_setup_hook)\n",
      "       96    0.000    0.000    0.001    0.000 tokenization_fsmt.py:434(create_token_type_ids_from_sequences)\n",
      "        8    0.000    0.000    0.001    0.000 local.py:68(info)\n",
      "       64    0.000    0.000    0.014    0.000 _compiler.py:571(_code)\n",
      "        2    0.000    0.000    0.013    0.007 data_connector.py:485(_process_dataloader)\n",
      "        3    0.000    0.000    0.000    0.000 result.py:127(_parse_reduce_fx)\n",
      "      102    0.000    0.000    0.001    0.000 Transition.py:73(__init__)\n",
      "       33    0.000    0.000    0.000    0.000 beam_search.py:965(<listcomp>)\n",
      "      376    0.000    0.000    0.003    0.000 typing.py:689(<genexpr>)\n",
      "        3    0.000    0.000    0.000    0.000 fx_validator.py:151(check_logging)\n",
      "      137    0.000    0.000    0.000    0.000 typing.py:1280(__getattr__)\n",
      "        4    0.000    0.000    0.000    0.000 ATNDeserializer.py:186(readSets)\n",
      "       36    0.000    0.000    0.000    0.000 callback.py:32(state_key)\n",
      "        6    0.000    0.000    0.000    0.000 __init__.py:124(get_formatter)\n",
      "      133    0.000    0.000    0.056    0.000 contextlib.py:132(__enter__)\n",
      "      700    0.000    0.000    0.000    0.000 {built-in method from_bytes}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch.is_anomaly_enabled}\n",
      "        2    0.000    0.000    0.000    0.000 base.py:197(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 api_pb2.py:1(<module>)\n",
      "      208    0.000    0.000    0.000    0.000 symbol_database.py:95(RegisterMessage)\n",
      "       36    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1559(__init__)\n",
      "       42    0.000    0.000    0.000    0.000 fingerprint.py:213(hash_bytes)\n",
      "      257    0.000    0.000    0.002    0.000 module.py:1146(convert)\n",
      "        1    0.000    0.000    0.016    0.016 resource_tracker.py:161(_send)\n",
      "        1    0.000    0.000    0.000    0.000 type_checkers.py:1(<module>)\n",
      "      109    0.000    0.000    0.000    0.000 typing.py:297(_deduplicate)\n",
      "        1    0.000    0.000    0.011    0.011 _defines.py:1(<module>)\n",
      "      362    0.000    0.000    0.002    0.000 module.py:2306(modules)\n",
      "        1    0.000    0.000    0.008    0.008 summary.py:163(hparams)\n",
      "      989    0.000    0.000    0.000    0.000 {method 'strip' of 'str' objects}\n",
      "        8    0.000    0.000    0.001    0.000 _dill.py:1053(_locate_function)\n",
      "       96    0.000    0.000    0.001    0.000 tokenize.py:353(restore_multidots)\n",
      "        1    0.000    0.000    0.016    0.016 resource_tracker.py:78(ensure_running)\n",
      "       24    0.000    0.000    0.005    0.000 formatters.py:373(lookup)\n",
      "        1    0.000    0.000    0.006    0.006 meta_graph_pb2.py:1(<module>)\n",
      "      648    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}\n",
      "       42    0.000    0.000    0.004    0.000 typing.py:697(Optional)\n",
      "      192    0.000    0.000    0.000    0.000 __init__.py:584(is_tensor)\n",
      "      258    0.000    0.000    0.000    0.000 _parser.py:284(tell)\n",
      "      102    0.000    0.000    0.001    0.000 ATNDeserializer.py:460(<lambda>)\n",
      "     14/8    0.000    0.000    0.005    0.001 _dill.py:1195(save_module_dict)\n",
      "       47    0.000    0.000    0.000    0.000 traitlets.py:4009(validate)\n",
      "        2    0.000    0.000  657.974  328.987 strategy.py:401(validation_step)\n",
      "        2    0.000    0.000    0.011    0.006 data_connector.py:424(_worker_check)\n",
      "       69    0.000    0.000    0.000    0.000 ATNDeserializer.py:488(<lambda>)\n",
      "      169    0.000    0.000    0.000    0.000 utils.py:1823(_has_unfinished_sequences)\n",
      "      310    0.000    0.000    0.000    0.000 {method 'pop' of 'list' objects}\n",
      "      793    0.000    0.000    0.000    0.000 traitlets.py:222(__init__)\n",
      "       17    0.000    0.000    0.000    0.000 std.py:101(acquire)\n",
      "      512    0.000    0.000    0.000    0.000 _parser.py:247(match)\n",
      "      691    0.000    0.000    0.000    0.000 {built-in method _thread.get_ident}\n",
      "        1    0.000    0.000    0.014    0.014 config_pb2.py:1(<module>)\n",
      "        1    0.000    0.000    0.004    0.004 omegaconf.py:172(create)\n",
      "        2    0.000    0.000    0.006    0.003 zmqshell.py:81(publish)\n",
      "       20    0.000    0.000    0.000    0.000 features.py:1651(__init__)\n",
      "       23    0.000    0.000    0.001    0.000 trainer.py:1565(_evaluation_loop)\n",
      "        2    0.000    0.000    0.042    0.021 ATNDeserializer.py:60(deserialize)\n",
      "        2    0.000    0.000    0.001    0.001 _monitor.py:30(__init__)\n",
      "      294    0.000    0.000    0.000    0.000 _parser.py:170(append)\n",
      "    14/13    0.000    0.000    0.000    0.000 builder.py:79(BuildMessage)\n",
      "        1    0.000    0.000    0.004    0.004 dictconfig.py:62(__init__)\n",
      "       15    0.000    0.000    0.002    0.000 emitter.py:111(emit)\n",
      "        5    0.000    0.000    0.003    0.001 enum.py:496(__new__)\n",
      "       62    0.000    0.000    0.000    0.000 session.py:854(<listcomp>)\n",
      "       23    0.000    0.000    0.000    0.000 traitlets.py:2814(validate)\n",
      "        2    0.000    0.000    0.002    0.001 utils.py:1075(_validate_model_kwargs)\n",
      "       84    0.000    0.000    0.000    0.000 traitlets.py:2330(_resolve_classes)\n",
      "        1    0.000    0.000    0.000    0.000 OmegaConfGrammarParser.py:1485(DictKeyContext)\n",
      "      263    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:180(_path_isabs)\n",
      "        1    0.000    0.000    0.006    0.006 evaluation_loop.py:144(setup_data)\n",
      "      959    0.000    0.000    0.000    0.000 copy.py:182(_deepcopy_atomic)\n",
      "  442/401    0.000    0.000    0.002    0.000 {built-in method builtins.hash}\n",
      "      208    0.000    0.000    0.000    0.000 <frozen _collections_abc>:315(__subclasshook__)\n",
      "      220    0.000    0.000    0.012    0.000 __init__.py:225(compile)\n",
      "        3    0.000    0.000    0.000    0.000 logger_connector.py:213(should_reset_tensors)\n",
      "      680    0.000    0.000    0.000    0.000 typing.py:1351(<genexpr>)\n",
      "        2    0.000    0.000    0.000    0.000 utils.py:267(sum_of_lists)\n",
      "       28    0.000    0.000    0.001    0.000 features.py:501(__post_init__)\n",
      "        2    0.000    0.000    0.000    0.000 progress.py:152(increment_processed)\n",
      "        2    0.000    0.000    0.000    0.000 utils.py:887(_get_stopping_criteria)\n",
      "     14/8    0.000    0.000    0.004    0.001 pickle.py:978(_batch_setitems)\n",
      "      248    0.000    0.000    0.000    0.000 hmac.py:117(update)\n",
      "        2    0.000    0.000    0.018    0.009 tqdm_progress.py:309(on_validation_batch_end)\n",
      "      226    0.000    0.000    0.000    0.000 {built-in method _imp._fix_co_filename}\n",
      "        1    0.000    0.000    0.025    0.025 Parser.py:1(<module>)\n",
      "       45    0.000    0.000    0.012    0.000 traitlets.py:1240(__call__)\n",
      "        3    0.000    0.000    0.000    0.000 profiler.py:220(add_metadata)\n",
      "        2    0.000    0.000    0.003    0.002 _tensor.py:1078(__contains__)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._are_functorch_transforms_active}\n",
      "      596    0.000    0.000    0.000    0.000 inspect.py:2743(default)\n",
      "        1    0.000    0.000    0.011    0.011 dtypes.py:1(<module>)\n",
      "       22    0.000    0.000    0.009    0.000 base_comm.py:69(open)\n",
      "      160    0.000    0.000    0.000    0.000 _dill.py:85(memoize)\n",
      "       11    0.000    0.000    0.000    0.000 copyreg.py:104(__newobj__)\n",
      "        2    0.000    0.000    0.000    0.000 eval_frame.py:341(__init__)\n",
      "      236    0.000    0.000    0.000    0.000 {built-in method _imp.find_frozen}\n",
      "        4    0.000    0.000    0.016    0.004 storage.py:838(_deepcopy)\n",
      "      236    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:748(find_spec)\n",
      "      307    0.000    0.000    0.001    0.000 tokenize.py:365(has_numeric_only)\n",
      "       66    0.000    0.000    0.001    0.000 __init__.py:658(update)\n",
      "       42    0.000    0.000    0.000    0.000 pickle.py:491(memoize)\n",
      "    46/44    0.000    0.000    0.001    0.000 data.py:334(wrapper)\n",
      "        1    0.000    0.000    0.001    0.001 utils.py:38(canonicalize_version)\n",
      "        5    0.000    0.000    0.000    0.000 version.py:306(__init__)\n",
      "       68    0.000    0.000    0.000    0.000 generic.py:119(<dictcomp>)\n",
      "       10    0.000    0.000    0.000    0.000 formatting.py:390(__init__)\n",
      "        8    0.000    0.000    0.000    0.000 decoder.py:332(decode)\n",
      "       11    0.000    0.000    0.000    0.000 traitlets.py:3278(validate)\n",
      "       10    0.000    0.000    0.002    0.000 pickle.py:1056(save_global)\n",
      "        5    0.000    0.000    0.002    0.000 ipkernel.py:768(init_closure)\n",
      "       69    0.000    0.000    0.002    0.000 typing.py:1565(copy_with)\n",
      "       68    0.000    0.000    0.000    0.000 generic.py:118(<listcomp>)\n",
      "      205    0.000    0.000    0.000    0.000 {built-in method sys.getrecursionlimit}\n",
      "        4    0.000    0.000    0.000    0.000 nodes.py:34(_set_value)\n",
      "        2    0.000    0.000    0.000    0.000 ipc.py:125(_get_legacy_format_default)\n",
      "       22    0.000    0.000    0.001    0.000 _utils.py:431(is_dataclass)\n",
      "       35    0.000    0.000    0.001    0.000 traitlets.py:1258(instance_init)\n",
      "      288    0.000    0.000    0.000    0.000 tokenization_utils_base.py:1071(sep_token)\n",
      "     12/4    0.000    0.000    0.008    0.002 pickle.py:621(save_reduce)\n",
      "        2    0.000    0.000    0.000    0.000 configuration_utils.py:301(__init__)\n",
      "        2    0.000    0.000    0.002    0.001 configuration_utils.py:946(to_diff_dict)\n",
      "      9/1    0.000    0.000    0.001    0.001 serializer.py:78(serialize_node)\n",
      "       12    0.000    0.000    0.003    0.000 configurable.py:216(_config_changed)\n",
      "        1    0.000    0.000    0.021    0.021 context.py:70(RLock)\n",
      "      208    0.000    0.000    0.000    0.000 symbol_database.py:113(RegisterMessageDescriptor)\n",
      "        1    0.000    0.000    0.009    0.009 saving.py:311(save_hparams_to_yaml)\n",
      "       33    0.000    0.000    0.000    0.000 typing.py:1843(__init_subclass__)\n",
      "        1    0.000    0.000    0.015    0.015 util.py:447(spawnv_passfds)\n",
      "        9    0.000    0.000    0.003    0.000 module.py:325(_call_batch_hook)\n",
      "        4    0.000    0.000    0.000    0.000 version.py:504(_cmpkey)\n",
      "        1    0.000    0.000    0.005    0.005 optimizer.py:245(__init__)\n",
      "       32    0.000    0.000    0.004    0.000 bleu.py:346(_extract_reference_info)\n",
      "        2    0.000    0.000    0.000    0.000 util.py:138(_stringify_path)\n",
      "        6    0.000    0.000    0.000    0.000 progress.py:142(increment_ready)\n",
      "        2    0.000    0.000    0.006    0.003 display_functions.py:45(publish_display_data)\n",
      "       42    0.000    0.000    0.024    0.001 _dill.py:106(dumps)\n",
      "      100    0.000    0.000    0.000    0.000 ATNState.py:156(__init__)\n",
      "       16    0.000    0.000    0.005    0.000 __init__.py:2753(requires)\n",
      "       16    0.000    0.000    0.006    0.000 sampler.py:152(__iter__)\n",
      "       70    0.000    0.000    0.000    0.000 Transition.py:93(__init__)\n",
      "        4    0.000    0.000    0.253    0.063 fetchers.py:119(__next__)\n",
      "        3    0.000    0.000    0.000    0.000 import_utils.py:1421(requires_backends)\n",
      "        1    0.000    0.000    0.054    0.054 tqdm_progress.py:185(init_sanity_tqdm)\n",
      "        1    0.000    0.000    0.002    0.002 tensor_util.py:292(make_tensor_proto)\n",
      "        1    0.000    0.000    0.000    0.000 util.py:186(__init__)\n",
      "        3    0.000    0.000    0.000    0.000 pytorch.py:130(pre_step)\n",
      "        2    0.000    0.000    0.000    0.000 arrow_dataset.py:1421(__del__)\n",
      "       47    0.000    0.000    0.001    0.000 traitlets.py:1643(observe)\n",
      "        1    0.000    0.000    0.001    0.001 tokenize.py:302(<listcomp>)\n",
      "       53    0.000    0.000    0.000    0.000 _parser.py:367(_escape)\n",
      "       63    0.000    0.000    0.000    0.000 tz.py:74(utcoffset)\n",
      "       62    0.000    0.000    0.000    0.000 hmac.py:161(hexdigest)\n",
      "        1    0.000    0.000    0.000    0.000 emitter.py:392(expect_first_block_mapping_key)\n",
      "       60    0.000    0.000    0.000    0.000 loader.py:241(__init__)\n",
      "      244    0.000    0.000    0.000    0.000 version.py:271(<genexpr>)\n",
      "      122    0.000    0.000    0.000    0.000 jsonutil.py:77(json_clean)\n",
      "       66    0.000    0.000    0.001    0.000 <frozen importlib._bootstrap>:216(_lock_unlock_module)\n",
      "       62    0.000    0.000    0.000    0.000 configurable.py:597(initialized)\n",
      "       22    0.000    0.000    0.002    0.000 decorator.py:199(fix)\n",
      "       22    0.000    0.000    0.006    0.000 widget.py:488(_default_keys)\n",
      "      434    0.000    0.000    0.000    0.000 {method 'write' of '_io.BytesIO' objects}\n",
      "        3    0.000    0.000    0.010    0.003 tensorboard.py:127(log_dir)\n",
      "       12    0.000    0.000    0.004    0.000 configurable.py:57(__init__)\n",
      "        1    0.000    0.000    0.001    0.001 model_helpers.py:70(capture)\n",
      "        2    0.000    0.000    0.000    0.000 struct_pb2.py:1(<module>)\n",
      "       44    0.000    0.000    0.000    0.000 functools.py:65(wraps)\n",
      "        2    0.000    0.000    0.004    0.002 dataloader.py:565(__init__)\n",
      "       27    0.000    0.000    0.000    0.000 {method 'match' of 're.Pattern' objects}\n",
      "      102    0.000    0.000    0.000    0.000 IntervalSet.py:35(addOne)\n",
      "        2    0.000    0.000    0.000    0.000 arrow_dataset.py:649(_check_column_names)\n",
      "       22    0.000    0.000    0.008    0.000 formatters.py:219(catch_format_error)\n",
      "       12    0.000    0.000    0.002    0.000 dataclasses.py:413(_create_fn)\n",
      "       22    0.000    0.000    0.000    0.000 _utils.py:439(is_attr_class)\n",
      "        2    0.000    0.000    0.000    0.000 device_dtype_mixin.py:39(device)\n",
      "        3    0.000    0.000    0.253    0.084 fetchers.py:55(__next__)\n",
      "        7    0.000    0.000    0.000    0.000 evaluation_loop.py:84(max_batches)\n",
      "      206    0.000    0.000    0.000    0.000 _dill.py:316(get)\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method torch._C._autograd._kineto_step}\n",
      "     12/4    0.000    0.000    0.000    0.000 features.py:1376(generate_from_dict)\n",
      "      226    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1097(__init__)\n",
      "        2    0.000    0.000    0.003    0.001 fingerprint.py:347(format_kwargs_for_fingerprint)\n",
      "        8    0.000    0.000    0.000    0.000 __init__.py:299(loads)\n",
      "      208    0.000    0.000    0.000    0.000 _parser.py:79(groups)\n",
      "        1    0.000    0.000  277.897  277.897 automatic.py:126(closure)\n",
      "        4    0.000    0.000    0.002    0.001 package_importer.py:695(_patched_getfile)\n",
      "       67    0.000    0.000    0.000    0.000 ATNState.py:179(__init__)\n",
      "      407    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}\n",
      "      510    0.000    0.000    0.000    0.000 {built-in method math.prod}\n",
      "        2    0.000    0.000    0.004    0.002 dataloader.py:659(__init__)\n",
      "       22    0.000    0.000    0.010    0.000 decorator.py:229(fun)\n",
      "        1    0.000    0.000    0.194    0.194 writer.py:1(<module>)\n",
      "       37    0.000    0.000    0.001    0.000 <frozen importlib._bootstrap_external>:1696(path_hook_for_FileFinder)\n",
      "       62    0.000    0.000    0.000    0.000 session.py:198(utcnow)\n",
      "      197    0.000    0.000    0.000    0.000 _parser.py:109(__init__)\n",
      "        1    0.000    0.000    0.034    0.034 OmegaConfGrammarLexer.py:258(OmegaConfGrammarLexer)\n",
      "        2    0.000    0.000    0.000    0.000 beam_search.py:184(<listcomp>)\n",
      "        1    0.000    0.000    0.059    0.059 event_pb2.py:1(<module>)\n",
      "       77    0.000    0.000    0.000    0.000 DFA.py:16(__init__)\n",
      "        2    0.000    0.000    0.001    0.000 arrow_dataset.py:2530(set_format)\n",
      "      120    0.000    0.000    0.001    0.000 configurable.py:129(section_names)\n",
      "        5    0.000    0.000    0.000    0.000 trainer.py:1539(num_sanity_val_batches)\n",
      "        1    0.000    0.000    0.023    0.023 strategy.py:141(setup)\n",
      "       62    0.000    0.000    0.001    0.000 session.py:272(msg_header)\n",
      "       96    0.000    0.000    0.000    0.000 tokenization_utils_base.py:287(items)\n",
      "        5    0.000    0.000    0.000    0.000 utils.py:87(__init__)\n",
      "       12    0.000    0.000    0.000    0.000 utils.py:278(<listcomp>)\n",
      "      237    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:165(__init__)\n",
      "        4    0.000    0.000    0.001    0.000 formatting.py:553(query_table)\n",
      "       11    0.000    0.000    0.056    0.005 imports.py:162(__bool__)\n",
      "      5/3    0.000    0.000    0.003    0.001 basecontainer.py:524(_set_item_impl)\n",
      "       22    0.000    0.000    0.000    0.000 inspect.py:2839(args)\n",
      "        2    0.000    0.000    0.001    0.000 utilities.py:135(_select_data_fetcher)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'flush' of '_io.BufferedWriter' objects}\n",
      "        2    0.000    0.000    0.001    0.001 notebook.py:85(__repr__)\n",
      "        6    0.000    0.000    0.001    0.000 results.py:431(__iadd__)\n",
      "       37    0.000    0.000    0.016    0.000 base_comm.py:111(send)\n",
      "       16    0.000    0.000    0.000    0.000 __init__.py:2912(<listcomp>)\n",
      "       65    0.000    0.000    0.000    0.000 typing.py:2561(overload)\n",
      "        2    0.000    0.000    0.000    0.000 signal.py:67(pthread_sigmask)\n",
      "        2    0.000    0.000    0.001    0.000 data.py:60(extract_batch_size)\n",
      "        4    0.000    0.000    0.003    0.001 arrow_dataset.py:2831(_getitem)\n",
      "      189    0.000    0.000    0.000    0.000 {method 'values' of 'collections.OrderedDict' objects}\n",
      "        4    0.000    0.000    0.002    0.000 queue.py:79(join)\n",
      "        1    0.000    0.000    0.002    0.002 ATNDeserializer.py:1(<module>)\n",
      "        2    0.000    0.000    0.000    0.000 beam_search.py:162(__init__)\n",
      "        5    0.000    0.000    0.005    0.001 iostream.py:592(flush)\n",
      "        3    0.000    0.000    0.000    0.000 {method 'fill_' of 'torch._C.TensorBase' objects}\n",
      "        4    0.000    0.000    0.017    0.004 __init__.py:108(import_module)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method posix.statvfs}\n",
      "        6    0.000    0.000    0.021    0.004 std.py:648(get_lock)\n",
      "        2    0.000    0.000    0.001    0.000 evaluation_loop.py:446(_build_step_args_from_hook_kwargs)\n",
      "       71    0.000    0.000    0.000    0.000 {built-in method builtins.locals}\n",
      "        1    0.000    0.000    0.001    0.001 core.py:3949(parseImpl)\n",
      "       69    0.000    0.000    0.000    0.000 ATNState.py:198(__init__)\n",
      "      579    0.000    0.000    0.000    0.000 widget.py:792(_trait_to_json)\n",
      "        5    0.000    0.000    0.000    0.000 threading.py:1317(_make_invoke_excepthook)\n",
      "       84    0.000    0.000    0.000    0.000 traitlets.py:2325(instance_init)\n",
      "        1    0.000    0.000    0.004    0.004 function_pb2.py:1(<module>)\n",
      "        4    0.000    0.000    0.002    0.001 arrow_writer.py:121(get_inferred_type)\n",
      "       12    0.000    0.000    0.000    0.000 base.py:152(_set_flag)\n",
      "       70    0.000    0.000    0.000    0.000 ATNDeserializer.py:456(<lambda>)\n",
      "       67    0.000    0.000    0.000    0.000 ATNDeserializer.py:489(<lambda>)\n",
      "      162    0.000    0.000    0.000    0.000 strategy.py:361(lightning_module)\n",
      "        1    0.000    0.000    0.001    0.001 omegaconf.py:113(OmegaConf)\n",
      "        2    0.000    0.000    0.002    0.001 errors.py:1(<module>)\n",
      "        4    0.000    0.000    0.002    0.001 formatting.py:596(format_table)\n",
      "       17    0.000    0.000    0.000    0.000 {method 'acquire' of '_multiprocessing.SemLock' objects}\n",
      "        1    0.000    0.000    0.001    0.001 tokenize.py:316(<listcomp>)\n",
      "       29    0.000    0.000    0.000    0.000 <frozen os>:756(encode)\n",
      "      124    0.000    0.000    0.000    0.000 jsonutil.py:38(_ensure_tzinfo)\n",
      "        2    0.000    0.000    0.002    0.001 pathlib.py:1111(mkdir)\n",
      "        2    0.000    0.000   39.571   19.786 utils.py:474(_prepare_encoder_decoder_kwargs_for_generation)\n",
      "        2    0.000    0.000    0.000    0.000 pathlib.py:1245(is_dir)\n",
      "        1    0.000    0.000    0.010    0.010 OmegaConfGrammarParser.py:1(<module>)\n",
      "        1    0.000    0.000    0.153    0.153 base.py:1(<module>)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'is_neg' of 'torch._C.TensorBase' objects}\n",
      "        1    0.000    0.000    0.010    0.010 summary_pb2.py:1(<module>)\n",
      "       22    0.000    0.000    0.016    0.001 comm.py:27(create_comm)\n",
      "       65    0.000    0.000    0.000    0.000 _compiler.py:396(_simple)\n",
      "        1    0.000    0.000    0.009    0.009 tensorboard.py:222(log_hyperparams)\n",
      "       14    0.000    0.000    0.000    0.000 data.py:283(_wrap_init_method)\n",
      "      136    0.000    0.000    0.001    0.000 typing.py:1561(<genexpr>)\n",
      "       22    0.000    0.000    0.000    0.000 traitlets.py:3631(validate_elements)\n",
      "        9    0.000    0.000    0.002    0.000 data_connector.py:366(get_instance)\n",
      "       21    0.000    0.000    0.000    0.000 <frozen posixpath>:150(dirname)\n",
      "       21    0.000    0.000    0.000    0.000 local.py:235(make_path_posix)\n",
      "       22    0.000    0.000    0.000    0.000 comm.py:7(requires_ipykernel_shim)\n",
      "        1    0.000    0.000    0.060    0.060 grammar_parser.py:1(<module>)\n",
      "       17    0.000    0.000    0.000    0.000 _compiler.py:386(<listcomp>)\n",
      "       10    0.000    0.000    0.000    0.000 formatting.py:430(__init__)\n",
      "        4    0.000    0.000    0.148    0.037 utils.py:599(_expand_dict_for_generation)\n",
      "        1    0.000    0.000    0.001    0.001 shutil.py:1448(which)\n",
      "        2    0.000    0.000    0.001    0.000 fit_loop.py:160(done)\n",
      "    38/28    0.000    0.000    0.000    0.000 base.py:189(_get_flag)\n",
      "        1    0.000    0.000    0.002    0.002 node_def_pb2.py:1(<module>)\n",
      "        3    0.000    0.000    0.006    0.002 sampler.py:274(__iter__)\n",
      "        1    0.000    0.000    0.015    0.015 optimizer.py:172(_init_optimizers_and_lr_schedulers)\n",
      "        2    0.000    0.000    0.001    0.001 base.py:229(_check_corpus_score_args)\n",
      "      194    0.000    0.000    0.000    0.000 traitlets.py:1827(has_trait)\n",
      "       69    0.000    0.000    0.000    0.000 ATNState.py:191(__init__)\n",
      "        3    0.000    0.000    0.000    0.000 result.py:122(__post_init__)\n",
      "        1    0.000    0.000    0.002    0.002 step_stats_pb2.py:1(<module>)\n",
      "        2    0.000    0.000    0.001    0.001 table.py:106(__init__)\n",
      "        2    0.000    0.000    0.003    0.001 tqdm_progress.py:292(on_validation_batch_start)\n",
      "        6    0.000    0.000    0.000    0.000 tensorboard.py:116(root_dir)\n",
      "        8    0.000    0.000    0.075    0.009 summary.py:1(<module>)\n",
      "        1    0.000    0.000    0.010    0.010 OmegaConfGrammarParser.py:92(OmegaConfGrammarParser)\n",
      "       18    0.000    0.000    0.002    0.000 formatters.py:330(__call__)\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method torch._C._autograd._add_metadata_json}\n",
      "     10/6    0.000    0.000    0.000    0.000 configuration_utils.py:934(dict_torch_dtype_to_str)\n",
      "        3    0.000    0.000    0.000    0.000 profiler.py:329(schedule_fn)\n",
      "        9    0.000    0.000    0.008    0.001 metadata.py:1(<module>)\n",
      "        1    0.000    0.000    0.006    0.006 ParseTreePatternMatcher.py:1(<module>)\n",
      "        2    0.000    0.000    0.000    0.000 arrow_reader.py:334(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 layout_pb2.py:1(<module>)\n",
      "        4    0.000    0.000    0.000    0.000 configuration_utils.py:457(validate)\n",
      "       14    0.000    0.000    0.000    0.000 version.py:293(__str__)\n",
      "        1    0.000    0.000    0.002    0.002 __init__.py:215(dump_all)\n",
      "        8    0.000    0.000    0.000    0.000 pathlib.py:239(splitroot)\n",
      "       64    0.000    0.000    0.000    0.000 signal.py:24(_int_to_enum)\n",
      "        3    0.000    0.000    0.000    0.000 warnings.py:403(__init__)\n",
      "        1    0.000    0.000    0.011    0.011 tensorboard.py:210(save)\n",
      "        5    0.000    0.000    0.000    0.000 utils.py:144(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 precision.py:173(val_step_context)\n",
      "        3    0.000    0.000    0.000    0.000 std.py:567(_get_free_pos)\n",
      "       22    0.000    0.000    0.000    0.000 dir2.py:54(get_real_method)\n",
      "        2    0.000    0.000    0.000    0.000 configuration_utils.py:409(get_generation_mode)\n",
      "        3    0.000    0.000    0.005    0.002 collate.py:216(default_collate)\n",
      "        1    0.000    0.000    0.000    0.000 graph_debug_info_pb2.py:1(<module>)\n",
      "      126    0.000    0.000    0.000    0.000 {method 'update' of 'xxhash.xxh64' objects}\n",
      "       47    0.000    0.000    0.000    0.000 traitlets.py:1572(_add_notifiers)\n",
      "       96    0.000    0.000    0.000    0.000 tokenization_utils_base.py:2895(_is_valid_text_input)\n",
      "      128    0.000    0.000    0.000    0.000 IntervalSet.py:16(__init__)\n",
      "       10    0.000    0.000    0.000    0.000 _weakrefset.py:85(add)\n",
      "       18    0.000    0.000    0.003    0.000 specifiers.py:168(contains)\n",
      "       32    0.000    0.000    0.004    0.000 base.py:335(<listcomp>)\n",
      "       25    0.000    0.000    0.000    0.000 _utils.py:508(_is_missing_value)\n",
      "        2    0.000    0.000    0.000    0.000 ATNDeserializer.py:53(isFeatureSupported)\n",
      "       16    0.000    0.000    0.000    0.000 <frozen _collections_abc>:771(get)\n",
      "       10    0.000    0.000    0.007    0.001 threading.py:604(wait)\n",
      "       40    0.000    0.000    0.000    0.000 trainer.py:1440(sanity_checking)\n",
      "       34    0.000    0.000    0.000    0.000 features.py:1540(require_decoding)\n",
      "        4    0.000    0.000    0.015    0.004 module.py:740(<listcomp>)\n",
      "       17    0.000    0.000    0.000    0.000 _compiler.py:384(_mk_bitmap)\n",
      "       64    0.000    0.000    0.000    0.000 _parser.py:954(fix_flags)\n",
      "       14    0.000    0.000    0.003    0.000 inheritance.py:8(get_all_subclasses_iterator)\n",
      "      7/6    0.000    0.000    0.003    0.000 core.py:4373(parseImpl)\n",
      "       42    0.000    0.000    0.000    0.000 pickle.py:212(end_framing)\n",
      "        2    0.000    0.000    0.006    0.003 bleu.py:32(_get_tokenizer)\n",
      "        8    0.000    0.000    0.000    0.000 decoder.py:343(raw_decode)\n",
      "       99    0.000    0.000    0.000    0.000 __init__.py:1132(__iter__)\n",
      "        5    0.000    0.000    0.003    0.001 threading.py:938(start)\n",
      "        3    0.000    0.000    0.000    0.000 tokenization_utils_base.py:784(to)\n",
      "     14/8    0.000    0.000    0.005    0.001 pickle.py:965(save_dict)\n",
      "        3    0.000    0.000    0.002    0.001 strategy.py:263(batch_to_device)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:25(__init__)\n",
      "        9    0.000    0.000    0.000    0.000 collate.py:129(<listcomp>)\n",
      "        1    0.000    0.000    0.001    0.001 device_dtype_mixin.py:109(_update_properties)\n",
      "        1    0.000    0.000    0.007    0.007 profiler.py:282(_prepare_trace)\n",
      "       25    0.000    0.000    0.000    0.000 utils.py:327(stringify_path)\n",
      "       10    0.000    0.000    0.000    0.000 dataclasses.py:723(_get_field)\n",
      "        1    0.000    0.000    0.000    0.000 tensor_shape_pb2.py:1(<module>)\n",
      "        4    0.000    0.000    0.001    0.000 features.py:1958(<listcomp>)\n",
      "     20/8    0.000    0.000    0.001    0.000 data.py:41(_extract_batch_size)\n",
      "        3    0.000    0.000    0.006    0.002 threading.py:1080(join)\n",
      "        2    0.000    0.000    0.000    0.000 _base.py:328(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 signal_connector.py:43(register_signal_handlers)\n",
      "      177    0.000    0.000    0.000    0.000 typing.py:888(__eq__)\n",
      "       14    0.000    0.000    0.001    0.000 specifiers.py:481(_compare_greater_than_equal)\n",
      "        4    0.000    0.000    0.003    0.001 arrow_dataset.py:2859(__getitem__)\n",
      "       39    0.000    0.000    0.001    0.000 ATNDeserializer.py:484(<lambda>)\n",
      "      109    0.000    0.000    0.000    0.000 traitlets.py:1247(__get__)\n",
      "       40    0.000    0.000    0.000    0.000 _parser.py:82(opengroup)\n",
      "       62    0.000    0.000    0.000    0.000 session.py:281(extract_header)\n",
      "      288    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1565(<genexpr>)\n",
      "        1    0.000    0.000    0.020    0.020 synchronize.py:186(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 representer.py:103(represent_mapping)\n",
      "        1    0.000    0.000    0.000    0.000 dumper.py:47(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 trainer.py:1546(num_val_batches)\n",
      "        7    0.000    0.000    0.020    0.003 std.py:1322(refresh)\n",
      "       22    0.000    0.000    0.000    0.000 widget.py:490(<listcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method posix.fchmod}\n",
      "       76    0.000    0.000    0.000    0.000 <frozen posixpath>:41(_get_sep)\n",
      "        8    0.000    0.000    0.000    0.000 exceptions.py:24(__init__)\n",
      "        2    0.000    0.000    0.001    0.000 _trace.py:1119(is_tracing)\n",
      "        2    0.000    0.000    0.005    0.003 utils.py:456(_prepare_attention_mask_for_generation)\n",
      "        2    0.000    0.000    0.017    0.009 tqdm_progress.py:451(_update_n)\n",
      "       69    0.000    0.000    0.000    0.000 ATNDeserializer.py:483(<lambda>)\n",
      "        3    0.000    0.000    0.243    0.081 fetch.py:46(fetch)\n",
      "        1    0.000    0.000    0.001    0.001 OmegaConfGrammarLexer.py:12(serializedATN)\n",
      "       32    0.000    0.000    0.000    0.000 beam_search.py:923(__init__)\n",
      "      182    0.000    0.000    0.000    0.000 {method 'find' of 'bytearray' objects}\n",
      "       40    0.000    0.000    0.000    0.000 _compiler.py:405(_generate_overlap_table)\n",
      "      165    0.000    0.000    0.000    0.000 {method 'get' of 'mappingproxy' objects}\n",
      "        1    0.000    0.000    0.000    0.000 core.py:959(reset_cache)\n",
      "        3    0.000    0.000    0.001    0.000 hooks.py:562(transfer_batch_to_device)\n",
      "       34    0.000    0.000    0.000    0.000 traitlets.py:3493(validate_elements)\n",
      "       18    0.000    0.000    0.002    0.000 features.py:1672(type)\n",
      "      5/3    0.000    0.000    0.002    0.001 omegaconf.py:994(_node_wrap)\n",
      "        4    0.000    0.000    0.001    0.000 eval_frame.py:120(backend_cache_wrapper)\n",
      "       42    0.000    0.000    0.000    0.000 data.py:295(<genexpr>)\n",
      "        2    0.000    0.000    0.008    0.004 seed.py:22(isolate_rng)\n",
      "        1    0.000    0.000    0.000    0.000 {function Random.seed at 0x10f54d9e0}\n",
      "        2    0.000    0.000    0.000    0.000 module.py:310(_get_all_cache_files)\n",
      "       68    0.000    0.000    0.000    0.000 types.py:65(is_integer)\n",
      "        1    0.000    0.000    0.001    0.001 rewriter_config_pb2.py:1(<module>)\n",
      "        6    0.000    0.000    0.003    0.000 features.py:1753(to_dict)\n",
      "        2    0.000    0.000    0.000    0.000 arrow_dataset.py:1810(cache_files)\n",
      "        2    0.000    0.000    0.000    0.000 _unix.py:52(_release)\n",
      "       12    0.000    0.000    0.000    0.000 threading.py:555(__init__)\n",
      "      226    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:931(create_module)\n",
      "        2    0.000    0.000    0.153    0.076 utils.py:590(_expand_inputs_for_generation)\n",
      "        1    0.000    0.000    0.050    0.050 tqdm_progress.py:197(init_train_tqdm)\n",
      "        1    0.000    0.000    0.000    0.000 op_def_pb2.py:1(<module>)\n",
      "        4    0.000    0.000    0.002    0.001 registry.py:276(filesystem)\n",
      "       13    0.000    0.000    0.000    0.000 iostream.py:364(fileno)\n",
      "       16    0.000    0.000    0.008    0.001 inspect.py:2773(__str__)\n",
      "        1    0.000    0.000    0.001    0.001 trackable_object_graph_pb2.py:1(<module>)\n",
      "        2    0.000    0.000    0.000    0.000 metric.py:689(reset)\n",
      "       39    0.000    0.000    0.001    0.000 ATNState.py:171(__init__)\n",
      "        3    0.000    0.000    0.001    0.000 pytorch.py:386(_should_override_schedule)\n",
      "        8    0.000    0.000    0.000    0.000 __init__.py:116(get_format_type_from_alias)\n",
      "        1    0.000    0.000    0.004    0.004 omegaconf.py:1(<module>)\n",
      "        6    0.000    0.000    0.000    0.000 traitlets.py:1266(instance_init)\n",
      "      103    0.000    0.000    0.000    0.000 typing.py:275(_check_generic)\n",
      "        2    0.000    0.000    0.000    0.000 weakref.py:427(__setitem__)\n",
      "       37    0.000    0.000    0.000    0.000 _parser.py:444(_uniq)\n",
      "       51    0.000    0.000    0.000    0.000 traitlets.py:2334(make_dynamic_default)\n",
      "      6/2    0.000    0.000    0.000    0.000 features.py:2076(recursive_reorder)\n",
      "        2    0.000    0.000    0.021    0.010 std.py:115(create_mp_lock)\n",
      "        2    0.000    0.000    0.000    0.000 threading.py:422(__init__)\n",
      "        7    0.000    0.000    0.000    0.000 emitter.py:1080(write_plain)\n",
      "       17    0.000    0.000    0.000    0.000 std.py:105(release)\n",
      "        2    0.000    0.000    0.011    0.005 _base.py:314(_result_or_cancel)\n",
      "        1    0.000    0.000    0.014    0.014 models.py:84(configure_optimizers)\n",
      "        1    0.000    0.000    0.000    0.000 attr_value_pb2.py:1(<module>)\n",
      "       11    0.000    0.000    0.000    0.000 widget_float.py:33(_validate_value)\n",
      "       64    0.000    0.000    0.000    0.000 _parser.py:73(__init__)\n",
      "       12    0.000    0.000    0.003    0.000 configurable.py:163(_load_config)\n",
      "        1    0.000    0.000    0.000    0.000 emitter.py:175(expect_first_document_start)\n",
      "      471    0.000    0.000    0.000    0.000 {method 'upper' of 'str' objects}\n",
      "        6    0.000    0.000    0.000    0.000 import_utils.py:1435(<genexpr>)\n",
      "        2    0.000    0.000    0.002    0.001 table.py:1127(replace_schema_metadata)\n",
      "        1    0.000    0.000    0.002    0.002 evaluation_loop.py:200(reset)\n",
      "        3    0.000    0.000    0.001    0.000 core.py:2984(parseImpl)\n",
      "        2    0.000    0.000    0.000    0.000 precision.py:167(train_step_context)\n",
      "        6    0.000    0.000    0.001    0.000 threading.py:359(notify)\n",
      "      195    0.000    0.000    0.000    0.000 version.py:393(_parse_letter_version)\n",
      "        4    0.000    0.000    0.011    0.003 widget_string.py:64(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 utilities.py:127(_reset_progress)\n",
      "      468    0.000    0.000    0.000    0.000 {function Config.__contains__ at 0x110256200}\n",
      "       64    0.000    0.000    0.000    0.000 {built-in method _sre.compile}\n",
      "        1    0.000    0.000    0.001    0.001 strategy.py:121(setup_environment)\n",
      "        2    0.000    0.000    0.000    0.000 modeling_utils.py:207(get_parameter_device)\n",
      "       17    0.000    0.000    0.000    0.000 {method 'release' of '_multiprocessing.SemLock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 normalize.py:127(__init__)\n",
      "       22    0.000    0.000    0.000    0.000 inspect.py:2862(kwargs)\n",
      "        1    0.000    0.000    0.000    0.000 debug_pb2.py:1(<module>)\n",
      "        1    0.000    0.000    0.004    0.004 formatters.py:69(_formatters_default)\n",
      "        2    0.000    0.000    0.000    0.000 ATNDeserializer.py:247(readDecisions)\n",
      "        1    0.000    0.000    0.046    0.046 automatic.py:293(_optimizer_zero_grad)\n",
      "      341    0.000    0.000    0.000    0.000 {method 'write' of '_io.StringIO' objects}\n",
      "        2    0.000    0.000    0.004    0.002 dataloader.py:382(_get_iterator)\n",
      "        1    0.000    0.000    0.001    0.001 ParserATNSimulator.py:1(<module>)\n",
      "        8    0.000    0.000    0.000    0.000 _dill.py:1020(_import_module)\n",
      "        4    0.000    0.000    0.000    0.000 storage.py:653(_new_wrapped_storage)\n",
      "      160    0.000    0.000    0.000    0.000 __init__.py:2379(_normalize_cached)\n",
      "        4    0.000    0.000    0.000    0.000 dictconfig.py:168(_validate_set)\n",
      "        1    0.000    0.000    0.000    0.000 projector_config_pb2.py:1(<module>)\n",
      "        2    0.000    0.000    0.000    0.000 keyhash.py:38(_as_bytes)\n",
      "        1    0.000    0.000    0.000    0.000 cluster_pb2.py:1(<module>)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'stride' of 'torch._C.TensorBase' objects}\n",
      "        4    0.000    0.000    0.002    0.001 formatting.py:441(format_column)\n",
      "       17    0.000    0.000    0.001    0.000 __init__.py:305(_compile_repl)\n",
      "       12    0.000    0.000    0.000    0.000 strategy.py:94(precision_plugin)\n",
      "        9    0.000    0.000    0.000    0.000 emitter.py:232(expect_node)\n",
      "      5/4    0.000    0.000    0.000    0.000 base.py:773(_invalidate_flags_cache)\n",
      "       46    0.000    0.000    0.002    0.000 dtypes.py:62(__init__)\n",
      "        1    0.000    0.000    0.010    0.010 trainer.py:1228(log_dir)\n",
      "        9    0.000    0.000    0.000    0.000 __init__.py:1720(getEffectiveLevel)\n",
      "       22    0.000    0.000    0.000    0.000 _funcs.py:301(has)\n",
      "        2    0.000    0.000    0.000    0.000 result.py:171(is_max_reduction)\n",
      "        1    0.000    0.000    0.002    0.002 tokenizer_13a.py:1(<module>)\n",
      "       38    0.000    0.000    0.000    0.000 Transition.py:188(__init__)\n",
      "       42    0.000    0.000    0.000    0.000 __init__.py:1889(isEnabledFor)\n",
      "        1    0.000    0.000    0.001    0.001 base.py:102(Node)\n",
      "       17    0.000    0.000    0.000    0.000 trainer.py:1403(testing)\n",
      "       72    0.000    0.000    0.000    0.000 types.py:60(is_boolean)\n",
      "       18    0.000    0.000    0.008    0.000 inspect.py:1441(formatannotation)\n",
      "        2    0.000    0.000    0.000    0.000 modeling_utils.py:1506(can_generate)\n",
      "        3    0.000    0.000    0.001    0.000 dataclasses.py:528(_init_fn)\n",
      "        1    0.000    0.000    0.054    0.054 grammar_visitor.py:1(<module>)\n",
      "        3    0.000    0.000    0.000    0.000 _api.py:273(release)\n",
      "        1    0.000    0.000    0.005    0.005 dictconfig.py:1(<module>)\n",
      "       31    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.RLock' objects}\n",
      "      137    0.000    0.000    0.000    0.000 {built-in method posix.getpid}\n",
      "      2/1    0.000    0.000    0.000    0.000 basecontainer.py:217(_to_content)\n",
      "      3/2    0.000    0.000    0.001    0.000 core.py:4889(parseImpl)\n",
      "        2    0.000    0.000    0.000    0.000 version.py:186(__init__)\n",
      "       72    0.000    0.000    0.000    0.000 encoder.py:334(_iterencode_dict)\n",
      "       49    0.000    0.000    0.000    0.000 enum.py:78(_is_private)\n",
      "       16    0.000    0.000    0.000    0.000 __init__.py:954(markers_pass)\n",
      "        2    0.000    0.000    0.002    0.001 data_connector.py:167(_requires_distributed_sampler)\n",
      "        2    0.000    0.000    0.000    0.000 modeling_utils.py:963(device)\n",
      "        3    0.000    0.000    0.002    0.001 local.py:304(_open)\n",
      "       35    0.000    0.000    0.000    0.000 Transition.py:170(__init__)\n",
      "      294    0.000    0.000    0.000    0.000 {method 'tell' of '_io.BytesIO' objects}\n",
      "        6    0.000    0.000    0.001    0.000 result.py:504(reset)\n",
      "       25    0.000    0.000    0.005    0.000 <frozen abc>:105(__new__)\n",
      "        2    0.000    0.000    0.036    0.018 arrow_reader.py:258(read_files)\n",
      "        2    0.000    0.000    0.000    0.000 arrow_reader.py:176(__init__)\n",
      "       26    0.000    0.000    0.000    0.000 threading.py:267(__exit__)\n",
      "        1    0.000    0.000    0.001    0.001 serializer.py:46(serialize)\n",
      "        1    0.000    0.000    0.004    0.004 evaluation_loop.py:239(on_run_start)\n",
      "        3    0.000    0.000    0.000    0.000 std.py:570(<setcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 model_summary.py:364(_format_summary_table)\n",
      "        3    0.000    0.000    0.000    0.000 trainer.py:1140(precision_plugin)\n",
      "        4    0.000    0.000    0.002    0.001 formatting.py:395(__call__)\n",
      "       14    0.000    0.000    0.000    0.000 _dill.py:1191(_repr_dict)\n",
      "        2    0.000    0.000    0.000    0.000 pathlib.py:777(parent)\n",
      "       92    0.000    0.000    0.000    0.000 _dill.py:2180(is_dill)\n",
      "       30    0.000    0.000    0.001    0.000 <frozen genericpath>:16(exists)\n",
      "        1    0.000    0.000    0.000    0.000 automatic.py:197(_make_closure)\n",
      "        8    0.000    0.000    0.000    0.000 utils.py:254(my_log)\n",
      "        1    0.000    0.000    0.002    0.002 resource_tracker.py:1(<module>)\n",
      "        1    0.000    0.000    0.182    0.182 tensorboard.py:156(log_hyperparams)\n",
      "        2    0.000    0.000    0.000    0.000 features.py:2049(reorder_fields_as)\n",
      "       23    0.000    0.000    0.000    0.000 traitlets.py:2565(_validate_bounds)\n",
      "        1    0.000    0.000    0.000    0.000 serializer.py:27(open)\n",
      "        2    0.000    0.000    0.011    0.005 _base.py:428(result)\n",
      "        2    0.000    0.000    0.004    0.002 notebook.py:293(reset)\n",
      "        2    0.000    0.000    0.000    0.000 functools.py:518(decorating_function)\n",
      "       10    0.000    0.000    0.000    0.000 utils.py:118(disable_on_exception)\n",
      "        2    0.000    0.000    0.005    0.003 ATNDeserializer.py:255(readLexerActions)\n",
      "       44    0.000    0.000    0.000    0.000 enum.py:744(__delattr__)\n",
      "        4    0.000    0.000    0.000    0.000 _contextlib.py:141(clone)\n",
      "        5    0.000    0.000    0.000    0.000 enum.py:481(__prepare__)\n",
      "        4    0.000    0.000    0.001    0.000 configuration_utils.py:969(to_dict)\n",
      "        1    0.000    0.000    0.000    0.000 text_encoding.py:43(<listcomp>)\n",
      "        1    0.000    0.000    0.001    0.001 formatters.py:57(_default_formatter)\n",
      "       65    0.000    0.000    0.000    0.000 widget.py:547(model_id)\n",
      "        2    0.000    0.000    0.000    0.000 notebook.py:76(_json_)\n",
      "       44    0.000    0.000    0.000    0.000 logger.py:136(trace)\n",
      "    20/16    0.000    0.000    0.000    0.000 base.py:201(_get_flag_no_cache)\n",
      "        5    0.000    0.000    0.007    0.001 cloud_io.py:105(_is_dir)\n",
      "        2    0.000    0.000    0.002    0.001 features.py:1942(encode_batch)\n",
      "    26/18    0.000    0.000    0.000    0.000 typing.py:224(_type_repr)\n",
      "        2    0.000    0.000    0.000    0.000 threading.py:433(acquire)\n",
      "        2    0.000    0.000    0.003    0.002 module.py:465(<dictcomp>)\n",
      "        7    0.000    0.000    0.000    0.000 _api.py:180(is_locked)\n",
      "       22    0.000    0.000    0.000    0.000 base_comm.py:190(register_comm)\n",
      "       18    0.000    0.000    0.000    0.000 features.py:1210(<dictcomp>)\n",
      "        1    0.000    0.000    0.002    0.002 tqdm_progress.py:263(on_train_epoch_start)\n",
      "       26    0.000    0.000    0.000    0.000 traitlets.py:2943(validate)\n",
      "        5    0.000    0.000    0.000    0.000 progress.py:114(reset)\n",
      "     12/8    0.000    0.000    0.000    0.000 typing.py:1500(__repr__)\n",
      "      228    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:413(has_location)\n",
      "       22    0.000    0.000    0.001    0.000 inspect.py:3207(bind)\n",
      "       16    0.000    0.000    0.000    0.000 typing.py:838(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 thread.py:216(shutdown)\n",
      "     12/6    0.000    0.000    0.003    0.000 pickle.py:874(save_tuple)\n",
      "        1    0.000    0.000    0.054    0.054 tqdm_progress.py:249(on_sanity_check_start)\n",
      "        3    0.000    0.000    0.252    0.084 combined_loader.py:339(__next__)\n",
      "        6    0.000    0.000    0.033    0.006 widget_description.py:30(__init__)\n",
      "       54    0.000    0.000    0.000    0.000 enum.py:47(_is_dunder)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'stat' of 'posix.DirEntry' objects}\n",
      "        3    0.000    0.000    0.005    0.002 collate.py:129(<dictcomp>)\n",
      "        3    0.000    0.000    0.000    0.000 precision.py:68(forward_context)\n",
      "        7    0.000    0.000    0.000    0.000 module.py:207(trainer)\n",
      "        2    0.000    0.000    0.000    0.000 fingerprint.py:72(maybe_register_dataset_for_temp_dir_deletion)\n",
      "       24    0.000    0.000    0.000    0.000 _parser.py:1006(addgroup)\n",
      "        4    0.000    0.000    0.001    0.000 nodes.py:24(__init__)\n",
      "       32    0.000    0.000    0.000    0.000 bleu.py:326(_get_closest_ref_len)\n",
      "      226    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1122(get_filename)\n",
      "        1    0.000    0.000    0.000    0.000 OmegaConfGrammarLexer.py:262(<listcomp>)\n",
      "      5/4    0.000    0.000    0.017    0.004 <frozen importlib._bootstrap>:1192(_gcd_import)\n",
      "      9/1    0.000    0.000    0.000    0.000 representer.py:33(represent_data)\n",
      "       64    0.000    0.000    0.000    0.000 tokenization_utils.py:1002(<setcomp>)\n",
      "        4    0.000    0.000    0.000    0.000 arrow_writer.py:100(__init__)\n",
      "      257    0.000    0.000    0.000    0.000 __future__.py:20(get_overwrite_module_params_on_conversion)\n",
      "        1    0.000    0.000    0.000    0.000 checkpoint_connector.py:208(resume_end)\n",
      "        7    0.000    0.000    0.223    0.032 tensorboard.py:175(experiment)\n",
      "       32    0.000    0.000    0.001    0.000 version.py:42(parse)\n",
      "       21    0.000    0.000    0.000    0.000 inspect.py:3036(return_annotation)\n",
      "       10    0.000    0.000    0.001    0.000 typing.py:1640(__getitem__)\n",
      "        3    0.000    0.000    0.001    0.000 trainer.py:1271(enable_validation)\n",
      "        2    0.000    0.000    0.008    0.004 _base.py:608(<listcomp>)\n",
      "       31    0.000    0.000    0.000    0.000 ATNDeserializer.py:464(<lambda>)\n",
      "        3    0.000    0.000    0.000    0.000 progress.py:274(optimizer_steps)\n",
      "        1    0.000    0.000    0.003    0.003 fit_loop.py:331(on_advance_start)\n",
      "        1    0.000    0.000    0.005    0.005 _argument_parser.py:1(<module>)\n",
      "       25    0.000    0.000    0.000    0.000 _parser.py:307(_class_escape)\n",
      "        3    0.000    0.000    0.002    0.001 module.py:340(_on_before_batch_transfer)\n",
      "        4    0.000    0.000    0.003    0.001 inheritance.py:19(get_all_subclasses)\n",
      "       14    0.000    0.000    0.000    0.000 threading.py:276(_acquire_restore)\n",
      "       35    0.000    0.000    0.000    0.000 ATNDeserializer.py:462(<lambda>)\n",
      "       97    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "        1    0.000    0.000    0.002    0.002 base.py:404(Container)\n",
      "      5/3    0.000    0.000    0.000    0.000 basecontainer.py:234(get_node_value)\n",
      "        3    0.000    0.000    0.000    0.000 emitter.py:437(check_simple_key)\n",
      "        2    0.000    0.000    0.002    0.001 configuration_utils.py:990(to_json_string)\n",
      "        1    0.000    0.000    0.001    0.001 event_file_writer.py:54(__init__)\n",
      "       55    0.000    0.000    0.000    0.000 _compiler.py:31(_combine_flags)\n",
      "        7    0.000    0.000    0.000    0.000 evaluation_loop.py:90(<listcomp>)\n",
      "       11    0.000    0.000    0.000    0.000 typing.py:1012(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 evaluation_loop.py:343(_on_before_fetch)\n",
      "        9    0.000    0.000    0.000    0.000 __init__.py:1319(disable)\n",
      "       22    0.000    0.000    0.000    0.000 uuid.py:334(hex)\n",
      "        2    0.000    0.000    0.000    0.000 logger_connector.py:201(on_batch_end)\n",
      "        4    0.000    0.000    0.000    0.000 features.py:1611(<dictcomp>)\n",
      "       15    0.000    0.000    0.000    0.000 enum.py:929(_check_for_existing_members_)\n",
      "        1    0.000    0.000    0.000    0.000 import_utils.py:1508(_get_module)\n",
      "        2    0.000    0.000    0.000    0.000 typing.py:1896(_get_protocol_attrs)\n",
      "        5    0.000    0.000    0.000    0.000 progress.py:146(increment_started)\n",
      "       38    0.000    0.000    0.000    0.000 {built-in method fromkeys}\n",
      "        2    0.000    0.000    0.000    0.000 _base.py:646(__exit__)\n",
      "        4    0.000    0.000    0.000    0.000 model_summary.py:412(get_human_readable_count)\n",
      "       49    0.000    0.000    0.000    0.000 enum.py:58(_is_sunder)\n",
      "       10    0.000    0.000    0.000    0.000 enum.py:975(_find_data_type_)\n",
      "        6    0.000    0.000    0.000    0.000 queue.py:209(_qsize)\n",
      "       19    0.000    0.000    0.000    0.000 _utils.py:567(_is_interpolation)\n",
      "        1    0.000    0.000    0.000    0.000 variable_pb2.py:1(<module>)\n",
      "        1    0.000    0.000    0.059    0.059 tensor_util.py:1(<module>)\n",
      "      210    0.000    0.000    0.000    0.000 api_implementation.py:151(Type)\n",
      "        1    0.000    0.000    0.003    0.003 dictconfig.py:649(_set_value_impl)\n",
      "        2    0.000    0.000    0.000    0.000 weakref.py:414(__getitem__)\n",
      "        1    0.000    0.000    0.013    0.013 writer.py:1258(close)\n",
      "       14    0.000    0.000    0.000    0.000 trait_types.py:402(validate)\n",
      "        1    0.000    0.000    0.000    0.000 emitter.py:38(__init__)\n",
      "       72    0.000    0.000    0.000    0.000 encoder.py:414(_iterencode)\n",
      "        1    0.000    0.000    0.001    0.001 _flagvalues.py:40(FlagValues)\n",
      "        3    0.000    0.000    0.000    0.000 threading.py:1214(daemon)\n",
      "        7    0.000    0.000    0.000    0.000 omegaconf.py:372(register_new_resolver)\n",
      "       16    0.000    0.000    0.000    0.000 <frozen io>:60(__getattr__)\n",
      "       18    0.000    0.000    0.000    0.000 _utils.py:205(is_union_annotation)\n",
      "        2    0.000    0.000    0.000    0.000 tokenizer_13a.py:11(__init__)\n",
      "      210    0.000    0.000    0.000    0.000 pickle.py:605(persistent_id)\n",
      "       24    0.000    0.000    0.000    0.000 traitlets.py:1449(hold_trait_notifications)\n",
      "        1    0.000    0.000    0.000    0.000 training_epoch_loop.py:147(reset)\n",
      "        1    0.000    0.000    0.018    0.018 text_format.py:1(<module>)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.dir}\n",
      "       14    0.000    0.000    0.000    0.000 dataclasses.py:827(_set_new_attribute)\n",
      "        1    0.000    0.000    0.002    0.002 resource_handle_pb2.py:1(<module>)\n",
      "       28    0.000    0.000    0.000    0.000 typing.py:1522(__mro_entries__)\n",
      "       13    0.000    0.000    0.000    0.000 data.py:17(__len__)\n",
      "        8    0.000    0.000    0.000    0.000 {method 'split' of 're.Pattern' objects}\n",
      "        3    0.000    0.000    0.036    0.012 warnings.py:96(_showwarnmsg)\n",
      "        1    0.000    0.000    0.001    0.001 basecontainer.py:1(<module>)\n",
      "        4    0.000    0.000    0.071    0.018 logger_connector.py:229(metrics)\n",
      "       16    0.000    0.000    0.000    0.000 resolver.py:143(resolve)\n",
      "       96    0.000    0.000    0.000    0.000 tokenization_utils_base.py:3883(_eventual_warn_about_too_long_sequence)\n",
      "       34    0.000    0.000    0.000    0.000 inspect.py:1443(repl)\n",
      "      3/2    0.000    0.000    0.003    0.002 core.py:4108(parseImpl)\n",
      "        2    0.000    0.000    0.000    0.000 combined_loader.py:313(flattened)\n",
      "       26    0.000    0.000    0.000    0.000 threading.py:264(__enter__)\n",
      "        2    0.000    0.000    0.000    0.000 optimizer.py:47(__init__)\n",
      "        1    0.000    0.000    0.001    0.001 listconfig.py:42(ListConfig)\n",
      "        1    0.000    0.000    0.001    0.001 local.py:60(ls)\n",
      "        1    0.000    0.000    0.001    0.001 basecontainer.py:56(BaseContainer)\n",
      "        1    0.000    0.000    0.000    0.000 types_pb2.py:1(<module>)\n",
      "        2    0.000    0.000    0.000    0.000 dataloader.py:93(_get_distributed_settings)\n",
      "       28    0.000    0.000    0.000    0.000 ATNState.py:254(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 ErrorStrategy.py:1(<module>)\n",
      "       39    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:164(_path_isdir)\n",
      "       12    0.000    0.000    0.000    0.000 std.py:285(format_interval)\n",
      "        1    0.000    0.000    0.013    0.013 Lexer.py:1(<module>)\n",
      "       34    0.000    0.000    0.000    0.000 sacrebleu.py:156(<genexpr>)\n",
      "       10    0.000    0.000    0.002    0.000 py_utils.py:221(<dictcomp>)\n",
      "       10    0.000    0.000    0.000    0.000 std.py:230(__call__)\n",
      "        8    0.000    0.000    0.000    0.000 data.py:330(_wrap_attr_method)\n",
      "        4    0.000    0.000    0.000    0.000 nodes.py:143(_validate_and_convert_impl)\n",
      "        8    0.000    0.000    0.000    0.000 py_utils.py:314(first_non_null_value)\n",
      "        1    0.000    0.000    0.000    0.000 verifier_config_pb2.py:1(<module>)\n",
      "        9    0.000    0.000    0.000    0.000 emitter.py:133(need_events)\n",
      "       40    0.000    0.000    0.000    0.000 _parser.py:94(closegroup)\n",
      "        1    0.000    0.000    0.002    0.002 _helpers.py:1(<module>)\n",
      "       33    0.000    0.000    0.000    0.000 local.py:368(write)\n",
      "        1    0.000    0.000    0.000    0.000 hooks.py:278(on_before_backward)\n",
      "        2    0.000    0.000    0.000    0.000 fetchers.py:29(__init__)\n",
      "        3    0.000    0.000    0.002    0.001 core.py:4956(parseImpl)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method posix.scandir}\n",
      "        1    0.000    0.000    0.000    0.000 model_summary.py:268(summarize)\n",
      "       12    0.000    0.000    0.000    0.000 _utils.py:541(get_value_kind)\n",
      "        1    0.000    0.000    0.000    0.000 progress_bar.py:150(reset_dataloader_idx_tracker)\n",
      "        9    0.000    0.000    0.000    0.000 std.py:1154(__hash__)\n",
      "       34    0.000    0.000    0.000    0.000 inspect.py:292(isclass)\n",
      "        1    0.000    0.000    0.002    0.002 containers.py:1(<module>)\n",
      "        2    0.000    0.000    0.002    0.001 info.py:375(<dictcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 search.py:420(__init__)\n",
      "       94    0.000    0.000    0.000    0.000 typing.py:1810(<genexpr>)\n",
      "        5    0.000    0.000    0.000    0.000 enum.py:1004(_find_new_)\n",
      "        1    0.000    0.000    0.003    0.003 tensor_pb2.py:1(<module>)\n",
      "        5    0.000    0.000    0.000    0.000 copyreg.py:113(_slotnames)\n",
      "        2    0.000    0.000    0.000    0.000 results.py:215(__delitem__)\n",
      "        2    0.000    0.000    0.002    0.001 info.py:374(copy)\n",
      "       15    0.000    0.000    0.000    0.000 utils.py:83(wrapper_setattr)\n",
      "        2    0.000    0.000    0.000    0.000 listconfig.py:90(_validate_set)\n",
      "        1    0.000    0.000    0.011    0.011 LexerATNSimulator.py:1(<module>)\n",
      "        2    0.000    0.000    0.000    0.000 utils.py:360(_prepare_model_inputs)\n",
      "        4    0.000    0.000    0.000    0.000 iostream.py:550(_is_master_process)\n",
      "        1    0.000    0.000    0.019    0.019 data.py:51(setup)\n",
      "       18    0.000    0.000    0.001    0.000 specifiers.py:290(wrapped)\n",
      "       63    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.RLock' objects}\n",
      "        3    0.000    0.000    0.000    0.000 emitter.py:580(prepare_tag)\n",
      "        1    0.000    0.000    0.001    0.001 evaluation_loop.py:454(_verify_dataloader_idx_requirement)\n",
      "       47    0.000    0.000    0.000    0.000 traitlets.py:4016(validate_elements)\n",
      "        1    0.000    0.000    0.010    0.010 trainer.py:1075(__setup_profiler)\n",
      "        1    0.000    0.000    0.003    0.003 checkpoint_connector.py:82(_select_ckpt_path)\n",
      "       61    0.000    0.000    0.000    0.000 threading.py:1145(name)\n",
      "        3    0.000    0.000    0.006    0.002 result.py:426(update_metrics)\n",
      "      5/3    0.000    0.000    0.002    0.001 basecontainer.py:622(_wrap_value_and_set)\n",
      "        5    0.000    0.000    0.000    0.000 trainer.py:1534(num_training_batches)\n",
      "       14    0.000    0.000    0.000    0.000 version.py:351(public)\n",
      "        1    0.000    0.000    0.001    0.001 data_connector.py:102(attach_data)\n",
      "        1    0.000    0.000    0.000    0.000 coordination_config_pb2.py:1(<module>)\n",
      "        2    0.000    0.000    0.001    0.000 __init__.py:569(join_continuation)\n",
      "        2    0.000    0.000    0.000    0.000 trainer.py:1167(device_ids)\n",
      "        2    0.000    0.000    0.000    0.000 distributed.py:381(_distributed_is_initialized)\n",
      "        1    0.000    0.000    0.000    0.000 typing.py:2858(__new__)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:428(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 model_summary.py:73(_summary)\n",
      "        2    0.000    0.000    0.002    0.001 encoder.py:1(<module>)\n",
      "       20    0.000    0.000    0.000    0.000 features.py:1657(<dictcomp>)\n",
      "        1    0.000    0.000    0.001    0.001 dictconfig.py:57(DictConfig)\n",
      "        1    0.000    0.000    0.001    0.001 _ops.py:468(__init__)\n",
      "        3    0.000    0.000    0.000    0.000 progress.py:158(increment_completed)\n",
      "        1    0.000    0.000    0.002    0.002 _flagvalues.py:1(<module>)\n",
      "        8    0.000    0.000    0.000    0.000 info.py:172(__post_init__)\n",
      "        1    0.000    0.000    0.000    0.000 tokenizer_re.py:7(TokenizerRegexp)\n",
      "        4    0.000    0.000    0.000    0.000 <frozen posixpath>:397(abspath)\n",
      "        1    0.000    0.000    0.003    0.003 well_known_types.py:1(<module>)\n",
      "        2    0.000    0.000    0.002    0.001 configuration_utils.py:395(__hash__)\n",
      "        1    0.000    0.000    0.011    0.011 data_connector.py:79(prepare_data)\n",
      "        1    0.000    0.000    0.002    0.002 _flag.py:1(<module>)\n",
      "        2    0.000    0.000    0.000    0.000 logits_process.py:1474(__init__)\n",
      "        2    0.000    0.000    0.002    0.001 data_connector.py:183(_prepare_dataloader)\n",
      "        1    0.000    0.000    0.000    0.000 OmegaConfGrammarParser.py:488(ListContainerContext)\n",
      "        4    0.000    0.000    0.000    0.000 features.py:1602(wrapper)\n",
      "        5    0.000    0.000    0.000    0.000 spec.py:718(isdir)\n",
      "        9    0.000    0.000    0.000    0.000 _weakrefset.py:63(__iter__)\n",
      "       10    0.000    0.000    0.000    0.000 enum.py:939(_get_mixins_)\n",
      "        1    0.000    0.000    0.000    0.000 omegaconf.py:542(to_container)\n",
      "       21    0.000    0.000    0.000    0.000 {built-in method time.time}\n",
      "        1    0.000    0.000    0.001    0.001 grammar_visitor.py:39(GrammarVisitor)\n",
      "        1    0.000    0.000    0.034    0.034 OmegaConfGrammarLexer.py:1(<module>)\n",
      "       13    0.000    0.000    0.000    0.000 ATNState.py:209(__init__)\n",
      "        1    0.000    0.000    0.011    0.011 model_summary.py:307(_get_summary_data)\n",
      "        1    0.000    0.000    0.000    0.000 text_encoding.py:50(<listcomp>)\n",
      "        1    0.000    0.000    0.072    0.072 evaluation_loop.py:328(_on_evaluation_epoch_end)\n",
      "       47    0.000    0.000    0.000    0.000 typing.py:455(__repr__)\n",
      "        5    0.000    0.000    0.000    0.000 core.py:2345(parseImpl)\n",
      "        1    0.000    0.000    0.054    0.054 automatic.py:222(zero_grad_fn)\n",
      "        1    0.000    0.000    0.000    0.000 PredictionMode.py:21(PredictionMode)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method torch.set_vital}\n",
      "        1    0.000    0.000    0.011    0.011 api_implementation.py:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 OmegaConfGrammarParser.py:12(serializedATN)\n",
      "        2    0.000    0.000    0.000    0.000 table.py:1776(list_table_cache_files)\n",
      "        9    0.000    0.000    0.000    0.000 worker.py:89(get_worker_info)\n",
      "        1    0.000    0.000    0.008    0.008 device_dtype_mixin.py:49(to)\n",
      "       60    0.000    0.000    0.000    0.000 _dill.py:125(<genexpr>)\n",
      "       69    0.000    0.000    0.000    0.000 {method 'setdefault' of 'dict' objects}\n",
      "        7    0.000    0.000    0.000    0.000 lazy.py:83(_memoize)\n",
      "        4    0.000    0.000    0.001    0.000 nodes.py:128(__init__)\n",
      "        1    0.000    0.000    0.007    0.007 decoder.py:1(<module>)\n",
      "        5    0.000    0.000    0.000    0.000 <frozen posixpath>:229(expanduser)\n",
      "        2    0.000    0.000    0.000    0.000 bleu.py:101(<listcomp>)\n",
      "        1    0.000    0.000    0.001    0.001 Transition.py:1(<module>)\n",
      "      3/2    0.000    0.000    0.001    0.000 core.py:4779(parseImpl)\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method posix.cpu_count}\n",
      "       21    0.000    0.000    0.001    0.000 _utils.py:447(is_structured_config)\n",
      "      351    0.000    0.000    0.000    0.000 {built-in method builtins.chr}\n",
      "        4    0.000    0.000    0.000    0.000 eval_frame.py:138(_set_current_backend)\n",
      "        4    0.000    0.000    0.000    0.000 utils.py:197(_supports_unicode)\n",
      "       26    0.000    0.000    0.000    0.000 configurable.py:553(instance)\n",
      "        1    0.000    0.000    0.000    0.000 seed.py:105(_collect_rng_states)\n",
      "       28    0.000    0.000    0.000    0.000 ATNDeserializer.py:493(<lambda>)\n",
      "        1    0.000    0.000    0.000    0.000 full_type_pb2.py:1(<module>)\n",
      "        5    0.000    0.000    0.061    0.012 summary_v2.py:1(<module>)\n",
      "        4    0.000    0.000    0.000    0.000 representer.py:171(represent_float)\n",
      "        2    0.000    0.000    0.001    0.001 fromnumeric.py:2512(cumsum)\n",
      "        4    0.000    0.000    0.000    0.000 data_connector.py:313(is_defined)\n",
      "       22    0.000    0.000    0.000    0.000 _utils.py:462(get_type_of)\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method _hashlib.openssl_md5}\n",
      "        1    0.000    0.000    0.001    0.001 model_summary.py:80(summarize)\n",
      "        1    0.000    0.000    0.000    0.000 versions_pb2.py:1(<module>)\n",
      "        1    0.000    0.000    0.001    0.001 specifiers.py:124(__hash__)\n",
      "       16    0.000    0.000    0.001    0.000 _dill.py:122(numpyufunc)\n",
      "        3    0.000    0.000    0.000    0.000 logger_connector.py:177(on_batch_start)\n",
      "        5    0.000    0.000    0.000    0.000 event_file_writer.py:165(write)\n",
      "        2    0.000    0.000    0.000    0.000 fingerprint.py:267(update_fingerprint)\n",
      "        1    0.000    0.000    0.000    0.000 ParserATNSimulator.py:257(ParserATNSimulator)\n",
      "        5    0.000    0.000    0.007    0.001 cloud_io.py:83(_is_object_storage)\n",
      "        1    0.000    0.000    0.000    0.000 optimizer.py:411(_patch_step_function)\n",
      "        5    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1101(_sanity_check)\n",
      "       17    0.000    0.000    0.000    0.000 dataclasses.py:449(_field_init)\n",
      "        1    0.000    0.000    0.000    0.000 hooks.py:257(on_before_zero_grad)\n",
      "        2    0.000    0.000    0.000    0.000 _pytree.py:503(__init__)\n",
      "        8    0.000    0.000    0.000    0.000 states.py:67(dataloader_prefix)\n",
      "        2    0.000    0.000    0.000    0.000 deepspeed.py:288(is_deepspeed_zero3_enabled)\n",
      "        3    0.000    0.000    0.000    0.000 combined_loader.py:96(__len__)\n",
      "       12    0.000    0.000    0.000    0.000 loader.py:260(merge)\n",
      "        2    0.000    0.000    0.001    0.001 fromnumeric.py:71(_wrapreduction)\n",
      "        9    0.000    0.000    0.000    0.000 dictconfig.py:455(_get_node)\n",
      "        1    0.000    0.000    0.001    0.001 _flag.py:36(Flag)\n",
      "        1    0.000    0.000    0.000    0.000 subprocess.py:300(_args_from_interpreter_flags)\n",
      "        1    0.000    0.000    0.015    0.015 strategy.py:131(setup_optimizers)\n",
      "       21    0.000    0.000    0.000    0.000 {method 'release' of '_thread.lock' objects}\n",
      "        4    0.000    0.000    0.000    0.000 writer.py:100(add_summary)\n",
      "       12    0.000    0.000    0.004    0.000 traitlets.py:1126(compatible_observer)\n",
      "       42    0.000    0.000    0.000    0.000 pickle.py:209(start_framing)\n",
      "        1    0.000    0.000    0.002    0.002 gfile.py:1(<module>)\n",
      "       22    0.000    0.000    0.000    0.000 {method '__enter__' of '_thread.lock' objects}\n",
      "        2    0.000    0.000    0.000    0.000 tqdm_progress.py:165(process_position)\n",
      "        1    0.000    0.000    0.021    0.021 app.py:1(<module>)\n",
      "        2    0.000    0.000    0.000    0.000 ATNDeserializer.py:102(checkUUID)\n",
      "        3    0.000    0.000    0.000    0.000 generic.py:176(is_torch_device)\n",
      "        3    0.000    0.000    0.000    0.000 builder.py:48(BuildMessageAndEnumDescriptors)\n",
      "       94    0.000    0.000    0.000    0.000 _compiler.py:426(_get_iscased)\n",
      "        1    0.000    0.000    0.000    0.000 requirements.py:64(<lambda>)\n",
      "        1    0.000    0.000    0.021    0.021 model_summary.py:59(on_fit_start)\n",
      "        5    0.000    0.000    0.000    0.000 version.py:490(_cmpkey)\n",
      "        6    0.000    0.000    0.000    0.000 listconfig.py:402(_get_node)\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method fcntl.flock}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'get_state' of 'torch._C.Generator' objects}\n",
      "        2    0.000    0.000    0.001    0.000 fetchers.py:139(reset)\n",
      "        1    0.000    0.000    0.000    0.000 fit_loop.py:434(_load_combined_loader_states)\n",
      "        2    0.000    0.000    0.000    0.000 bleu.py:290(<listcomp>)\n",
      "       11    0.000    0.000    0.000    0.000 traitlets.py:3032(validate)\n",
      "       16    0.000    0.000    0.005    0.000 ATNDeserializer.py:524(lexerActionFactory)\n",
      "        1    0.000    0.000    0.005    0.005 PredictionContext.py:1(<module>)\n",
      "       54    0.000    0.000    0.000    0.000 version.py:301(<genexpr>)\n",
      "        1    0.000    0.000    0.006    0.006 graph_pb2.py:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 tensor_description_pb2.py:1(<module>)\n",
      "        2    0.000    0.000    0.000    0.000 combined_loader.py:29(__init__)\n",
      "       12    0.000    0.000    0.000    0.000 types.py:48(is_null)\n",
      "        1    0.000    0.000    0.000    0.000 summary.py:352(scalar)\n",
      "       14    0.000    0.000    0.000    0.000 _dill.py:322(__missing__)\n",
      "        2    0.000    0.000    0.001    0.001 fromnumeric.py:40(_wrapit)\n",
      "        1    0.000    0.000    0.000    0.000 random.py:77(set_rng_state_all)\n",
      "        1    0.000    0.000    0.000    0.000 spawn.py:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 tensorboard.py:325(_sanitize_params)\n",
      "        4    0.000    0.000    0.000    0.000 notebook.py:201(colour)\n",
      "        1    0.000    0.000    0.193    0.193 utilities.py:59(_log_hyperparams)\n",
      "        1    0.000    0.000    0.000    0.000 tokenize.py:677(__init__)\n",
      "       24    0.000    0.000    0.000    0.000 pretty.py:321(_get_mro)\n",
      "    34/22    0.000    0.000    0.001    0.000 copy.py:264(<genexpr>)\n",
      "        2    0.000    0.000    0.000    0.000 hooks.py:100(on_validation_batch_end)\n",
      "        1    0.000    0.000    0.003    0.003 combined_loader.py:41(__iter__)\n",
      "        1    0.000    0.000    0.000    0.000 trainer.py:1456(received_sigterm)\n",
      "        1    0.000    0.000    0.000    0.000 model_checkpoint.py:268(setup)\n",
      "        1    0.000    0.000    0.001    0.001 _pytorch_graph.py:1(<module>)\n",
      "       22    0.000    0.000    0.000    0.000 _compat.py:83(get_generic_base)\n",
      "        2    0.000    0.000    0.002    0.001 std.py:1357(reset)\n",
      "       23    0.000    0.000    0.000    0.000 ipkernel.py:58(_get_comm_manager)\n",
      "        2    0.000    0.000    0.000    0.000 encoder.py:260(_make_iterencode)\n",
      "        3    0.000    0.000    0.000    0.000 import_utils.py:1436(<listcomp>)\n",
      "       11    0.000    0.000    0.000    0.000 std.py:109(__enter__)\n",
      "        1    0.000    0.000    0.000    0.000 progress_bar.py:80(total_train_batches)\n",
      "        9    0.000    0.000    0.000    0.000 dictconfig.py:149(_validate_get)\n",
      "        8    0.000    0.000    0.000    0.000 typing.py:1268(__mro_entries__)\n",
      "        1    0.000    0.000    0.000    0.000 saver_pb2.py:1(<module>)\n",
      "        8    0.000    0.000    0.019    0.002 widget_layout.py:80(__init__)\n",
      "        6    0.000    0.000    0.000    0.000 traitlets.py:1713(_register_validator)\n",
      "        2    0.000    0.000    0.000    0.000 pickle.py:925(save_list)\n",
      "       18    0.000    0.000    0.000    0.000 version.py:368(is_prerelease)\n",
      "        6    0.000    0.000    0.000    0.000 imports.py:49(_graphcore_available_and_importable)\n",
      "        1    0.000    0.000    0.001    0.001 nodes.py:1(<module>)\n",
      "        8    0.000    0.000    0.000    0.000 _api.py:147(lock_file)\n",
      "        1    0.000    0.000    0.086    0.086 v1.py:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 model_summary.py:203(__init__)\n",
      "       11    0.000    0.000    0.000    0.000 std.py:112(__exit__)\n",
      "        1    0.000    0.000    0.002    0.002 tokenize.py:296(__init__)\n",
      "       11    0.000    0.000    0.000    0.000 _utils.py:521(_is_none)\n",
      "        1    0.000    0.000    0.000    0.000 LexerATNSimulator.py:52(LexerATNSimulator)\n",
      "        1    0.000    0.000    0.001    0.001 listconfig.py:1(<module>)\n",
      "       30    0.000    0.000    0.000    0.000 signal.py:60(getsignal)\n",
      "       96    0.000    0.000    0.000    0.000 tokenization_utils.py:891(prepare_for_tokenization)\n",
      "        2    0.000    0.000    0.000    0.000 tqdm_progress.py:425(_should_update)\n",
      "        1    0.000    0.000    0.012    0.012 descriptor.py:1(<module>)\n",
      "       49    0.000    0.000    0.000    0.000 enum.py:69(_is_internal_class)\n",
      "        1    0.000    0.000    0.000    0.000 allocation_description_pb2.py:1(<module>)\n",
      "       60    0.000    0.000    0.000    0.000 _dill.py:113(<genexpr>)\n",
      "        8    0.000    0.000    0.000    0.000 result.py:60(should)\n",
      "       34    0.000    0.000    0.000    0.000 enum.py:37(_is_descriptor)\n",
      "        1    0.000    0.000    0.000    0.000 rpc_options_pb2.py:1(<module>)\n",
      "        3    0.000    0.000    0.000    0.000 _utils.py:613(is_int)\n",
      "        2    0.000    0.000    0.000    0.000 sampler.py:261(__init__)\n",
      "        4    0.000    0.000    0.011    0.003 _base.py:612(result_iterator)\n",
      "       10    0.000    0.000    0.000    0.000 enum.py:769(__getattr__)\n",
      "        4    0.000    0.000    0.000    0.000 typing.py:1625(__getitem_inner__)\n",
      "      8/6    0.000    0.000    0.000    0.000 copy.py:211(<listcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 tokenizer_re.py:12(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:799(UnionNode)\n",
      "       99    0.000    0.000    0.000    0.000 version.py:459(<lambda>)\n",
      "        3    0.000    0.000    0.015    0.005 dataclasses.py:1219(wrap)\n",
      "        7    0.000    0.000    0.000    0.000 lazy.py:39(wrapper)\n",
      "        4    0.000    0.000    0.007    0.002 <frozen importlib.util>:73(find_spec)\n",
      "        3    0.000    0.000    0.000    0.000 _utils.py:115(str_representer)\n",
      "        3    0.000    0.000    0.000    0.000 pytorch.py:165(_step)\n",
      "        2    0.000    0.000    0.000    0.000 _pytree.py:479(__post_init__)\n",
      "        1    0.000    0.000    0.000    0.000 memory.py:150(empty_cache)\n",
      "        3    0.000    0.000    0.000    0.000 builder.py:70(BuildTopDescriptorsAndMessages)\n",
      "        1    0.000    0.000    0.000    0.000 callback_connector.py:151(_attach_model_logging_functions)\n",
      "       10    0.000    0.000    0.000    0.000 __init__.py:237(_releaseLock)\n",
      "        1    0.000    0.000    0.052    0.052 fit_loop.py:313(on_run_start)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:292(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 OmegaConfGrammarParserVisitor.py:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 signal_connector.py:126(_get_current_signal_handlers)\n",
      "        1    0.000    0.000    0.050    0.050 tqdm_progress.py:259(on_train_start)\n",
      "        1    0.000    0.000    0.001    0.001 _embedding.py:1(<module>)\n",
      "       16    0.000    0.000    0.000    0.000 _dill.py:124(numpydtype)\n",
      "        4    0.000    0.000    0.000    0.000 utils.py:906(_merge_criteria_processor_list)\n",
      "        1    0.000    0.000    0.000    0.000 ATNDeserializer.py:33(ATNDeserializer)\n",
      "       15    0.000    0.000    0.000    0.000 ATNState.py:243(__init__)\n",
      "        9    0.000    0.000    0.000    0.000 results.py:191(__getitem__)\n",
      "       12    0.000    0.000    0.000    0.000 configurable.py:97(notice_config_override)\n",
      "       52    0.000    0.000    0.000    0.000 features.py:508(__call__)\n",
      "       32    0.000    0.000    0.000    0.000 bleu.py:396(<listcomp>)\n",
      "       96    0.000    0.000    0.000    0.000 tokenization_utils_base.py:3903(_switch_to_input_mode)\n",
      "        1    0.000    0.000    0.001    0.001 specifiers.py:120(_canonical_spec)\n",
      "        8    0.000    0.000    0.000    0.000 __init__.py:198(split)\n",
      "        4    0.000    0.000    0.000    0.000 data.py:303(<dictcomp>)\n",
      "        6    0.000    0.000    0.000    0.000 pathlib.py:682(with_suffix)\n",
      "        8    0.000    0.000    0.000    0.000 types.py:150(is_fixed_size_list)\n",
      "        8    0.000    0.000    0.000    0.000 omegaconf.py:971(read_write)\n",
      "        1    0.000    0.000    0.006    0.006 Errors.py:1(<module>)\n",
      "       24    0.000    0.000    0.000    0.000 formatters.py:273(_get_type)\n",
      "       44    0.000    0.000    0.000    0.000 <frozen _collections_abc>:262(__subclasshook__)\n",
      "        8    0.000    0.000    0.000    0.000 inspect.py:946(<genexpr>)\n",
      "        9    0.000    0.000    0.000    0.000 {built-in method utcfromtimestamp}\n",
      "       15    0.000    0.000    0.000    0.000 ATNDeserializer.py:486(<lambda>)\n",
      "    14/13    0.000    0.000    0.000    0.000 builder.py:56(BuildNestedDescriptors)\n",
      "        1    0.000    0.000    0.000    0.000 emitter.py:226(expect_document_root)\n",
      "        6    0.000    0.000    0.004    0.001 <frozen codecs>:319(decode)\n",
      "       34    0.000    0.000    0.000    0.000 pickle.py:740(save_none)\n",
      "        2    0.000    0.000    0.000    0.000 weakref.py:369(remove)\n",
      "       22    0.000    0.000    0.000    0.000 widget.py:361(_call_widget_constructed)\n",
      "        1    0.000    0.000    0.001    0.001 modeling_fsmt.py:1018(fill_with_neg_inf)\n",
      "        4    0.000    0.000    0.000    0.000 widget_float.py:51(_validate_max)\n",
      "        7    0.000    0.000    0.000    0.000 emitter.py:515(process_scalar)\n",
      "       15    0.000    0.000    0.000    0.000 ATNState.py:229(__init__)\n",
      "        7    0.000    0.000    0.000    0.000 typing.py:1611(__getitem__)\n",
      "        2    0.000    0.000    0.000    0.000 functools.py:479(lru_cache)\n",
      "        1    0.000    0.000    0.000    0.000 combined_loader.py:68(__init__)\n",
      "        2    0.000    0.000    0.001    0.000 training_epoch_loop.py:412(_should_check_val_epoch)\n",
      "        2    0.000    0.000    0.000    0.000 emitter.py:178(expect_document_start)\n",
      "        5    0.000    0.000    0.000    0.000 event_file_writer.py:106(add_event)\n",
      "        1    0.000    0.000    0.000    0.000 evaluation_loop.py:284(_on_evaluation_start)\n",
      "       42    0.000    0.000    0.000    0.000 {method 'getbuffer' of '_io.BytesIO' objects}\n",
      "        4    0.000    0.000    0.000    0.000 writer.py:83(add_event)\n",
      "        1    0.000    0.000    0.002    0.002 text_format.py:1278(Tokenizer)\n",
      "        1    0.000    0.000    0.000    0.000 signal.py:87(valid_signals)\n",
      "        5    0.000    0.000    0.000    0.000 {built-in method posix.close}\n",
      "        2    0.000    0.000    0.004    0.002 features.py:1244(<dictcomp>)\n",
      "        1    0.000    0.000    0.014    0.014 optimizer.py:95(__init__)\n",
      "       15    0.000    0.000    0.000    0.000 dataclasses.py:820(_set_qualname)\n",
      "        3    0.000    0.000    0.000    0.000 dataclasses.py:592(<listcomp>)\n",
      "        6    0.000    0.000    0.000    0.000 tqdm_progress.py:161(refresh_rate)\n",
      "        8    0.000    0.000    0.000    0.000 dataloader.py:457(__len__)\n",
      "       42    0.000    0.000    0.000    0.000 pickle.py:205(__init__)\n",
      "       65    0.000    0.000    0.000    0.000 _parser.py:166(__setitem__)\n",
      "        1    0.000    0.000    0.071    0.071 logger_connector.py:193(on_epoch_end)\n",
      "       15    0.000    0.000    0.000    0.000 ATNDeserializer.py:491(<lambda>)\n",
      "      9/1    0.000    0.000    0.000    0.000 serializer.py:60(anchor_node)\n",
      "        1    0.000    0.000    0.001    0.001 listconfig.py:620(_set_value_impl)\n",
      "        2    0.000    0.000    0.000    0.000 fetchers.py:95(__init__)\n",
      "       12    0.000    0.000    0.000    0.000 std.py:225(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 stopping_criteria.py:161(max_length)\n",
      "        1    0.000    0.000    0.001    0.001 text_encoding.py:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 model_checkpoint.py:327(on_validation_end)\n",
      "        3    0.000    0.000    0.000    0.000 core.py:497(get_compression)\n",
      "        2    0.000    0.000    0.000    0.000 utils.py:1135(_validate_generated_length)\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method _pickle.dumps}\n",
      "        1    0.000    0.000    0.003    0.003 evaluation_loop.py:293(_on_evaluation_model_eval)\n",
      "        1    0.000    0.000    0.009    0.009 optimizer.py:121(fill_qmap)\n",
      "        1    0.000    0.000    0.000    0.000 ATNConfigSet.py:1(<module>)\n",
      "        1    0.000    0.000    0.008    0.008 single_device.py:76(model_to_device)\n",
      "        2    0.000    0.000    0.000    0.000 std.py:152(__init__)\n",
      "       69    0.000    0.000    0.000    0.000 {method 'items' of 'mappingproxy' objects}\n",
      "        1    0.000    0.000    0.000    0.000 message.py:54(Message)\n",
      "       12    0.000    0.000    0.000    0.000 dictconfig.py:274(_validate_and_normalize_key)\n",
      "        1    0.000    0.000    0.000    0.000 tensor_shape.py:25(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 external_utils.py:6(is_compiling)\n",
      "        1    0.000    0.000    0.000    0.000 optimizer.py:365(profile_hook_step)\n",
      "        1    0.000    0.000    0.020    0.020 flags.py:1(<module>)\n",
      "        2    0.000    0.000    0.000    0.000 ATNDeserializer.py:446(readUUID)\n",
      "        1    0.000    0.000    0.001    0.001 Recognizer.py:1(<module>)\n",
      "        3    0.000    0.000    0.000    0.000 local.py:402(__getattr__)\n",
      "        2    0.000    0.000    0.001    0.001 fromnumeric.py:2979(prod)\n",
      "        4    0.000    0.000    0.000    0.000 result.py:463(valid_items)\n",
      "        1    0.000    0.000    0.000    0.000 gfile.py:829(close)\n",
      "        2    0.000    0.000    0.000    0.000 ATNDeserializer.py:109(readATN)\n",
      "        1    0.000    0.000    0.000    0.000 _utils.py:112(OmegaConfDumper)\n",
      "        5    0.000    0.000    0.000    0.000 distributed_c10d.py:453(default_pg)\n",
      "        2    0.000    0.000    0.000    0.000 module.py:91(info)\n",
      "        1    0.000    0.000    0.007    0.007 omegaconf.py:748(to_yaml)\n",
      "       21    0.000    0.000    0.000    0.000 {method 'remove' of 'set' objects}\n",
      "        2    0.000    0.000    0.007    0.003 fetchers.py:49(__iter__)\n",
      "       33    0.000    0.000    0.000    0.000 {method 'write' of '_io.BufferedWriter' objects}\n",
      "       16    0.000    0.000    0.000    0.000 _utils.py:625(is_primitive_dict)\n",
      "       10    0.000    0.000    0.000    0.000 tokenization_utils_base.py:265(__getattr__)\n",
      "       12    0.000    0.000    0.000    0.000 dictconfig.py:277(_s_validate_and_normalize_key)\n",
      "        4    0.000    0.000    0.000    0.000 omegaconf.py:951(flag_override)\n",
      "       31    0.000    0.000    0.000    0.000 {method 'release' of '_thread.RLock' objects}\n",
      "       15    0.000    0.000    0.000    0.000 pytorch.py:133(is_training)\n",
      "        1    0.000    0.000    0.000    0.000 progress.py:167(reset)\n",
      "        6    0.000    0.000    0.000    0.000 pytorch.py:153(num_step)\n",
      "       13    0.000    0.000    0.000    0.000 ATNState.py:221(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 OmegaConfGrammarParser.py:98(<listcomp>)\n",
      "       50    0.000    0.000    0.000    0.000 dataclasses.py:425(<genexpr>)\n",
      "       26    0.000    0.000    0.000    0.000 {method 'difference' of 'set' objects}\n",
      "        3    0.000    0.000    0.003    0.001 dictconfig.py:316(__set_impl)\n",
      "        2    0.000    0.000    0.000    0.000 tqdm_progress.py:127(train_progress_bar)\n",
      "        6    0.000    0.000    0.000    0.000 progress.py:87(reset)\n",
      "       15    0.000    0.000    0.000    0.000 ATNDeserializer.py:490(<lambda>)\n",
      "        8    0.000    0.000    0.000    0.000 __init__.py:24(_module_matches_namespace)\n",
      "        1    0.000    0.000    0.000    0.000 profiler.py:81(__init__)\n",
      "     18/2    0.000    0.000    0.000    0.000 configuration_utils.py:1013(convert_keys_to_string)\n",
      "     12/8    0.000    0.000    0.000    0.000 typing.py:1506(<listcomp>)\n",
      "        4    0.000    0.000    0.001    0.000 logger_connector.py:221(reset_results)\n",
      "       62    0.000    0.000    0.000    0.000 hmac.py:139(_current)\n",
      "       16    0.000    0.000    0.000    0.000 _dill.py:112(ndarraysubclassinstance)\n",
      "        4    0.000    0.000    0.000    0.000 fingerprint.py:236(hexdigest)\n",
      "        2    0.000    0.000    0.000    0.000 displaypub.py:43(_validate_data)\n",
      "        9    0.000    0.000    0.000    0.000 emitter.py:469(process_tag)\n",
      "        3    0.000    0.000    0.001    0.000 dataclasses.py:588(_repr_fn)\n",
      "        2    0.000    0.000    0.000    0.000 tqdm_progress.py:440(convert_inf)\n",
      "        1    0.000    0.000    0.000    0.000 descriptor_pool.py:118(DescriptorPool)\n",
      "        4    0.000    0.000    0.000    0.000 emitter.py:395(expect_block_mapping_key)\n",
      "       10    0.000    0.000    0.000    0.000 LexerAction.py:64(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 checkpoint_connector.py:395(_restore_modules_and_callbacks)\n",
      "       64    0.000    0.000    0.000    0.000 tokenization_utils_base.py:1128(<listcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 cloud_io.py:60(get_filesystem)\n",
      "        1    0.000    0.000    0.008    0.008 omegaconf.py:208(save)\n",
      "        1    0.000    0.000    0.001    0.001 LexerAction.py:1(<module>)\n",
      "      5/3    0.000    0.000    0.002    0.001 omegaconf.py:1091(_maybe_wrap)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.vars}\n",
      "       24    0.000    0.000    0.000    0.000 bunch.py:16(__getattr__)\n",
      "        1    0.000    0.000    0.003    0.003 omegaconf.py:101(register_default_resolvers)\n",
      "        1    0.000    0.000    0.001    0.001 PredictionMode.py:1(<module>)\n",
      "        8    0.000    0.000    0.000    0.000 progress.py:56(reset)\n",
      "       15    0.000    0.000    0.000    0.000 strategy.py:352(model)\n",
      "       25    0.000    0.000    0.000    0.000 _utils.py:516(_is_missing_literal)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method posix.pipe}\n",
      "        7    0.000    0.000    0.000    0.000 result.py:163(is_mean_reduction)\n",
      "        2    0.000    0.000    0.000    0.000 strategy.py:109(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 wire_format.py:1(<module>)\n",
      "        7    0.000    0.000    0.000    0.000 representer.py:77(represent_scalar)\n",
      "       12    0.000    0.000    0.000    0.000 version.py:453(_parse_letter_version)\n",
      "       12    0.000    0.000    0.000    0.000 traitlets.py:1677(unobserve)\n",
      "        1    0.000    0.000    0.000    0.000 dict.py:1(<module>)\n",
      "        3    0.000    0.000    0.000    0.000 threading.py:804(_newname)\n",
      "       14    0.000    0.000    0.000    0.000 _utils.py:212(_resolve_optional)\n",
      "        4    0.000    0.000    0.000    0.000 features.py:1724(from_dict)\n",
      "        1    0.000    0.000    0.000    0.000 text_encoding.py:49(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 trainer.py:1511(val_dataloaders)\n",
      "       13    0.000    0.000    0.000    0.000 ATNDeserializer.py:492(<lambda>)\n",
      "       15    0.000    0.000    0.000    0.000 ATNState.py:235(__init__)\n",
      "        1    0.000    0.000    0.001    0.001 pkgutil.py:600(get_data)\n",
      "        1    0.000    0.000    0.000    0.000 profiler.py:77(_set_is_profiler_enabled)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:7(_make_name)\n",
      "       26    0.000    0.000    0.001    0.000 shutil.py:1443(_access_check)\n",
      "       10    0.000    0.000    0.000    0.000 pickle.py:322(_getattribute)\n",
      "        7    0.000    0.000    0.000    0.000 emitter.py:266(expect_scalar)\n",
      "        5    0.000    0.000    0.000    0.000 <frozen posixpath>:140(basename)\n",
      "        3    0.000    0.000    0.000    0.000 core.py:3954(<genexpr>)\n",
      "       32    0.000    0.000    0.000    0.000 utils.py:492(<genexpr>)\n",
      "        1    0.000    0.000    0.014    0.014 optimizer.py:326(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 encoder.py:224(floatstr)\n",
      "        1    0.000    0.000    0.000    0.000 tqdm_progress.py:254(on_sanity_check_end)\n",
      "       12    0.000    0.000    0.000    0.000 {built-in method _struct.calcsize}\n",
      "        1    0.000    0.000    0.000    0.000 DiagnosticErrorListener.py:1(<module>)\n",
      "        6    0.000    0.000    0.000    0.000 queue.py:213(_put)\n",
      "        9    0.000    0.000    0.000    0.000 dictconfig.py:144(_is_typed)\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method posix.umask}\n",
      "        3    0.000    0.000    0.000    0.000 std.py:1144(__del__)\n",
      "        4    0.000    0.000    0.000    0.000 version.py:492(_parse_local_version)\n",
      "       10    0.000    0.000    0.000    0.000 dataclasses.py:368(field)\n",
      "       13    0.000    0.000    0.000    0.000 ATNDeserializer.py:485(<lambda>)\n",
      "        3    0.000    0.000    0.000    0.000 tokenization_utils_base.py:800(<dictcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 local.py:377(seekable)\n",
      "       17    0.000    0.000    0.000    0.000 dataclasses.py:509(_init_param)\n",
      "        1    0.000    0.000    0.000    0.000 errors.py:42(ValidationError)\n",
      "        1    0.000    0.000    0.000    0.000 signal_connector.py:133(<dictcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 writer.py:171(SummaryWriter)\n",
      "       32    0.000    0.000    0.000    0.000 base.py:329(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:154(_tensor_or_tensors_to_tuple)\n",
      "        1    0.000    0.000    0.000    0.000 representer.py:18(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 result.py:175(is_min_reduction)\n",
      "        4    0.000    0.000    0.000    0.000 inspect.py:283(ismodule)\n",
      "        4    0.000    0.000    0.011    0.003 std.py:1157(__iter__)\n",
      "        2    0.000    0.000    0.001    0.000 utilities.py:187(_verify_dataloader_idx_requirement)\n",
      "        2    0.000    0.000    0.007    0.004 ATNDeserializer.py:87(reset)\n",
      "        2    0.000    0.000    0.000    0.000 _defines.py:152(DEFINE_flag)\n",
      "        4    0.000    0.000    0.000    0.000 <frozen posixpath>:389(normpath)\n",
      "        1    0.000    0.000    0.000    0.000 SemanticContext.py:1(<module>)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'discard' of 'set' objects}\n",
      "        1    0.000    0.000    0.013    0.013 writer.py:154(close)\n",
      "        5    0.000    0.000    0.000    0.000 contextlib.py:751(__init__)\n",
      "        2    0.000    0.000    0.001    0.000 apply_func.py:122(to_item)\n",
      "        1    0.000    0.000    0.000    0.000 signal.py:89(<setcomp>)\n",
      "        4    0.000    0.000    0.000    0.000 eval_frame.py:257(nothing)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:44(Metadata)\n",
      "        1    0.000    0.000    0.002    0.002 ATNConfig.py:1(<module>)\n",
      "        9    0.000    0.000    0.000    0.000 representer.py:136(ignore_aliases)\n",
      "        2    0.000    0.000    0.000    0.000 _helpers.py:111(get_calling_module_object_and_name)\n",
      "        1    0.000    0.000    0.000    0.000 errors.py:4(OmegaConfBaseException)\n",
      "        3    0.000    0.000    0.000    0.000 pathlib.py:530(_make_child)\n",
      "        1    0.000    0.000    0.004    0.004 ATN.py:1(<module>)\n",
      "       18    0.000    0.000    0.000    0.000 specifiers.py:144(_coerce_version)\n",
      "        1    0.000    0.000    0.000    0.000 DFA.py:1(<module>)\n",
      "        6    0.000    0.000    0.000    0.000 evaluation_loop.py:103(_is_sequential)\n",
      "        3    0.000    0.000    0.000    0.000 omegaconf.py:903(_get_obj_type)\n",
      "        1    0.000    0.000    0.002    0.002 ATNSimulator.py:1(<module>)\n",
      "        2    0.000    0.000    0.001    0.000 fetchers.py:71(reset)\n",
      "        1    0.000    0.000    0.000    0.000 tensorboard.py:200(log_metrics)\n",
      "        1    0.000    0.000    0.002    0.002 RuleContext.py:1(<module>)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen os>:200(makedirs)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'hexdigest' of '_hashlib.HASH' objects}\n",
      "        8    0.000    0.000    0.000    0.000 _dill.py:1040(_getattribute)\n",
      "       60    0.000    0.000    0.000    0.000 loader.py:245(_ensure_subconfig)\n",
      "       10    0.000    0.000    0.000    0.000 dataclasses.py:287(__init__)\n",
      "        9    0.000    0.000    0.000    0.000 threading.py:90(RLock)\n",
      "        1    0.000    0.000    0.000    0.000 strategy.py:164(setup_precision_plugin)\n",
      "        1    0.000    0.000    0.000    0.000 module.py:215(trainer)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method _signal.pthread_sigmask}\n",
      "        1    0.000    0.000    0.000    0.000 progress.py:199(reset)\n",
      "        8    0.000    0.000    0.000    0.000 threading.py:1199(daemon)\n",
      "        1    0.000    0.000    0.000    0.000 Lexer.py:30(Lexer)\n",
      "        1    0.000    0.000    0.001    0.001 configuration_validator.py:53(__verify_train_val_loop_configuration)\n",
      "        8    0.000    0.000    0.000    0.000 sampler.py:297(__len__)\n",
      "        5    0.000    0.000    0.000    0.000 enum.py:357(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 random.py:21(get_rng_state)\n",
      "        3    0.000    0.000    0.000    0.000 dataclasses.py:228(_recursive_repr)\n",
      "        4    0.000    0.000    0.000    0.000 specifiers.py:517(_compare_greater_than)\n",
      "       12    0.000    0.000    0.000    0.000 base.py:304(_is_none)\n",
      "        1    0.000    0.000    0.004    0.004 _utils.py:947(_ensure_container)\n",
      "        3    0.000    0.000    0.000    0.000 basecontainer.py:179(__len__)\n",
      "        4    0.000    0.000    0.000    0.000 _utils.py:741(is_primitive_type_annotation)\n",
      "        1    0.000    0.000    0.000    0.000 model_checkpoint.py:609(__resolve_ckpt_dir)\n",
      "        1    0.000    0.000    0.000    0.000 fit_loop.py:305(reset)\n",
      "        8    0.000    0.000    0.000    0.000 ATNDeserializer.py:436(readInt32)\n",
      "        3    0.000    0.000    0.000    0.000 memory.py:40(detach_and_move)\n",
      "        1    0.000    0.000    0.000    0.000 Trees.py:1(<module>)\n",
      "        6    0.000    0.000    0.000    0.000 tensorboard.py:137(root_dir)\n",
      "       26    0.000    0.000    0.000    0.000 {method 'count' of 'list' objects}\n",
      "        2    0.000    0.000    0.000    0.000 trainer.py:1214(model)\n",
      "        3    0.000    0.000    0.000    0.000 dataclasses.py:392(_fields_in_init_order)\n",
      "        2    0.000    0.000    0.000    0.000 results.py:533(copy)\n",
      "       65    0.000    0.000    0.000    0.000 version.py:432(_parse_local_version)\n",
      "        1    0.000    0.000    0.000    0.000 util.py:48(debug)\n",
      "       46    0.000    0.000    0.000    0.000 {method 'hexdigest' of 'xxhash.xxh64' objects}\n",
      "       20    0.000    0.000    0.000    0.000 version.py:316(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 Parser.py:47(Parser)\n",
      "        2    0.000    0.000    0.000    0.000 utils.py:3067(<listcomp>)\n",
      "        3    0.000    0.000    0.000    0.000 {method 'sort' of 'list' objects}\n",
      "       42    0.000    0.000    0.000    0.000 pickle.py:514(put)\n",
      "        1    0.000    0.000    0.000    0.000 importstring.py:9(import_item)\n",
      "        1    0.000    0.000    0.000    0.000 tempfile.py:153(__next__)\n",
      "       12    0.000    0.000    0.000    0.000 traitlets.py:1587(_remove_notifiers)\n",
      "        2    0.000    0.000    0.000    0.000 optimizer.py:158(_to_lightning_optimizer)\n",
      "       10    0.000    0.000    0.000    0.000 uuid.py:240(__eq__)\n",
      "        7    0.000    0.000    0.000    0.000 emitter.py:494(choose_scalar_style)\n",
      "        1    0.000    0.000    0.001    0.001 event_file_writer.py:1(<module>)\n",
      "        1    0.000    0.000    0.007    0.007 descriptor_pool.py:1(<module>)\n",
      "        1    0.000    0.000    0.008    0.008 pywrap_tensorflow.py:1(<module>)\n",
      "       21    0.000    0.000    0.000    0.000 typing.py:897(__hash__)\n",
      "        9    0.000    0.000    0.000    0.000 resolver.py:91(descend_resolver)\n",
      "        2    0.000    0.000    0.000    0.000 result.py:158(forked_name)\n",
      "        2    0.000    0.000    0.000    0.000 fingerprint.py:383(<dictcomp>)\n",
      "        4    0.000    0.000    0.000    0.000 data_connector.py:321(is_module)\n",
      "        5    0.000    0.000    0.000    0.000 contextlib.py:260(contextmanager)\n",
      "        1    0.000    0.000    0.000    0.000 automatic.py:228(_make_backward_fn)\n",
      "        7    0.000    0.000    0.000    0.000 dtypes.py:279(__eq__)\n",
      "        1    0.000    0.000    0.000    0.000 tokenizer_re.py:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 training_epoch_loop.py:452(_build_kwargs)\n",
      "       10    0.000    0.000    0.000    0.000 pickle.py:335(whichmodule)\n",
      "       11    0.000    0.000    0.000    0.000 typing.py:938(__init__)\n",
      "        1    0.000    0.000    0.001    0.001 any_pb2.py:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 {function Random.getstate at 0x10f54da80}\n",
      "        2    0.000    0.000    0.000    0.000 evaluation_loop.py:346(_on_after_fetch)\n",
      "        6    0.000    0.000    0.000    0.000 base.py:108(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 utils.py:489(<dictcomp>)\n",
      "        2    0.000    0.000    0.001    0.001 table.py:1011(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 formatters.py:678(_type_printers_default)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'float' of 'torch._C.TensorBase' objects}\n",
      "        4    0.000    0.000    0.000    0.000 typing.py:1606(copy_with)\n",
      "        7    0.000    0.000    0.000    0.000 dataclasses.py:401(_tuple_str)\n",
      "       14    0.000    0.000    0.000    0.000 version.py:87(__ge__)\n",
      "       10    0.000    0.000    0.000    0.000 results.py:244(__bool__)\n",
      "       21    0.000    0.000    0.000    0.000 omegaconf.py:410(_should_pass)\n",
      "       22    0.000    0.000    0.000    0.000 inspect.py:2831(__init__)\n",
      "        1    0.000    0.000    0.003    0.003 dictconfig.py:641(_set_value)\n",
      "        2    0.000    0.000    0.000    0.000 stopping_criteria.py:62(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 ListTokenSource.py:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 tempfile.py:142(rng)\n",
      "        4    0.000    0.000    0.000    0.000 utils.py:56(__eq__)\n",
      "        1    0.000    0.000    0.000    0.000 tensor_shape.py:940(as_proto)\n",
      "        1    0.000    0.000    0.007    0.007 module.py:1047(to)\n",
      "       13    0.000    0.000    0.000    0.000 base.py:131(_get_parent)\n",
      "       11    0.000    0.000    0.000    0.000 local.py:389(closed)\n",
      "        1    0.000    0.000    0.000    0.000 writer.py:353(add_scalar)\n",
      "       28    0.000    0.000    0.000    0.000 typing.py:1649(<genexpr>)\n",
      "       11    0.000    0.000    0.000    0.000 _helpers.py:91(get_module_object_and_name)\n",
      "        2    0.000    0.000    0.000    0.000 apply_func.py:63(__subclasshook__)\n",
      "        2    0.000    0.000    0.000    0.000 std.py:307(format_num)\n",
      "       11    0.000    0.000    0.000    0.000 typing.py:1947(_caller)\n",
      "        1    0.000    0.000    0.000    0.000 optimizer.py:198(_configure_optimizers)\n",
      "        5    0.000    0.000    0.000    0.000 _utils.py:630(is_dict_annotation)\n",
      "       10    0.000    0.000    0.000    0.000 ATNDeserializer.py:521(<lambda>)\n",
      "        4    0.000    0.000    0.000    0.000 inspect.py:466(isframe)\n",
      "        1    0.000    0.000    0.002    0.002 __init__.py:248(dump)\n",
      "        2    0.000    0.000    0.000    0.000 tensor_shape.py:511(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 trainer.py:1194(optimizers)\n",
      "        1    0.000    0.000    0.000    0.000 Tree.py:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 emitter.py:430(check_empty_document)\n",
      "        1    0.000    0.000    0.000    0.000 descriptor.py:425(FieldDescriptor)\n",
      "       30    0.000    0.000    0.000    0.000 <frozen posixpath>:52(normcase)\n",
      "        8    0.000    0.000    0.000    0.000 omegaconf.py:503(set_readonly)\n",
      "        1    0.000    0.000    0.001    0.001 listconfig.py:46(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 _api.py:315(__del__)\n",
      "        1    0.000    0.000    0.000    0.000 ErrorStrategy.py:41(DefaultErrorStrategy)\n",
      "        1    0.000    0.000    0.002    0.002 ATNState.py:1(<module>)\n",
      "       24    0.000    0.000    0.000    0.000 basecontainer.py:707(_value)\n",
      "        1    0.000    0.000    0.003    0.003 ParserRuleContext.py:1(<module>)\n",
      "        8    0.000    0.000    0.000    0.000 result.py:465(<genexpr>)\n",
      "        8    0.000    0.000    0.000    0.000 base.py:181(_get_node_flag)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'get' of '_contextvars.ContextVar' objects}\n",
      "        2    0.000    0.000    0.002    0.001 formatters.py:953(__call__)\n",
      "        2    0.000    0.000    0.000    0.000 configuration_utils.py:1015(<dictcomp>)\n",
      "        7    0.000    0.000    0.000    0.000 <frozen codecs>:309(__init__)\n",
      "        5    0.000    0.000    0.000    0.000 _utils.py:597(_is_special)\n",
      "        7    0.000    0.000    0.000    0.000 dataclasses.py:410(<listcomp>)\n",
      "       46    0.000    0.000    0.000    0.000 symbol_database.py:218(Default)\n",
      "        3    0.000    0.000    0.007    0.002 imports.py:45(module_available)\n",
      "        1    0.000    0.000    0.001    0.001 containers.py:126(RepeatedScalarFieldContainer)\n",
      "        1    0.000    0.000    0.009    0.009 BufferedTokenStream.py:1(<module>)\n",
      "        7    0.000    0.000    0.000    0.000 ATNDeserializer.py:466(<lambda>)\n",
      "        1    0.000    0.000    0.001    0.001 data.py:65(val_dataloader)\n",
      "        2    0.000    0.000    0.000    0.000 version.py:503(_cmpkey)\n",
      "        1    0.000    0.000    0.000    0.000 tensorboard.py:183(log_graph)\n",
      "        1    0.000    0.000    0.002    0.002 representer.py:26(represent)\n",
      "       54    0.000    0.000    0.000    0.000 inspect.py:2747(annotation)\n",
      "       43    0.000    0.000    0.000    0.000 {method 'items' of 'google._upb._message._ByNameMap' objects}\n",
      "       59    0.000    0.000    0.000    0.000 traitlets.py:469(instance_init)\n",
      "       33    0.000    0.000    0.000    0.000 version.py:331(pre)\n",
      "        2    0.000    0.000    0.000    0.000 ATN.py:24(__init__)\n",
      "       46    0.000    0.000    0.000    0.000 descriptor_pool.py:1289(Default)\n",
      "        1    0.000    0.000    0.016    0.016 resource_tracker.py:153(register)\n",
      "        1    0.000    0.000    0.002    0.002 hooks.py:160(on_validation_model_eval)\n",
      "        2    0.000    0.000    0.000    0.000 strategy.py:106(optimizers)\n",
      "        1    0.000    0.000    0.000    0.000 random.py:128(seed)\n",
      "        4    0.000    0.000    0.000    0.000 signal.py:70(<genexpr>)\n",
      "        1    0.000    0.000    0.002    0.002 message_factory.py:1(<module>)\n",
      "       48    0.000    0.000    0.000    0.000 tokenization_utils_base.py:3909(_switch_to_target_mode)\n",
      "       10    0.000    0.000    0.000    0.000 _parser.py:265(getuntil)\n",
      "        2    0.000    0.000    0.001    0.000 arrow_writer.py:417(_build_metadata)\n",
      "        2    0.000    0.000    0.000    0.000 _defines.py:382(DEFINE_string)\n",
      "       44    0.000    0.000    0.000    0.000 {built-in method builtins.abs}\n",
      "        1    0.000    0.000    0.000    0.000 well_known_types.py:61(Any)\n",
      "        3    0.000    0.000    0.001    0.000 __init__.py:1479(info)\n",
      "        2    0.000    0.000    0.000    0.000 data.py:414(_set_sampler_epoch)\n",
      "        4    0.000    0.000    0.000    0.000 features.py:1392(<dictcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 configuration_utils.py:1069(update)\n",
      "        2    0.000    0.000    0.000    0.000 modeling_fsmt.py:1300(get_encoder)\n",
      "       12    0.000    0.000    0.000    0.000 base.py:298(_is_missing)\n",
      "       34    0.000    0.000    0.000    0.000 base.py:246(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 representer.py:85(represent_sequence)\n",
      "        1    0.000    0.000    0.001    0.001 LexerActionExecutor.py:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 _exceptions.py:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 strategy.py:111(connect)\n",
      "        1    0.000    0.000    0.000    0.000 loop.py:32(restarting)\n",
      "        1    0.000    0.000    0.000    0.000 random.py:166(getstate)\n",
      "       15    0.000    0.000    0.000    0.000 {built-in method _weakref.proxy}\n",
      "        1    0.000    0.000    0.000    0.000 version.py:149(LegacyVersion)\n",
      "        3    0.000    0.000    0.000    0.000 dataclasses.py:573(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 automatic.py:209(_make_zero_grad_fn)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen _collections_abc>:786(keys)\n",
      "        7    0.000    0.000    0.000    0.000 Transition.py:205(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 training_epoch_loop.py:116(done)\n",
      "        1    0.000    0.000    0.000    0.000 model_summary.py:462(summarize)\n",
      "        1    0.000    0.000    0.007    0.007 profiler.py:619(__enter__)\n",
      "        1    0.000    0.000    0.000    0.000 optimizer.py:25(_optimizers_to_device)\n",
      "        3    0.000    0.000    0.000    0.000 dataclasses.py:548(<dictcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 Trees.py:17(Trees)\n",
      "       10    0.000    0.000    0.000    0.000 utils.py:39(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 combined_loader.py:404(_get_iterables_lengths)\n",
      "        1    0.000    0.000    0.001    0.001 listconfig.py:610(_set_value)\n",
      "       18    0.000    0.000    0.000    0.000 LexerAction.py:27(__init__)\n",
      "       33    0.000    0.000    0.000    0.000 version.py:340(dev)\n",
      "        1    0.000    0.000    0.000    0.000 model_summary.py:72(__init__)\n",
      "        1    0.000    0.000    0.014    0.014 CommonTokenStream.py:1(<module>)\n",
      "        4    0.000    0.000    0.000    0.000 formatting.py:543(key_to_query_type)\n",
      "       11    0.000    0.000    0.000    0.000 pathlib.py:515(_from_parsed_parts)\n",
      "        1    0.000    0.000    0.000    0.000 tensor_shape.py:946(<listcomp>)\n",
      "       19    0.000    0.000    0.000    0.000 specifiers.py:153(version)\n",
      "        6    0.000    0.000    0.000    0.000 traitlets.py:1761(set_trait)\n",
      "        1    0.000    0.000    0.001    0.001 slurm.py:189(_validate_srun_used)\n",
      "        1    0.000    0.000    0.000    0.000 logger.py:104(_sanitize_params)\n",
      "        1    0.000    0.000    0.000    0.000 weakref.py:164(__setitem__)\n",
      "        2    0.000    0.000    0.000    0.000 {method '_acquire_restore' of '_thread.RLock' objects}\n",
      "        2    0.000    0.000    0.000    0.000 model_summary.py:117(detach_hook)\n",
      "        3    0.000    0.000    0.000    0.000 _monitor.py:94(report)\n",
      "        8    0.000    0.000    0.000    0.000 {method 'SerializeToString' of 'google._upb._message.Message' objects}\n",
      "        6    0.000    0.000    0.000    0.000 emitter.py:814(write_indent)\n",
      "       12    0.000    0.000    0.000    0.000 features.py:1177(_check_non_null_non_empty_recursive)\n",
      "        2    0.000    0.000    0.000    0.000 data.py:245(_auto_add_worker_init_fn)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method atexit.register}\n",
      "       11    0.000    0.000    0.000    0.000 traitlets.py:172(isidentifier)\n",
      "        1    0.000    0.000    0.000    0.000 combined_loader.py:124(__init__)\n",
      "       10    0.000    0.000    0.000    0.000 formatting.py:212(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 DFAState.py:1(<module>)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'index' of 'list' objects}\n",
      "        5    0.000    0.000    0.000    0.000 ATNState.py:262(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 tensor_shape.py:1(<module>)\n",
      "        8    0.000    0.000    0.000    0.000 features.py:1403(<setcomp>)\n",
      "        1    0.000    0.000    0.001    0.001 __init__.py:1098(emit)\n",
      "       31    0.000    0.000    0.000    0.000 results.py:17(__getitem__)\n",
      "        1    0.000    0.000    0.000    0.000 context.py:237(get_context)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'put' of '_queue.SimpleQueue' objects}\n",
      "        1    0.000    0.000    0.000    0.000 text_encoding.py:48(<listcomp>)\n",
      "       14    0.000    0.000    0.000    0.000 __init__.py:422(<genexpr>)\n",
      "        5    0.000    0.000    0.000    0.000 basecontainer.py:64(_get_child)\n",
      "        8    0.000    0.000    0.000    0.000 __init__.py:57(find_spec)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:26(tf)\n",
      "        8    0.000    0.000    0.000    0.000 types.py:165(is_struct)\n",
      "        2    0.000    0.000    0.000    0.000 utils.py:1119(<setcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 emitter.py:160(expect_stream_start)\n",
      "        1    0.000    0.000    0.000    0.000 ErrorListener.py:1(<module>)\n",
      "        2    0.000    0.000    0.001    0.001 fromnumeric.py:53(_wrapfunc)\n",
      "        1    0.000    0.000    0.000    0.000 strategy.py:393(post_training_step)\n",
      "        1    0.000    0.000    0.000    0.000 _onnx_graph.py:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 dtypes.py:26(DType)\n",
      "        1    0.000    0.000    0.000    0.000 queue.py:34(__init__)\n",
      "        3    0.000    0.000    0.000    0.000 _weakrefset.py:53(_commit_removals)\n",
      "        2    0.000    0.000    0.000    0.000 std.py:185(__format__)\n",
      "        6    0.000    0.000    0.002    0.000 apply_func.py:69(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 strategy.py:346(pre_backward)\n",
      "        3    0.000    0.000    0.000    0.000 _weakrefset.py:27(__exit__)\n",
      "        3    0.000    0.000    0.000    0.000 omegaconf.py:644(get_type)\n",
      "        4    0.000    0.000    0.000    0.000 types.py:220(is_large_binary)\n",
      "        1    0.000    0.000    0.000    0.000 spec.py:1289(<dictcomp>)\n",
      "        4    0.000    0.000    0.000    0.000 nodes.py:56(validate_and_convert)\n",
      "        1    0.000    0.000    0.000    0.000 random.py:493(<listcomp>)\n",
      "        2    0.000    0.000    0.001    0.000 eval_frame.py:99(_maybe_init_guarded_backend_cache)\n",
      "        1    0.000    0.000    0.000    0.000 nodes.py:21(ValueNode)\n",
      "        1    0.000    0.000    0.000    0.000 OmegaConfGrammarParserVisitor.py:10(OmegaConfGrammarParserVisitor)\n",
      "        8    0.000    0.000    0.000    0.000 features.py:1404(<dictcomp>)\n",
      "        1    0.000    0.000    0.014    0.014 adam.py:22(__init__)\n",
      "       10    0.000    0.000    0.000    0.000 inspect.py:2801(__eq__)\n",
      "        2    0.000    0.000    0.000    0.000 table.py:433(__len__)\n",
      "        2    0.000    0.000    0.000    0.000 threading.py:822(_maintain_shutdown_locks)\n",
      "        6    0.000    0.000    0.000    0.000 base.py:65(<lambda>)\n",
      "        1    0.000    0.000    0.000    0.000 containers.py:248(RepeatedCompositeFieldContainer)\n",
      "        2    0.000    0.000    0.000    0.000 evaluation_loop.py:428(_build_kwargs)\n",
      "        3    0.000    0.000    0.007    0.002 imports.py:29(package_available)\n",
      "        1    0.000    0.000    0.000    0.000 tensor_util.py:47(SlowAppendFloat32ArrayToTensorProto)\n",
      "        4    0.000    0.000    0.000    0.000 utils.py:153(__eq__)\n",
      "        6    0.000    0.000    0.000    0.000 results.py:418(__getattr__)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1035(_resolve_name)\n",
      "       14    0.000    0.000    0.000    0.000 threading.py:273(_release_save)\n",
      "        3    0.000    0.000    0.000    0.000 grad_mode.py:195(__exit__)\n",
      "        5    0.000    0.000    0.000    0.000 {built-in method _abc._abc_register}\n",
      "        4    0.000    0.000    0.000    0.000 inspect.py:456(istraceback)\n",
      "        1    0.000    0.000    0.000    0.000 CommonTokenFactory.py:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 symbol_database.py:1(<module>)\n",
      "        5    0.000    0.000    0.000    0.000 utilities.py:113(_is_max_limit_reached)\n",
      "        1    0.000    0.000    0.000    0.000 enum.py:1505(__or__)\n",
      "        2    0.000    0.000    0.000    0.000 ATNDeserializer.py:180(readModes)\n",
      "       42    0.000    0.000    0.000    0.000 {method 'getvalue' of '_io.BytesIO' objects}\n",
      "        1    0.000    0.000    0.000    0.000 BufferedTokenStream.py:29(BufferedTokenStream)\n",
      "       64    0.000    0.000    0.000    0.000 dtypes.py:307(__hash__)\n",
      "        2    0.000    0.000    0.000    0.000 progress.py:204(reset_on_run)\n",
      "        1    0.000    0.000    0.000    0.000 fit_loop.py:111(min_steps)\n",
      "        1    0.000    0.000    0.000    0.000 _proto_graph.py:1(<module>)\n",
      "        4    0.000    0.000    0.000    0.000 _weakrefset.py:110(remove)\n",
      "        4    0.000    0.000    0.000    0.000 enum_type_wrapper.py:76(Value)\n",
      "        1    0.000    0.000    0.000    0.000 random.py:480(choices)\n",
      "        8    0.000    0.000    0.000    0.000 listconfig.py:84(_validate_get)\n",
      "        3    0.000    0.000    0.000    0.000 std.py:643(set_lock)\n",
      "        9    0.000    0.000    0.000    0.000 emitter.py:146(increase_indent)\n",
      "        1    0.000    0.000    0.001    0.001 configuration_validator.py:156(__warn_dataloader_iter_limitations)\n",
      "        1    0.000    0.000    0.000    0.000 cpu.py:30(setup_device)\n",
      "       14    0.000    0.000    0.000    0.000 table.py:360(schema)\n",
      "        1    0.000    0.000    0.000    0.000 signal_connector.py:166(_register_signal)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen _collections_abc>:283(__subclasshook__)\n",
      "        2    0.000    0.000    0.000    0.000 model_summary.py:269(<genexpr>)\n",
      "        2    0.000    0.000    0.000    0.000 data.py:438(suggested_max_num_workers)\n",
      "        1    0.000    0.000    0.000    0.000 _utils.py:125(get_omega_conf_dumper)\n",
      "        9    0.000    0.000    0.000    0.000 _utils.py:676(is_dict)\n",
      "        6    0.000    0.000    0.000    0.000 single_device.py:86(barrier)\n",
      "        1    0.000    0.000    0.000    0.000 TokenTagToken.py:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 _validators.py:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 data_connector.py:124(attach_dataloaders)\n",
      "        1    0.000    0.000    0.000    0.000 IntervalSet.py:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 logger.py:70(_flatten_dict)\n",
      "       17    0.000    0.000    0.000    0.000 {method 'translate' of 'bytearray' objects}\n",
      "        1    0.000    0.000    0.000    0.000 Token.py:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 model_checkpoint.py:651(__warn_if_dir_not_empty)\n",
      "       17    0.000    0.000    0.000    0.000 dataclasses.py:437(_field_assign)\n",
      "        1    0.000    0.000    0.000    0.000 traitlets.py:2014(_resolve_string)\n",
      "        4    0.000    0.000    0.000    0.000 ATNDeserializer.py:441(readLong)\n",
      "      5/4    0.000    0.000    0.001    0.000 <frozen importlib._bootstrap_external>:1311(__iter__)\n",
      "        1    0.000    0.000    0.001    0.001 containers.py:366(ScalarMap)\n",
      "        1    0.000    0.000    0.000    0.000 ListTokenSource.py:20(ListTokenSource)\n",
      "       15    0.000    0.000    0.000    0.000 version.py:441(_parse_letter_version)\n",
      "       22    0.000    0.000    0.000    0.000 base_comm.py:131(on_msg)\n",
      "        2    0.000    0.000    0.000    0.000 features.py:2104(<dictcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 dtypes.py:524(<dictcomp>)\n",
      "        4    0.000    0.000    0.000    0.000 formatting.py:218(decode_column)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:1595(makeRecord)\n",
      "        8    0.000    0.000    0.000    0.000 sampler.py:145(num_samples)\n",
      "        4    0.000    0.000    0.000    0.000 <frozen posixpath>:60(isabs)\n",
      "       10    0.000    0.000    0.000    0.000 dataloader.py:445(_index_sampler)\n",
      "        1    0.000    0.000    0.000    0.000 serializer.py:15(__init__)\n",
      "       34    0.000    0.000    0.000    0.000 {method 'removeprefix' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'write' of '_io.TextIOWrapper' objects}\n",
      "        1    0.000    0.000    0.000    0.000 field_mask.py:1(<module>)\n",
      "        2    0.000    0.000    0.000    0.000 _compiler.py:389(_bytes_to_codes)\n",
      "        4    0.000    0.000    0.000    0.000 copy.py:201(_deepcopy_list)\n",
      "       11    0.000    0.000    0.000    0.000 {method 'decode' of 'bytes' objects}\n",
      "        1    0.000    0.000    0.000    0.000 v2.py:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:1273(append)\n",
      "        1    0.000    0.000    0.000    0.000 event_file_writer.py:140(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 data_connector.py:456(_parse_num_batches)\n",
      "        8    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1293(_get_parent_path)\n",
      "        1    0.000    0.000    0.000    0.000 RuleTagToken.py:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 specifiers.py:694(__iter__)\n",
      "        5    0.000    0.000    0.000    0.000 ATNDeserializer.py:487(<lambda>)\n",
      "        1    0.000    0.000    0.000    0.000 wrappers_pb2.py:1(<module>)\n",
      "       12    0.000    0.000    0.000    0.000 loader.py:332(__getitem__)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen posixpath>:100(split)\n",
      "        1    0.000    0.000    0.000    0.000 std.py:574(_decr_instances)\n",
      "        1    0.000    0.000    0.000    0.000 profiler.py:992(init_step_count)\n",
      "        1    0.000    0.000    0.002    0.002 _output.py:1(<module>)\n",
      "        3    0.000    0.000    0.000    0.000 emitter.py:409(expect_block_mapping_simple_value)\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method math.exp}\n",
      "        2    0.000    0.000    0.002    0.001 widget.py:802(_repr_mimebundle_)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:3106(<listcomp>)\n",
      "        8    0.000    0.000    0.000    0.000 six.py:194(find_spec)\n",
      "        1    0.000    0.000    0.082    0.082 combined_loader.py:72(__next__)\n",
      "        1    0.000    0.000    0.000    0.000 automatic.py:54(_clone_loss)\n",
      "        2    0.000    0.000    0.000    0.000 _defines.py:89(DEFINE)\n",
      "        2    0.000    0.000    0.000    0.000 sacrebleu.py:153(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 hparams_mixin.py:148(hparams_initial)\n",
      "        2    0.000    0.000    0.001    0.001 listconfig.py:293(append)\n",
      "       10    0.000    0.000    0.000    0.000 dataclasses.py:646(_is_classvar)\n",
      "       12    0.000    0.000    0.000    0.000 pathlib.py:622(name)\n",
      "        3    0.000    0.000    0.000    0.000 _utils.py:605(is_float)\n",
      "       19    0.000    0.000    0.000    0.000 results.py:14(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 pathlib.py:1008(stat)\n",
      "        1    0.000    0.000    0.000    0.000 Recognizer.py:13(Recognizer)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:1378(_fixupParents)\n",
      "        1    0.000    0.000    0.001    0.001 __init__.py:1610(_log)\n",
      "        1    0.000    0.000    0.000    0.000 well_known_types.py:527(ListValue)\n",
      "        1    0.000    0.000    0.000    0.000 well_known_types.py:274(Duration)\n",
      "        4    0.000    0.000    0.000    0.000 core.py:375(<dictcomp>)\n",
      "        8    0.000    0.000    0.000    0.000 six.py:190(find_spec)\n",
      "        1    0.000    0.000    0.000    0.000 requirements.py:67(<lambda>)\n",
      "        2    0.000    0.000    0.000    0.000 stopping_criteria.py:142(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 _argument_parser.py:47(__call__)\n",
      "        5    0.000    0.000    0.000    0.000 emitter.py:800(write_indicator)\n",
      "       25    0.000    0.000    0.000    0.000 version.py:336(post)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:1328(safe_name)\n",
      "        6    0.000    0.000    0.000    0.000 basecontainer.py:696(_is_interpolation)\n",
      "        8    0.000    0.000    0.000    0.000 {built-in method math.log}\n",
      "        1    0.000    0.000    0.000    0.000 nodes.py:422(EnumNode)\n",
      "        3    0.000    0.000    0.000    0.000 local.py:386(close)\n",
      "        1    0.000    0.000    0.000    0.000 containers.py:468(MessageMap)\n",
      "        8    0.000    0.000    0.000    0.000 std.py:1150(_comparable)\n",
      "       20    0.000    0.000    0.000    0.000 dataclasses.py:1106(<genexpr>)\n",
      "        2    0.000    0.000    0.000    0.000 inspect.py:2065(_signature_is_builtin)\n",
      "        1    0.000    0.000    0.000    0.000 trainer.py:1436(evaluating)\n",
      "        3    0.000    0.000    0.000    0.000 _utils.py:132(yaml_is_bool)\n",
      "       12    0.000    0.000    0.000    0.000 base.py:128(_invalidate_flags_cache)\n",
      "        2    0.000    0.000    0.000    0.000 _flagvalues.py:427(__setitem__)\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method posix._path_normpath}\n",
      "       21    0.000    0.000    0.000    0.000 <frozen abc>:7(abstractmethod)\n",
      "       26    0.000    0.000    0.000    0.000 {built-in method builtins.divmod}\n",
      "        1    0.000    0.000    0.003    0.003 combined_loader.py:90(__iter__)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method numpy.array}\n",
      "        1    0.000    0.000    0.000    0.000 typing.py:1975(__instancecheck__)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:1327(getLogger)\n",
      "        2    0.000    0.000    0.000    0.000 basecontainer.py:59(__init__)\n",
      "       14    0.000    0.000    0.000    0.000 enum_type_wrapper.py:55(__init__)\n",
      "       20    0.000    0.000    0.000    0.000 dataclasses.py:396(<genexpr>)\n",
      "        4    0.000    0.000    0.000    0.000 features.py:1669(__reduce__)\n",
      "        1    0.000    0.000    0.000    0.000 PredictionContext.py:109(SingletonPredictionContext)\n",
      "        2    0.000    0.000    0.000    0.000 arrow_writer.py:427(write_examples_on_file)\n",
      "        5    0.000    0.000    0.000    0.000 basecontainer.py:562(get_target_type_hint)\n",
      "        7    0.000    0.000    0.000    0.000 lazy.py:63(LazyModule)\n",
      "        1    0.000    0.000    0.000    0.000 containers.py:67(BaseContainer)\n",
      "        6    0.000    0.000    0.000    0.000 inspect.py:943(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 descriptor_database.py:46(DescriptorDatabase)\n",
      "        1    0.000    0.000    0.000    0.000 ATNType.py:10(ATNType)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen _collections_abc>:78(_check_methods)\n",
      "        1    0.000    0.000    0.000    0.000 representer.py:191(represent_list)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:1087(flush)\n",
      "        1    0.000    0.000    0.001    0.001 base_comm.py:196(unregister_comm)\n",
      "        1    0.000    0.000    0.000    0.000 representer.py:65(add_representer)\n",
      "        2    0.000    0.000    0.000    0.000 omegaconf.py:962(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 StdinStream.py:1(<module>)\n",
      "        4    0.000    0.000    0.000    0.000 basecontainer.py:227(convert)\n",
      "        1    0.000    0.000    0.000    0.000 summary.py:328(<listcomp>)\n",
      "        7    0.000    0.000    0.000    0.000 emitter.py:18(__init__)\n",
      "        2    0.000    0.000    0.007    0.003 fetchers.py:102(__iter__)\n",
      "     10/6    0.000    0.000    0.001    0.000 data.py:47(sized_len)\n",
      "        1    0.000    0.000    0.000    0.000 grammar_parser.py:43(OmegaConfErrorListener)\n",
      "        2    0.000    0.000    0.000    0.000 pickle.py:938(_batch_appends)\n",
      "        4    0.000    0.000    0.000    0.000 typing.py:1257(__call__)\n",
      "        1    0.000    0.000    0.000    0.000 ATNDeserializationOptions.py:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 local.py:52(makedirs)\n",
      "        3    0.000    0.000    0.000    0.000 dataclasses.py:1017(<listcomp>)\n",
      "        5    0.000    0.000    0.000    0.000 enum.py:961(_find_data_repr_)\n",
      "        1    0.000    0.000    0.000    0.000 _flag.py:427(MultiFlag)\n",
      "        7    0.000    0.000    0.000    0.000 nodes.py:27(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 trainer.py:1184(num_devices)\n",
      "        1    0.000    0.000    0.000    0.000 raw_unicode_escape.py:1(<module>)\n",
      "        5    0.000    0.000    0.000    0.000 _utils.py:644(is_list_annotation)\n",
      "        1    0.000    0.000    0.000    0.000 trainer.py:1131(accelerator)\n",
      "        2    0.000    0.000    0.000    0.000 signal.py:34(_enum_to_int)\n",
      "        5    0.000    0.000    0.000    0.000 _utils.py:654(is_tuple_annotation)\n",
      "        1    0.000    0.000    0.000    0.000 ParseTreePatternMatcher.py:91(ParseTreePatternMatcher)\n",
      "        1    0.000    0.000    0.000    0.000 metric.py:181(update_called)\n",
      "        1    0.000    0.000    0.000    0.000 progress_bar.py:90(total_val_batches_current_dataloader)\n",
      "       16    0.000    0.000    0.000    0.000 __init__.py:962(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 logger_connector.py:250(progress_bar_metrics)\n",
      "        3    0.000    0.000    0.000    0.000 dataclasses.py:624(_cmp_fn)\n",
      "        3    0.000    0.000    0.000    0.000 dataclasses.py:1043(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 tensor_shape.py:471(as_dimension)\n",
      "        3    0.000    0.000    0.000    0.000 emitter.py:376(expect_block_sequence_item)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:88(__post_init__)\n",
      "       25    0.000    0.000    0.000    0.000 {built-in method sys._getframe}\n",
      "        1    0.000    0.000    0.000    0.000 ATNType.py:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 FileStream.py:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 random.py:119(__init__)\n",
      "       36    0.000    0.000    0.000    0.000 {method '__getitem__' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 lazy_tensor_creator.py:1(<module>)\n",
      "        2    0.000    0.000    0.000    0.000 _utils.py:724(is_valid_value_annotation)\n",
      "        1    0.000    0.000    0.000    0.000 version.py:17(InfinityType)\n",
      "        5    0.000    0.000    0.000    0.000 progress.py:172(reset_on_run)\n",
      "       20    0.000    0.000    0.000    0.000 formatters.py:358(_check_return)\n",
      "        2    0.000    0.000    0.000    0.000 zmqshell.py:74(_hooks)\n",
      "        4    0.000    0.000    0.005    0.001 ATNDeserializer.py:519(<lambda>)\n",
      "       10    0.000    0.000    0.000    0.000 pytorch.py:138(is_validating)\n",
      "        3    0.000    0.000    0.001    0.000 writer.py:278(_get_file_writer)\n",
      "        2    0.000    0.000    0.000    0.000 result.py:467(_forked_name)\n",
      "        9    0.000    0.000    0.000    0.000 tqdm_progress.py:131(val_progress_bar)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'flush' of '_io.TextIOWrapper' objects}\n",
      "        7    0.000    0.000    0.000    0.000 typing.py:1991(<genexpr>)\n",
      "        2    0.000    0.000    0.000    0.000 _flag.py:90(__init__)\n",
      "       16    0.000    0.000    0.000    0.000 {built-in method _json.encode_basestring_ascii}\n",
      "        1    0.000    0.000    0.000    0.000 profiler.py:82(_run_on_profiler_start)\n",
      "        2    0.000    0.000    0.000    0.000 results.py:473(_asStringList)\n",
      "        2    0.000    0.000    0.000    0.000 module.py:595(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 OmegaConfGrammarParser.py:405(ElementContext)\n",
      "        5    0.000    0.000    0.000    0.000 emitter.py:827(write_line_break)\n",
      "        1    0.000    0.000    0.000    0.000 gfile.py:665(__init__)\n",
      "        7    0.000    0.000    0.000    0.000 events.py:65(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 data.py:485(__getattr__)\n",
      "        4    0.000    0.000    0.000    0.000 inspect.py:480(iscode)\n",
      "        1    0.000    0.000    0.000    0.000 record_writer.py:1(<module>)\n",
      "        2    0.000    0.000    0.000    0.000 _flag.py:234(_set_default)\n",
      "        6    0.000    0.000    0.000    0.000 {method 'rsplit' of 'str' objects}\n",
      "        2    0.000    0.000    0.000    0.000 combined_loader.py:329(limits)\n",
      "        2    0.000    0.000    0.004    0.002 dataloader.py:426(__iter__)\n",
      "        1    0.000    0.000    0.000    0.000 representer.py:206(represent_dict)\n",
      "       10    0.000    0.000    0.000    0.000 result.py:70(op)\n",
      "        1    0.000    0.000    0.000    0.000 combined_loader.py:158(__len__)\n",
      "        1    0.000    0.000    0.000    0.000 InputStream.py:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 optimizer.py:248(_configure_schedulers_automatic_opt)\n",
      "        1    0.000    0.000    0.000    0.000 parsing.py:39(clean_namespace)\n",
      "        1    0.000    0.000    0.000    0.000 gfile.py:421(FSSpecFileSystem)\n",
      "        1    0.000    0.000    0.000    0.000 dictconfig.py:519(keys)\n",
      "        1    0.000    0.000    0.000    0.000 signal_connector.py:135(_valid_signals)\n",
      "        8    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1283(_find_parent_path_names)\n",
      "        3    0.000    0.000    0.000    0.000 generic.py:170(_is_torch_device)\n",
      "        2    0.000    0.000    0.000    0.000 training_epoch_loop.py:336(_should_accumulate)\n",
      "        3    0.000    0.000    0.000    0.000 pytorch.py:180(has_finished)\n",
      "       14    0.000    0.000    0.000    0.000 dataloader.py:441(_auto_collation)\n",
      "        1    0.000    0.000    0.000    0.000 tokenizer_13a.py:6(Tokenizer13a)\n",
      "        1    0.000    0.000    0.000    0.000 OmegaConfGrammarParser.py:1152(ResolverNameContext)\n",
      "        3    0.000    0.000    0.000    0.000 _weakrefset.py:21(__enter__)\n",
      "        1    0.000    0.000    0.000    0.000 data.py:329(_is_dataloader_shuffled)\n",
      "        2    0.000    0.000    0.000    0.000 gfile.py:72(get_filesystem)\n",
      "        2    0.000    0.000    0.001    0.001 table.py:166(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 _convert_np.py:6(make_np)\n",
      "        2    0.000    0.000    0.006    0.003 model_summary.py:139(num_parameters)\n",
      "       13    0.000    0.000    0.000    0.000 base.py:344(_is_flags_root)\n",
      "        2    0.000    0.000    0.000    0.000 widget.py:52(<listcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 sacrebleu.py:158(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 Utils.py:1(<module>)\n",
      "        2    0.000    0.000    0.000    0.000 hooks.py:34(remove)\n",
      "        4    0.000    0.000    0.000    0.000 pickle.py:526(get)\n",
      "        2    0.000    0.000    0.000    0.000 ATNDeserializer.py:97(checkVersion)\n",
      "        1    0.000    0.000    0.000    0.000 LexerActionExecutor.py:22(LexerActionExecutor)\n",
      "        6    0.000    0.000    0.000    0.000 pathlib.py:630(suffix)\n",
      "        1    0.000    0.000    0.000    0.000 tensor_util.py:48(<listcomp>)\n",
      "        6    0.000    0.000    0.000    0.000 strategy.py:73(accelerator)\n",
      "        3    0.000    0.000    0.003    0.001 dictconfig.py:306(__setitem__)\n",
      "        3    0.000    0.000    0.000    0.000 result.py:74(op)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:1561(findCaller)\n",
      "        3    0.000    0.000    0.011    0.004 model_summary.py:250(total_parameters)\n",
      "        3    0.000    0.000    0.014    0.005 dataclasses.py:1202(dataclass)\n",
      "       13    0.000    0.000    0.000    0.000 typing.py:1634(<genexpr>)\n",
      "        5    0.000    0.000    0.000    0.000 sampler.py:170(__len__)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:2081(getLogger)\n",
      "        1    0.000    0.000    0.001    0.001 writer.py:52(__init__)\n",
      "        6    0.000    0.000    0.000    0.000 inspect.py:1947(_signature_get_user_defined_method)\n",
      "        1    0.000    0.000    0.001    0.001 slurm.py:101(detect)\n",
      "        4    0.000    0.000    0.000    0.000 combined_loader.py:405(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 _writer.py:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 states.py:63(evaluating)\n",
      "        1    0.000    0.000    0.000    0.000 typing.py:2839(_make_nmtuple)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:554(drop_comment)\n",
      "        1    0.000    0.000    0.000    0.000 evaluation_loop.py:92(skip)\n",
      "        2    0.000    0.000    0.000    0.000 progress_bar.py:145(has_dataloader_changed)\n",
      "        1    0.000    0.000    0.000    0.000 configuration_validator.py:123(__verify_batch_transfer_support)\n",
      "       19    0.000    0.000    0.000    0.000 enum.py:238(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 cpp_message.py:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 tensor_util.py:135(GetNumpyAppendFn)\n",
      "        2    0.000    0.000    0.000    0.000 std.py:1109(__len__)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method fromhex}\n",
      "        1    0.000    0.000    0.000    0.000 lazy.py:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 typing.py:611(ClassVar)\n",
      "        1    0.000    0.000    0.000    0.000 pytorch.py:65(__init__)\n",
      "        3    0.000    0.000    0.000    0.000 data.py:43(has_iterable_dataset)\n",
      "        1    0.000    0.000    0.000    0.000 RuleContext.py:35(RuleContext)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:364(__init__)\n",
      "       10    0.000    0.000    0.000    0.000 dataclasses.py:654(_is_initvar)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:1012(__iter__)\n",
      "        1    0.000    0.000    0.000    0.000 DFA.py:13(DFA)\n",
      "        2    0.000    0.000    0.000    0.000 events.py:22(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 _base.py:364(cancel)\n",
      "        1    0.000    0.000    0.000    0.000 typing.py:1913(_is_callable_members_only)\n",
      "        5    0.000    0.000    0.000    0.000 result.py:143(sync)\n",
      "        1    0.000    0.000    0.000    0.000 LexerAction.py:13(LexerActionType)\n",
      "        5    0.000    0.000    0.000    0.000 descriptor_pool.py:71(_Deprecated)\n",
      "        2    0.000    0.000    0.000    0.000 module.py:512(<dictcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 data.py:453(_num_cpus_available)\n",
      "        1    0.000    0.000    0.000    0.000 lazy.py:92(wrapper)\n",
      "        2    0.000    0.000    0.000    0.000 utils.py:1180(_prepare_generated_length)\n",
      "        1    0.000    0.000    0.004    0.004 reflection.py:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 model_summary.py:82(_register_hook)\n",
      "        1    0.000    0.000    0.000    0.000 util.py:171(register_after_fork)\n",
      "        2    0.000    0.000    0.000    0.000 arrow_dataset.py:637(_check_table)\n",
      "        3    0.000    0.000    0.000    0.000 pathlib.py:792(is_absolute)\n",
      "        1    0.000    0.000    0.000    0.000 tensor_shape.py:491(TensorShape)\n",
      "        5    0.000    0.000    0.000    0.000 <frozen abc>:110(register)\n",
      "        7    0.000    0.000    0.000    0.000 module.py:290(automatic_optimization)\n",
      "       33    0.000    0.000    0.000    0.000 {method '__init_subclass__' of 'object' objects}\n",
      "       15    0.000    0.000    0.000    0.000 version.py:321(epoch)\n",
      "        3    0.000    0.000    0.000    0.000 trainer.py:1252(is_global_zero)\n",
      "        5    0.000    0.000    0.000    0.000 trainer.py:1544(<listcomp>)\n",
      "        3    0.000    0.000    0.000    0.000 __init__.py:194(_is_internal_frame)\n",
      "        4    0.000    0.000    0.000    0.000 ATNDeserializationOptions.py:18(__setattr__)\n",
      "       17    0.000    0.000    0.000    0.000 errors.py:473(<genexpr>)\n",
      "        2    0.000    0.000    0.000    0.000 formatters.py:944(_check_return)\n",
      "        2    0.000    0.000    0.000    0.000 version.py:92(__ge__)\n",
      "       19    0.000    0.000    0.000    0.000 version.py:344(local)\n",
      "        1    0.000    0.000    0.000    0.000 functools.py:188(total_ordering)\n",
      "        1    0.000    0.000    0.004    0.004 descriptor_database.py:1(<module>)\n",
      "        6    0.000    0.000    0.000    0.000 combined_loader.py:100(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 message.py:1(<module>)\n",
      "        7    0.000    0.000    0.000    0.000 omegaconf.py:454(has_resolver)\n",
      "        1    0.000    0.000    0.000    0.000 training_epoch_loop.py:189(_on_after_fetch)\n",
      "        2    0.000    0.000    0.000    0.000 dataloader.py:393(multiprocessing_context)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:431(__enter__)\n",
      "        1    0.000    0.000    0.000    0.000 trainer.py:1414(predicting)\n",
      "       30    0.000    0.000    0.000    0.000 {built-in method _signal.getsignal}\n",
      "        1    0.000    0.000    0.000    0.000 training_epoch_loop.py:186(_on_before_fetch)\n",
      "        1    0.000    0.000    0.002    0.002 combined_loader.py:151(__iter__)\n",
      "        1    0.000    0.000    0.000    0.000 ParserRuleContext.py:36(ParserRuleContext)\n",
      "        1    0.000    0.000    0.000    0.000 event_file_writer.py:218(__init__)\n",
      "        1    0.000    0.000    0.002    0.002 tensorboard.py:290(save)\n",
      "        8    0.000    0.000    0.000    0.000 model_summary.py:378(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 _argument_parser.py:144(NumericParser)\n",
      "        2    0.000    0.000    0.001    0.000 core.py:878(try_parse)\n",
      "        3    0.000    0.000    0.000    0.000 ATNConfigSet.py:36(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 builder.py:1(<module>)\n",
      "        5    0.000    0.000    0.000    0.000 <string>:1(<lambda>)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen posixpath>:293(expandvars)\n",
      "       20    0.000    0.000    0.000    0.000 {method 'end' of 're.Match' objects}\n",
      "        1    0.000    0.000    0.000    0.000 unicode_escape.py:1(<module>)\n",
      "        2    0.000    0.000    0.000    0.000 nodes.py:36(__init__)\n",
      "        3    0.000    0.000    0.000    0.000 parsing.py:30(is_picklable)\n",
      "        7    0.000    0.000    0.000    0.000 version.py:205(<genexpr>)\n",
      "        2    0.000    0.000    0.000    0.000 logger_connector.py:134(update_eval_epoch_metrics)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen genericpath>:53(getmtime)\n",
      "        1    0.000    0.000    0.000    0.000 _utils.py:502(ValueKind)\n",
      "        4    0.000    0.000    0.000    0.000 formatting.py:95(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:988(__init__)\n",
      "        3    0.000    0.000    0.000    0.000 pathlib.py:765(__truediv__)\n",
      "        1    0.000    0.000    0.000    0.000 ATNSimulator.py:12(ATNSimulator)\n",
      "        1    0.000    0.000    0.000    0.000 ErrorStrategy.py:17(ErrorStrategy)\n",
      "        1    0.000    0.000    0.000    0.000 OmegaConfGrammarParser.py:179(ConfigValueContext)\n",
      "        2    0.000    0.000    0.000    0.000 {method '__setstate__' of 'functools.partial' objects}\n",
      "        1    0.000    0.000    0.000    0.000 training_epoch_loop.py:106(_is_training_done)\n",
      "        2    0.000    0.000    0.000    0.000 grad_mode.py:134(__enter__)\n",
      "        1    0.000    0.000    0.000    0.000 _flag.py:505(MultiEnumClassFlag)\n",
      "        1    0.000    0.000    0.000    0.000 _flagvalues.py:1333(FlagHolder)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:356(Box)\n",
      "        1    0.000    0.000    0.001    0.001 __init__.py:1690(callHandlers)\n",
      "        7    0.000    0.000    0.000    0.000 results.py:262(haskeys)\n",
      "        1    0.000    0.000    0.000    0.000 _validators_classes.py:1(<module>)\n",
      "       13    0.000    0.000    0.000    0.000 version.py:498(<lambda>)\n",
      "        1    0.000    0.000    0.000    0.000 _argument_parser.py:376(EnumClassParser)\n",
      "        1    0.000    0.000    0.002    0.002 module.py:2397(eval)\n",
      "        1    0.000    0.000    0.001    0.001 __init__.py:1636(handle)\n",
      "       15    0.000    0.000    0.000    0.000 version.py:326(release)\n",
      "        1    0.000    0.000    0.000    0.000 tensor_util.py:124(GetFromNumpyDTypeDict)\n",
      "        3    0.000    0.000    0.006    0.002 dataloader.py:620(_next_index)\n",
      "        4    0.000    0.000    0.000    0.000 combined_loader.py:355(__len__)\n",
      "        3    0.000    0.000    0.000    0.000 logger_connector.py:216(reset_metrics)\n",
      "       10    0.000    0.000    0.000    0.000 dataclasses.py:660(_is_kw_only)\n",
      "        1    0.000    0.000    0.000    0.000 _flag.py:394(EnumClassFlag)\n",
      "        5    0.000    0.000    0.000    0.000 {method 'lstrip' of 'str' objects}\n",
      "        2    0.000    0.000    0.006    0.003 model_summary.py:248(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 DFAState.py:47(DFAState)\n",
      "        1    0.000    0.000    0.000    0.000 optimizer.py:349(_validate_multiple_optimizers_support)\n",
      "        3    0.000    0.000    0.000    0.000 training_epoch_loop.py:331(_num_ready_batches_reached)\n",
      "        1    0.000    0.000    0.001    0.001 __init__.py:965(handle)\n",
      "        1    0.000    0.000    0.000    0.000 closure.py:41(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 features.py:1984(decode_column)\n",
      "        2    0.000    0.000    0.000    0.000 beam_search.py:196(<listcomp>)\n",
      "        3    0.000    0.000    0.000    0.000 dataclasses.py:1052(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._autograd._profiler_enabled}\n",
      "        8    0.000    0.000    0.000    0.000 version.py:372(is_postrelease)\n",
      "        9    0.000    0.000    0.000    0.000 emitter.py:459(process_anchor)\n",
      "        1    0.000    0.000    0.000    0.000 _argument_parser.py:82(ArgumentParser)\n",
      "        4    0.000    0.000    0.000    0.000 decoder.py:262(_StructPackDecoder)\n",
      "        1    0.000    0.000    0.000    0.000 tensor_shape.py:22(Dimension)\n",
      "        2    0.000    0.000    0.000    0.000 module.py:100(experiment_id)\n",
      "        2    0.000    0.000    0.000    0.000 tokenization_utils_base.py:284(values)\n",
      "        1    0.000    0.000    0.000    0.000 lazy.py:42(load_once)\n",
      "        1    0.000    0.000    0.000    0.000 formatters.py:62(_default_mime_formatter)\n",
      "        1    0.000    0.000    0.000    0.000 OmegaConfGrammarParser.py:1325(PrimitiveContext)\n",
      "        1    0.000    0.000    0.000    0.000 trainer.py:1643(progress_bar_metrics)\n",
      "        8    0.000    0.000    0.000    0.000 types.py:140(is_list)\n",
      "        1    0.000    0.000    0.000    0.000 OmegaConfGrammarParser.py:553(DictContainerContext)\n",
      "        1    0.000    0.000    0.000    0.000 InputStream.py:14(InputStream)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'storage_offset' of 'torch._C.TensorBase' objects}\n",
      "        1    0.000    0.000    0.000    0.000 text_format.py:821(_Parser)\n",
      "        5    0.000    0.000    0.000    0.000 hparams_mixin.py:135(hparams)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _socket.gethostname}\n",
      "       22    0.000    0.000    0.000    0.000 core.py:772(postParse)\n",
      "        1    0.000    0.000    0.000    0.000 _argument_parser.py:193(FloatParser)\n",
      "        3    0.000    0.000    0.000    0.000 _utils.py:621(is_primitive_list)\n",
      "        1    0.000    0.000    0.000    0.000 dataclasses.py:599(_frozen_get_del_attr)\n",
      "        1    0.000    0.000    0.010    0.010 <frozen importlib._bootstrap_external>:1231(create_module)\n",
      "        3    0.000    0.000    0.000    0.000 dtypes.py:100(base_dtype)\n",
      "        2    0.000    0.000    0.000    0.000 fit_loop.py:427(_should_accumulate)\n",
      "        2    0.000    0.000    0.000    0.000 emitter.py:788(flush_stream)\n",
      "        1    0.000    0.000    0.000    0.000 version.py:104(_BaseVersion)\n",
      "        1    0.000    0.000    0.000    0.000 signal.py:54(signal)\n",
      "        3    0.000    0.000    0.000    0.000 data.py:10(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 Token.py:12(Token)\n",
      "        3    0.000    0.000    0.000    0.000 dataclasses.py:1046(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 nodes.py:507(InterpolationResultNode)\n",
      "        1    0.000    0.000    0.000    0.000 automatic.py:115(__init__)\n",
      "        2    0.000    0.000    0.001    0.000 pickle.py:782(save_float)\n",
      "       10    0.000    0.000    0.000    0.000 {method 'setter' of 'property' objects}\n",
      "        1    0.000    0.000    0.000    0.000 _utils.py:680(is_primitive_container)\n",
      "        1    0.000    0.000    0.000    0.000 training_epoch_loop.py:176(on_run_start)\n",
      "        2    0.000    0.000    0.000    0.000 bleu.py:254(<listcomp>)\n",
      "        3    0.000    0.000    0.000    0.000 dataclasses.py:346(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method numpy.empty}\n",
      "        1    0.000    0.000    0.000    0.000 local.py:371(tell)\n",
      "        1    0.000    0.000    0.000    0.000 ATNConfigSet.py:22(ATNConfigSet)\n",
      "        1    0.000    0.000    0.000    0.000 spec.py:725(isfile)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:1447(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method posix.write}\n",
      "        2    0.000    0.000    0.000    0.000 fetch.py:8(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 version.py:93(__gt__)\n",
      "        2    0.000    0.000    0.000    0.000 arrow_writer.py:553(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 OmegaConfGrammarParser.py:870(InterpolationNodeContext)\n",
      "        6    0.000    0.000    0.000    0.000 loop.py:27(restarting)\n",
      "        1    0.000    0.000    0.000    0.000 ATNDeserializationOptions.py:13(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 imports.py:58(_habana_available_and_importable)\n",
      "        2    0.000    0.000    0.006    0.003 model_summary.py:246(param_nums)\n",
      "        1    0.000    0.000    0.000    0.000 DiagnosticErrorListener.py:32(DiagnosticErrorListener)\n",
      "        2    0.000    0.000    0.000    0.000 ATNType.py:15(fromOrdinal)\n",
      "        1    0.000    0.000    0.000    0.000 writer.py:42(FileWriter)\n",
      "        1    0.000    0.000    0.000    0.000 SemanticContext.py:100(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 threading.py:832(<listcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 ATNDeserializer.py:36(__init__)\n",
      "       19    0.000    0.000    0.000    0.000 enum.py:1142(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 fromnumeric.py:72(<dictcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 text_format.py:347(_Printer)\n",
      "        1    0.000    0.000    0.000    0.000 model_summary.py:385(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 _utils.py:735(_valid_dict_key_annotation_type)\n",
      "        1    0.000    0.000    0.000    0.000 nodes.py:127(AnyNode)\n",
      "        1    0.000    0.000    0.000    0.000 errors.py:90(ConfigKeyError)\n",
      "        1    0.000    0.000    0.000    0.000 configuration_validator.py:139(__verify_manual_optimization_support)\n",
      "        1    0.000    0.000    0.000    0.000 ATN.py:14(ATN)\n",
      "        9    0.000    0.000    0.000    0.000 {method 'partition' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 OmegaConfGrammarParser.py:1252(QuotedValueContext)\n",
      "        4    0.000    0.000    0.000    0.000 base.py:67(__post_init__)\n",
      "        2    0.000    0.000    0.000    0.000 arrow_dataset.py:623(<dictcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 evaluation_loop.py:320(_on_evaluation_epoch_start)\n",
      "        1    0.000    0.000    0.000    0.000 OmegaConfGrammarParser.py:285(TextContext)\n",
      "        6    0.000    0.000    0.000    0.000 arrow_dataset.py:652(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 _argument_parser.py:238(IntegerParser)\n",
      "        1    0.000    0.000    0.000    0.000 _convert_np.py:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen _collections_abc>:381(__subclasshook__)\n",
      "        2    0.000    0.000    0.000    0.000 module.py:451(<dictcomp>)\n",
      "        2    0.000    0.000    0.001    0.001 std.py:1379(set_description)\n",
      "        1    0.000    0.000    0.000    0.000 ATNState.py:71(ATNState)\n",
      "        9    0.000    0.000    0.000    0.000 resolver.py:114(ascend_resolver)\n",
      "        2    0.000    0.000    0.000    0.000 table.py:108(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 Token.py:70(CommonToken)\n",
      "        7    0.000    0.000    0.000    0.000 <frozen codecs>:260(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 spawn.py:36(set_executable)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:793(SCMode)\n",
      "        4    0.000    0.000    0.000    0.000 arrow_reader.py:200(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 omegaconf.py:638(is_config)\n",
      "        1    0.000    0.000    0.000    0.000 automatic.py:51(__post_init__)\n",
      "        3    0.000    0.000    0.000    0.000 tensorboard.py:165(sub_dir)\n",
      "       13    0.000    0.000    0.000    0.000 decoder.py:185(_SimpleDecoder)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen posixpath>:117(splitext)\n",
      "        1    0.000    0.000    0.000    0.000 encoder.py:411(_VarintBytes)\n",
      "       12    0.000    0.000    0.000    0.000 {built-in method math.floor}\n",
      "        1    0.000    0.000    0.000    0.000 parsing.py:41(<listcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 arrow_reader.py:214(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 formatters.py:674(_singleton_printers_default)\n",
      "       12    0.000    0.000    0.000    0.000 {method 'reverse' of 'list' objects}\n",
      "        1    0.000    0.000    0.000    0.000 _flag.py:362(EnumFlag)\n",
      "        5    0.000    0.000    0.000    0.000 version.py:478(_parse_local_version)\n",
      "        5    0.000    0.000    0.000    0.000 tqdm_progress.py:121(train_progress_bar)\n",
      "        1    0.000    0.000    0.000    0.000 version.py:49(NegativeInfinityType)\n",
      "        1    0.000    0.000    0.000    0.000 IntervalSet.py:13(IntervalSet)\n",
      "        1    0.000    0.000    0.000    0.000 descriptor.py:246(Descriptor)\n",
      "        1    0.000    0.000    0.000    0.000 gfile.py:899(makedirs)\n",
      "        1    0.000    0.000    0.000    0.000 profiler.py:129(setup)\n",
      "        7    0.000    0.000    0.000    0.000 tensorboard.py:113(name)\n",
      "        1    0.000    0.000    0.000    0.000 tensor_shape.py:980(as_shape)\n",
      "        7    0.000    0.000    0.000    0.000 dtypes.py:123(as_numpy_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:674(format)\n",
      "        4    0.000    0.000    0.000    0.000 {method '__enter__' of '_thread.RLock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 emitter.py:214(expect_document_end)\n",
      "        2    0.000    0.000    0.000    0.000 utils.py:497(<dictcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 CommonTokenStream.py:37(CommonTokenStream)\n",
      "        3    0.000    0.000    0.000    0.000 dataclasses.py:397(<genexpr>)\n",
      "        2    0.000    0.000    0.000    0.000 local.py:396(flush)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:942(format)\n",
      "        1    0.000    0.000    0.000    0.000 unknown_fields.py:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method fromtimestamp}\n",
      "        1    0.000    0.000    0.000    0.000 trainer.py:1206(precision)\n",
      "        3    0.000    0.000    0.000    0.000 std.py:1425(<genexpr>)\n",
      "        3    0.000    0.000    0.000    0.000 _weakrefset.py:17(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 Chunk.py:1(<module>)\n",
      "        7    0.000    0.000    0.000    0.000 result.py:80(group)\n",
      "        1    0.000    0.000    0.000    0.000 _argument_parser.py:466(EnumClassListSerializer)\n",
      "        1    0.000    0.000    0.000    0.000 errors.py:25(OpError)\n",
      "        1    0.000    0.000    0.000    0.000 encoder.py:420(TagBytes)\n",
      "        2    0.000    0.000    0.000    0.000 tensor_shape.py:548(<listcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 widget_float.py:41(_validate_min)\n",
      "        4    0.000    0.000    0.000    0.000 inspect.py:300(ismethod)\n",
      "        2    0.000    0.000    0.000    0.000 table.py:1022(__getstate__)\n",
      "        1    0.000    0.000    0.000    0.000 ATNConfig.py:116(LexerATNConfig)\n",
      "        2    0.000    0.000    0.000    0.000 std.py:97(<listcomp>)\n",
      "        6    0.000    0.000    0.000    0.000 {method 'keys' of 'mappingproxy' objects}\n",
      "       12    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'manual_seed' of 'torch._C.Generator' objects}\n",
      "        1    0.000    0.000    0.000    0.000 OmegaConfGrammarParser.py:1004(InterpolationResolverContext)\n",
      "        2    0.000    0.000    0.000    0.000 _flag.py:167(_get_parsed_value_as_string)\n",
      "        2    0.000    0.000    0.000    0.000 inspect.py:2077(_signature_is_functionlike)\n",
      "       13    0.000    0.000    0.000    0.000 typing.py:1021(<genexpr>)\n",
      "        7    0.000    0.000    0.000    0.000 lazy.py:23(lazy_load)\n",
      "        1    0.000    0.000    0.000    0.000 emitter.py:388(expect_block_mapping)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen _collections_abc>:835(__iter__)\n",
      "        1    0.000    0.000    0.000    0.000 nodes.py:165(StringNode)\n",
      "        1    0.000    0.000    0.000    0.000 _flag.py:335(BooleanFlag)\n",
      "        1    0.000    0.000    0.000    0.000 nodes.py:317(FloatNode)\n",
      "        8    0.000    0.000    0.000    0.000 arrow_dataset.py:168(info)\n",
      "        1    0.000    0.000    0.000    0.000 OmegaConfGrammarParser.py:698(SequenceContext)\n",
      "        7    0.000    0.000    0.000    0.000 omegaconf.py:932(_get_resolver)\n",
      "        1    0.000    0.000    0.000    0.000 OmegaConfGrammarParser.py:639(DictKeyValuePairContext)\n",
      "        1    0.000    0.000    0.000    0.000 OmegaConfGrammarParser.py:232(SingleElementContext)\n",
      "        1    0.000    0.000    0.000    0.000 _argument_parser.py:558(ListParser)\n",
      "        4    0.000    0.000    0.000    0.000 utils.py:60(<genexpr>)\n",
      "        2    0.000    0.000    0.000    0.000 module.py:446(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 optimizer.py:16(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 table.py:1044(_append_replay)\n",
      "        2    0.000    0.000    0.000    0.000 utils.py:204(_is_ascii)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _signal.signal}\n",
      "        1    0.000    0.000    0.002    0.002 combined_loader.py:170(_load_current_iterator)\n",
      "        1    0.000    0.000    0.000    0.000 _output.py:25(Output)\n",
      "        3    0.000    0.000    0.000    0.000 local.py:362(writable)\n",
      "        1    0.000    0.000    0.000    0.000 PredictionContext.py:119(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 pytorch.py:528(<dictcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 nodes.py:203(PathNode)\n",
      "        5    0.000    0.000    0.000    0.000 {built-in method time.monotonic}\n",
      "        1    0.000    0.000    0.000    0.000 lazy.py:64(__getattr__)\n",
      "        4    0.000    0.000    0.000    0.000 encoder.py:505(_StructPackEncoder)\n",
      "        2    0.000    0.000    0.000    0.000 trainer.py:1144(global_rank)\n",
      "        1    0.000    0.000    0.000    0.000 symbol_database.py:67(SymbolDatabase)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'indices' of 'slice' objects}\n",
      "        1    0.000    0.000    0.000    0.000 TokenTagToken.py:15(TokenTagToken)\n",
      "        8    0.000    0.000    0.000    0.000 dtypes.py:128(as_datatype_enum)\n",
      "        4    0.000    0.000    0.000    0.000 module.py:454(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:83(ContainerMetadata)\n",
      "        1    0.000    0.000    0.000    0.000 well_known_types.py:98(Timestamp)\n",
      "        2    0.000    0.000    0.000    0.000 _flagvalues.py:179(register_flag_by_module)\n",
      "        2    0.000    0.000    0.000    0.000 op_evaluator.py:62(__init__)\n",
      "        1    0.000    0.000    0.003    0.003 combined_loader.py:43(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 call.py:99(_call_configure_model)\n",
      "        1    0.000    0.000    0.000    0.000 nodes.py:373(BooleanNode)\n",
      "        1    0.000    0.000    0.000    0.000 _utils.py:701(get_dict_key_value_types)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:119(_is_compiled)\n",
      "        1    0.000    0.000    0.000    0.000 RuleTagToken.py:15(RuleTagToken)\n",
      "        1    0.000    0.000    0.000    0.000 _argument_parser.py:524(BaseListParser)\n",
      "        1    0.000    0.000    0.000    0.000 resource_tracker.py:54(ResourceTracker)\n",
      "        3    0.000    0.000    0.000    0.000 result.py:97(__call__)\n",
      "        1    0.000    0.000    0.000    0.000 _argument_parser.py:591(WhitespaceSeparatedListParser)\n",
      "        1    0.000    0.000    0.000    0.000 gfile.py:98(LocalFileSystem)\n",
      "        1    0.000    0.000    0.011    0.011 api_implementation.py:62(_CanImport)\n",
      "        1    0.000    0.000    0.000    0.000 flags.py:61(_FlagValuesWrapper)\n",
      "        1    0.000    0.000    0.000    0.000 nodes.py:244(IntegerNode)\n",
      "        7    0.000    0.000    0.000    0.000 {built-in method _stat.S_ISDIR}\n",
      "       16    0.000    0.000    0.000    0.000 {built-in method _sre.unicode_iscased}\n",
      "        4    0.000    0.000    0.000    0.000 _parser.py:286(seek)\n",
      "        1    0.000    0.000    0.000    0.000 model_summary.py:217(named_modules)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1276(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 _api.py:35(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 ATNDeserializer.py:516(<lambda>)\n",
      "        1    0.000    0.000    0.000    0.000 PredictionContext.py:160(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 dataclasses.py:565(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 ParserRuleContext.py:38(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 emitter.py:373(expect_first_block_sequence_item)\n",
      "        1    0.000    0.000    0.000    0.000 field_mask.py:36(FieldMask)\n",
      "        1    0.000    0.000    0.000    0.000 enum_type_wrapper.py:41(EnumTypeWrapper)\n",
      "        1    0.000    0.000    0.000    0.000 progress.py:282(reset_on_run)\n",
      "        6    0.000    0.000    0.000    0.000 typing.py:1817(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 dataclasses.py:845(_hash_add)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen codecs>:327(reset)\n",
      "        4    0.000    0.000    0.000    0.000 formatting.py:519(_check_valid_column_key)\n",
      "        1    0.000    0.000    0.000    0.000 functools.py:191(<setcomp>)\n",
      "       10    0.000    0.000    0.000    0.000 formatting.py:226(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 model_summary.py:230(layer_names)\n",
      "        1    0.000    0.000    0.000    0.000 _argument_parser.py:319(EnumParser)\n",
      "        1    0.000    0.000    0.000    0.000 typing.py:2841(<dictcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 __init__.py:89(as_str_any)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'tell' of '_io.BufferedWriter' objects}\n",
      "        2    0.000    0.000    0.000    0.000 DFAState.py:53(__init__)\n",
      "        6    0.000    0.000    0.000    0.000 {method 'remove' of 'collections.deque' objects}\n",
      "        1    0.000    0.000    0.000    0.000 sampler.py:110(__iter__)\n",
      "        1    0.000    0.000    0.000    0.000 events.py:37(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method math.isinf}\n",
      "        9    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\n",
      "        2    0.000    0.000    0.000    0.000 version.py:112(__lt__)\n",
      "        2    0.000    0.000    0.000    0.000 module.py:404(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 ATNConfig.py:23(ATNConfig)\n",
      "        4    0.000    0.000    0.000    0.000 types.py:272(is_date32)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'copy' of 'collections.OrderedDict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 descriptor.py:682(EnumDescriptor)\n",
      "        1    0.000    0.000    0.000    0.000 tqdm_progress.py:137(val_progress_bar)\n",
      "        1    0.000    0.000    0.000    0.000 nodes.py:283(BytesNode)\n",
      "        1    0.000    0.000    0.000    0.000 functional.py:105(get_instance)\n",
      "       10    0.000    0.000    0.000    0.000 gfile.py:451(_translate_errors)\n",
      "        2    0.000    0.000    0.000    0.000 pickle.py:744(save_bool)\n",
      "        1    0.000    0.000    0.000    0.000 encoder.py:375(EncodeVarint)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen os>:806(fsencode)\n",
      "        2    0.000    0.000    0.000    0.000 data_connector.py:392(_check_dataloader_iterable)\n",
      "        2    0.000    0.000    0.000    0.000 dataclasses.py:603(<genexpr>)\n",
      "        3    0.000    0.000    0.000    0.000 events.py:5(__init__)\n",
      "        5    0.000    0.000    0.000    0.000 results.py:434(<lambda>)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen genericpath>:39(isdir)\n",
      "        1    0.000    0.000    0.003    0.003 model_summary.py:264(model_size)\n",
      "        1    0.000    0.000    0.000    0.000 trainer.py:1449(sanity_checking)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _signal.valid_signals}\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:128(is_available)\n",
      "        1    0.000    0.000    0.000    0.000 model_summary.py:277(<listcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 arrow_writer.py:554(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 slurm.py:227(_is_srun_used)\n",
      "        1    0.000    0.000    0.000    0.000 op_evaluator.py:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 Tree.py:82(TerminalNodeImpl)\n",
      "        1    0.000    0.000    0.000    0.000 type_checkers.py:127(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 error_codes.py:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 PredictionContext.py:15(PredictionContext)\n",
      "        1    0.000    0.000    0.000    0.000 OmegaConfGrammarParser.py:805(InterpolationContext)\n",
      "        1    0.000    0.000    0.000    0.000 PredictionContext.py:178(ArrayPredictionContext)\n",
      "        4    0.000    0.000    0.000    0.000 fit_loop.py:116(max_steps)\n",
      "        1    0.000    0.000    0.000    0.000 gfile.py:662(GFile)\n",
      "        1    0.000    0.000    0.000    0.000 resource_tracker.py:56(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 checkpoint_connector.py:122(<listcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 _flagvalues.py:1314(_check_method_name_conflicts)\n",
      "        4    0.000    0.000    0.000    0.000 _parser.py:160(__delitem__)\n",
      "        1    0.000    0.000    0.000    0.000 _exceptions.py:40(DuplicateFlagError)\n",
      "        1    0.000    0.000    0.000    0.000 ATNDeserializationOptions.py:8(ATNDeserializationOptions)\n",
      "        1    0.000    0.000    0.000    0.000 automatic.py:205(_make_step_fn)\n",
      "        1    0.000    0.000    0.000    0.000 serializer.py:36(close)\n",
      "        1    0.000    0.000    0.000    0.000 gfile.py:221(S3FileSystem)\n",
      "        1    0.000    0.000    0.000    0.000 encoder.py:40(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 storage.py:29(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 _flag.py:247(_parse_from_default)\n",
      "        1    0.000    0.000    0.000    0.000 LexerAction.py:48(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 Transition.py:28(Transition)\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method math.log10}\n",
      "        1    0.000    0.000    0.000    0.000 <frozen _collections_abc>:812(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 _utils.py:100(Marker)\n",
      "        1    0.000    0.000    0.000    0.000 result.py:64(should)\n",
      "       11    0.000    0.000    0.000    0.000 traitlets.py:3030(<lambda>)\n",
      "        5    0.000    0.000    0.000    0.000 contextlib.py:757(__exit__)\n",
      "        1    0.000    0.000    0.000    0.000 weakref.py:352(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 utils.py:183(_is_utf)\n",
      "        1    0.000    0.000    0.000    0.000 logger_connector.py:124(_evaluation_epoch_end)\n",
      "        1    0.000    0.000    0.000    0.000 FileStream.py:16(FileStream)\n",
      "        2    0.000    0.000    0.000    0.000 _flagvalues.py:192(register_flag_by_module_id)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'difference_update' of 'set' objects}\n",
      "        1    0.000    0.000    0.000    0.000 error.py:1(<module>)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen abc>:146(update_abstractmethods)\n",
      "        1    0.000    0.000    0.000    0.000 containers.py:614(UnknownFieldRef)\n",
      "        2    0.000    0.000    0.000    0.000 logger.py:23(_convert_params)\n",
      "        1    0.000    0.000    0.000    0.000 typing.py:1201(args)\n",
      "        1    0.000    0.000    0.000    0.000 tensorboard.py:329(<dictcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 _argument_parser.py:291(BooleanParser)\n",
      "        6    0.000    0.000    0.000    0.000 version.py:519(<lambda>)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen os>:773(getenv)\n",
      "        2    0.000    0.000    0.000    0.000 _flag.py:193(_parse)\n",
      "        3    0.000    0.000    0.000    0.000 sampler.py:113(__len__)\n",
      "        1    0.000    0.000    0.000    0.000 _defines.py:326(disclaim_key_flags)\n",
      "        1    0.000    0.000    0.000    0.000 checkpoint_connector.py:63(resume_start)\n",
      "        8    0.000    0.000    0.000    0.000 {method 'random' of '_random.Random' objects}\n",
      "        2    0.000    0.000    0.000    0.000 typing.py:1646(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 PredictionContext.py:86(__init__)\n",
      "        3    0.000    0.000    0.000    0.000 decoder.py:248(_ModifiedDecoder)\n",
      "        2    0.000    0.000    0.000    0.000 training_epoch_loop.py:327(_accumulated_batches_reached)\n",
      "        1    0.000    0.000    0.000    0.000 text_format.py:77(ParseError)\n",
      "        1    0.000    0.000    0.000    0.000 record_writer.py:20(RecordWriter)\n",
      "        1    0.000    0.000    0.000    0.000 LexerAction.py:160(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 enum_type_wrapper.py:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 emitter.py:368(expect_block_sequence)\n",
      "        1    0.000    0.000    0.000    0.000 model_checkpoint.py:281(on_train_start)\n",
      "        9    0.000    0.000    0.000    0.000 __init__.py:96(<lambda>)\n",
      "        2    0.000    0.000    0.000    0.000 __init__.py:922(acquire)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1239(exec_module)\n",
      "        1    0.000    0.000    0.000    0.000 CommonTokenFactory.py:17(CommonTokenFactory)\n",
      "        1    0.000    0.000    0.000    0.000 progress_bar.py:171(setup)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:440(_format)\n",
      "        2    0.000    0.000    0.000    0.000 version.py:130(__ge__)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'tolist' of 'memoryview' objects}\n",
      "        1    0.000    0.000    0.000    0.000 Parser.py:25(TraceListener)\n",
      "        4    0.000    0.000    0.000    0.000 typing.py:494(__repr__)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen _collections_abc>:778(__contains__)\n",
      "        4    0.000    0.000    0.000    0.000 types.py:80(is_int8)\n",
      "        1    0.000    0.000    0.000    0.000 containers.py:647(UnknownFieldSet)\n",
      "        1    0.000    0.000    0.000    0.000 OmegaConfGrammarParser.py:1080(ConfigKeyContext)\n",
      "        4    0.000    0.000    0.000    0.000 types.py:90(is_int32)\n",
      "        4    0.000    0.000    0.000    0.000 spec.py:207(_get_kwargs_from_urls)\n",
      "        1    0.000    0.000    0.000    0.000 well_known_types.py:474(Struct)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method time.perf_counter}\n",
      "        4    0.000    0.000    0.000    0.000 fetchers.py:38(combined_loader)\n",
      "        2    0.000    0.000    0.000    0.000 {method '_release_save' of '_thread.RLock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._get_privateuse1_backend_name}\n",
      "        1    0.000    0.000    0.000    0.000 trainer.py:1158(world_size)\n",
      "        2    0.000    0.000    0.000    0.000 arrow_dataset.py:1826(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 trainer.py:1396(training)\n",
      "        1    0.000    0.000    0.000    0.000 event_file_writer.py:34(get)\n",
      "        1    0.000    0.000    0.000    0.000 Transition.py:120(RangeTransition)\n",
      "        4    0.000    0.000    0.000    0.000 types.py:85(is_int16)\n",
      "        2    0.000    0.000    0.000    0.000 inspect.py:310(ismethoddescriptor)\n",
      "        1    0.000    0.000    0.000    0.000 progress.py:249(reset_on_run)\n",
      "        1    0.000    0.000    0.000    0.000 pytorch.py:127(setup)\n",
      "        4    0.000    0.000    0.000    0.000 types.py:100(is_uint8)\n",
      "        1    0.000    0.000    0.000    0.000 resolver.py:21(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 Errors.py:41(RecognitionException)\n",
      "        1    0.000    0.000    0.000    0.000 dtypes.py:289(__ne__)\n",
      "        1    0.000    0.000    0.000    0.000 events.py:46(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 synchronize.py:90(_make_methods)\n",
      "        2    0.000    0.000    0.000    0.000 __init__.py:929(release)\n",
      "        1    0.000    0.000    0.000    0.000 op_evaluator.py:24(PersistentOpEvaluator)\n",
      "        1    0.000    0.000    0.000    0.000 numeric.py:1855(isscalar)\n",
      "        1    0.000    0.000    0.000    0.000 flags.py:69(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method _stat.S_ISLNK}\n",
      "        1    0.000    0.000    0.000    0.000 weakref.py:347(__new__)\n",
      "        1    0.000    0.000    0.000    0.000 descriptor.py:858(ServiceDescriptor)\n",
      "        2    0.000    0.000    0.000    0.000 inspect.py:505(isbuiltin)\n",
      "        1    0.000    0.000    0.000    0.000 Transition.py:70(AtomTransition)\n",
      "       10    0.000    0.000    0.000    0.000 {method 'isdecimal' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 trainer.py:1495(min_steps)\n",
      "        4    0.000    0.000    0.000    0.000 types.py:110(is_uint32)\n",
      "       13    0.000    0.000    0.000    0.000 {built-in method _sre.unicode_tolower}\n",
      "        1    0.000    0.000    0.000    0.000 RuleContext.py:39(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 ErrorStrategy.py:686(BailErrorStrategy)\n",
      "        1    0.000    0.000    0.000    0.000 SemanticContext.py:97(Predicate)\n",
      "        3    0.000    0.000    0.000    0.000 dtypes.py:87(_is_ref_dtype)\n",
      "        4    0.000    0.000    0.000    0.000 spec.py:65(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 errors.py:114(ConfigTypeError)\n",
      "        2    0.000    0.000    0.000    0.000 trainer.py:1491(max_steps)\n",
      "        1    0.000    0.000    0.000    0.000 dataclasses.py:638(_hash_fn)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen genericpath>:121(_splitext)\n",
      "        4    0.000    0.000    0.000    0.000 strategy.py:357(model)\n",
      "        2    0.000    0.000    0.000    0.000 decoder.py:124(_SignedVarintDecoder)\n",
      "        1    0.000    0.000    0.000    0.000 optimizer.py:34(get_instance)\n",
      "        4    0.000    0.000    0.000    0.000 nodes.py:31(_value)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'ravel' of 'numpy.ndarray' objects}\n",
      "        7    0.000    0.000    0.000    0.000 {method 'locked' of '_thread.lock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 specifiers.py:627(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 compile.py:137(_verify_strategy_supports_compile)\n",
      "        1    0.000    0.000    0.000    0.000 dataclasses.py:327(__set_name__)\n",
      "        3    0.000    0.000    0.000    0.000 callback.py:285(on_before_zero_grad)\n",
      "        1    0.000    0.000    0.000    0.000 queue.py:206(_init)\n",
      "        4    0.000    0.000    0.000    0.000 callback.py:152(on_validation_batch_end)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:164(<lambda>)\n",
      "        4    0.000    0.000    0.000    0.000 types.py:215(is_binary)\n",
      "        4    0.000    0.000    0.000    0.000 types.py:210(is_time64)\n",
      "        2    0.000    0.000    0.000    0.000 result.py:154(forked)\n",
      "        2    0.000    0.000    0.000    0.000 arrow_writer.py:422(<dictcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 ErrorListener.py:13(ErrorListener)\n",
      "        4    0.000    0.000    0.000    0.000 types.py:277(is_date64)\n",
      "        1    0.000    0.000    0.000    0.000 PredictionContext.py:84(PredictionContextCache)\n",
      "        2    0.000    0.000    0.000    0.000 utils.py:43(__format__)\n",
      "        1    0.000    0.000    0.000    0.000 Transition.py:147(PredicateTransition)\n",
      "        4    0.000    0.000    0.000    0.000 types.py:105(is_uint16)\n",
      "        1    0.000    0.000    0.000    0.000 LexerAction.py:61(LexerTypeAction)\n",
      "        1    0.000    0.000    0.000    0.000 SemanticContext.py:125(PrecedencePredicate)\n",
      "        2    0.000    0.000    0.000    0.000 module.py:506(<listcomp>)\n",
      "        4    0.000    0.000    0.000    0.000 types.py:135(is_float64)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:658(formatMessage)\n",
      "        2    0.000    0.000    0.000    0.000 utils.py:213(_screen_shape_wrapper)\n",
      "        1    0.000    0.000    0.000    0.000 SemanticContext.py:156(AND)\n",
      "        1    0.000    0.000    0.000    0.000 encoder.py:370(_VarintEncoder)\n",
      "        1    0.000    0.000    0.000    0.000 field_mask.py:186(_FieldMaskTree)\n",
      "        4    0.000    0.000    0.000    0.000 types.py:130(is_float32)\n",
      "        4    0.000    0.000    0.000    0.000 types.py:125(is_float16)\n",
      "        3    0.000    0.000    0.000    0.000 pathlib.py:94(join_parsed_parts)\n",
      "        3    0.000    0.000    0.000    0.000 typing.py:919(_is_typevar_like)\n",
      "        1    0.000    0.000    0.003    0.003 model_summary.py:254(trainable_parameters)\n",
      "        1    0.000    0.000    0.000    0.000 gfile.py:206(makedirs)\n",
      "        2    0.000    0.000    0.000    0.000 table.py:111(<listcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'is_dir' of 'posix.DirEntry' objects}\n",
      "        6    0.000    0.000    0.000    0.000 version.py:452(_parse_letter_version)\n",
      "        1    0.000    0.000    0.000    0.000 subprocess.py:290(_optim_args_from_interpreter_flags)\n",
      "        1    0.000    0.000    0.000    0.000 _argument_parser.py:456(ListSerializer)\n",
      "        4    0.000    0.000    0.000    0.000 types.py:95(is_int64)\n",
      "        1    0.000    0.000    0.000    0.000 unicode_escape.py:13(Codec)\n",
      "        4    0.000    0.000    0.000    0.000 types.py:205(is_time32)\n",
      "        2    0.000    0.000    0.000    0.000 encoder.py:543(_FloatingPointEncoder)\n",
      "        1    0.000    0.000    0.000    0.000 text_format.py:1293(<listcomp>)\n",
      "        4    0.000    0.000    0.000    0.000 callback.py:142(on_validation_batch_start)\n",
      "        3    0.000    0.000    0.000    0.000 {method 'find' of 'str' objects}\n",
      "        4    0.000    0.000    0.000    0.000 types.py:115(is_uint64)\n",
      "        1    0.000    0.000    0.000    0.000 descriptor.py:118(DescriptorBase)\n",
      "        1    0.000    0.000    0.000    0.000 pywrap_tensorflow.py:168(PyRecordReader_New)\n",
      "        2    0.000    0.000    0.000    0.000 _utils.py:101(__init__)\n",
      "        3    0.000    0.000    0.000    0.000 progress_bar.py:54(trainer)\n",
      "        2    0.000    0.000    0.000    0.000 combined_loader.py:162(<genexpr>)\n",
      "        2    0.000    0.000    0.000    0.000 arrow_writer.py:461(write_rows_on_file)\n",
      "        2    0.000    0.000    0.000    0.000 typing.py:1915(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 descriptor.py:936(MethodDescriptor)\n",
      "        1    0.000    0.000    0.000    0.000 ErrorListener.py:50(ProxyErrorListener)\n",
      "        1    0.000    0.000    0.000    0.000 descriptor.py:1024(FileDescriptor)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:652(usesTime)\n",
      "       10    0.000    0.000    0.000    0.000 {method 'isascii' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._autograd.kineto_available}\n",
      "        1    0.000    0.000    0.000    0.000 Transition.py:203(NotSetTransition)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method _operator.length_hint}\n",
      "        1    0.000    0.000    0.000    0.000 _validators_classes.py:24(Validator)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:61(as_text)\n",
      "        1    0.000    0.000    0.000    0.000 descriptor.py:81(_Lock)\n",
      "        1    0.000    0.000    0.000    0.000 Errors.py:138(FailedPredicateException)\n",
      "        1    0.000    0.000    0.000    0.000 StdinStream.py:7(StdinStream)\n",
      "        1    0.000    0.000    0.000    0.000 Tree.py:32(ParseTreeVisitor)\n",
      "        1    0.000    0.000    0.003    0.003 model_summary.py:260(total_layer_params)\n",
      "        4    0.000    0.000    0.000    0.000 types.py:195(is_duration)\n",
      "        1    0.000    0.000    0.000    0.000 signal_connector.py:158(_is_on_windows)\n",
      "        1    0.000    0.000    0.000    0.000 encoder.py:80(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 signal_connector.py:24(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 model_summary.py:234(layer_types)\n",
      "        1    0.000    0.000    0.000    0.000 _writer.py:29(Writer)\n",
      "        4    0.000    0.000    0.000    0.000 types.py:190(is_timestamp)\n",
      "        1    0.000    0.000    0.000    0.000 LexerAction.py:227(LexerChannelAction)\n",
      "        1    0.000    0.000    0.000    0.000 signal_connector.py:162(_has_already_handler)\n",
      "        1    0.000    0.000    0.000    0.000 listconfig.py:534(ListIterator)\n",
      "        1    0.000    0.000    0.000    0.000 optimizer.py:31(_optimizer_to_device)\n",
      "        4    0.000    0.000    0.000    0.000 types.py:292(is_decimal128)\n",
      "        2    0.000    0.000    0.000    0.000 std.py:166(colour)\n",
      "        1    0.000    0.000    0.000    0.000 Chunk.py:10(TagChunk)\n",
      "        1    0.000    0.000    0.000    0.000 message_factory.py:147(MessageFactory)\n",
      "        1    0.000    0.000    0.000    0.000 descriptor.py:774(EnumValueDescriptor)\n",
      "        1    0.000    0.000    0.000    0.000 descriptor.py:189(_NestedDescriptorBase)\n",
      "        1    0.000    0.000    0.000    0.000 specifiers.py:657(__hash__)\n",
      "        2    0.000    0.000    0.000    0.000 utils.py:572(_get_decoder_start_token_id)\n",
      "        1    0.000    0.000    0.000    0.000 Transition.py:232(PrecedencePredicateTransition)\n",
      "        5    0.000    0.000    0.000    0.000 contextlib.py:754(__enter__)\n",
      "        1    0.000    0.000    0.000    0.000 writer.py:79(get_logdir)\n",
      "        4    0.000    0.000    0.000    0.000 types.py:297(is_decimal256)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1320(__len__)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen os>:760(decode)\n",
      "        3    0.000    0.000    0.000    0.000 callback.py:229(on_exception)\n",
      "        1    0.000    0.000    0.000    0.000 model_summary.py:408(get_formatted_model_size)\n",
      "        1    0.000    0.000    0.000    0.000 LexerAction.py:263(LexerIndexedCustomAction)\n",
      "        1    0.000    0.000    0.000    0.000 SemanticContext.py:242(OR)\n",
      "        1    0.000    0.000    0.000    0.000 Transition.py:90(RuleTransition)\n",
      "        1    0.000    0.000    0.000    0.000 emitter.py:426(check_empty_mapping)\n",
      "        1    0.000    0.000    0.000    0.000 descriptor.py:818(OneofDescriptor)\n",
      "        1    0.000    0.000    0.000    0.000 version.py:76(__lt__)\n",
      "        1    0.000    0.000    0.000    0.000 event_file_writer.py:30(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 app.py:60(_HelpFlag)\n",
      "        1    0.000    0.000    0.000    0.000 optimizer.py:27(initialize)\n",
      "        1    0.000    0.000    0.000    0.000 configuration_validator.py:173(__verify_configure_model_configuration)\n",
      "        1    0.000    0.000    0.000    0.000 ParseTreePatternMatcher.py:81(CannotInvokeStartRule)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen os>:818(fsdecode)\n",
      "        1    0.000    0.000    0.000    0.000 Tree.py:139(ParseTreeWalker)\n",
      "        2    0.000    0.000    0.000    0.000 contextlib.py:434(__exit__)\n",
      "        1    0.000    0.000    0.000    0.000 Transition.py:167(ActionTransition)\n",
      "        1    0.000    0.000    0.000    0.000 fit_loop.py:431(_iteration_based_training)\n",
      "        1    0.000    0.000    0.000    0.000 _utils.py:684(get_list_element_type)\n",
      "        1    0.000    0.000    0.000    0.000 SemanticContext.py:19(SemanticContext)\n",
      "        1    0.000    0.000    0.000    0.000 raw_unicode_escape.py:13(Codec)\n",
      "        2    0.000    0.000    0.000    0.000 _flagvalues.py:1361(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 LexerAction.py:192(LexerCustomAction)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'cast' of 'memoryview' objects}\n",
      "        1    0.000    0.000    0.000    0.000 LexerAction.py:139(LexerMoreAction)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'seekable' of '_io.BufferedWriter' objects}\n",
      "        1    0.000    0.000    0.000    0.000 Transition.py:185(SetTransition)\n",
      "        1    0.000    0.000    0.000    0.000 Errors.py:82(LexerNoViableAltException)\n",
      "        1    0.000    0.000    0.000    0.000 flags.py:72(__getattribute__)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:123(getLevelName)\n",
      "        1    0.000    0.000    0.000    0.000 PredictionContext.py:158(EmptyPredictionContext)\n",
      "        1    0.000    0.000    0.000    0.000 encoder.py:26(_TensorFlowPngEncoder)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'isdigit' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 training_epoch_loop.py:92(batch_idx)\n",
      "        1    0.000    0.000    0.000    0.000 LexerAction.py:24(LexerAction)\n",
      "        1    0.000    0.000    0.000    0.000 Tree.py:66(ParseTreeListener)\n",
      "        1    0.000    0.000    0.000    0.000 logger_connector.py:144(log_eval_end_metrics)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:447(format)\n",
      "        1    0.000    0.000    0.000    0.000 Transition.py:218(WildcardTransition)\n",
      "        1    0.000    0.000    0.000    0.000 _helpers.py:80(_ModuleObjectAndName)\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method math.ceil}\n",
      "        1    0.000    0.000    0.000    0.000 event_file_writer.py:45(EventFileWriter)\n",
      "        1    0.000    0.000    0.000    0.000 containers.py:589(_UnknownField)\n",
      "        1    0.000    0.000    0.000    0.000 tensor_util.py:429(<listcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 module.py:238(example_input_array)\n",
      "        1    0.000    0.000    0.000    0.000 LexerAction.py:43(LexerSkipAction)\n",
      "        1    0.000    0.000    0.000    0.000 LexerAction.py:157(LexerModeAction)\n",
      "        1    0.000    0.000    0.000    0.000 model_summary.py:236(<listcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 _base.py:398(__get_result)\n",
      "        1    0.000    0.000    0.000    0.000 LexerAction.py:143(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 text_format.py:100(TextWriter)\n",
      "        1    0.000    0.000    0.000    0.000 _argument_parser.py:507(EnumClassSerializer)\n",
      "        1    0.000    0.000    0.000    0.000 tqdm_progress.py:287(on_validation_start)\n",
      "        1    0.000    0.000    0.000    0.000 _validators_classes.py:86(SingleFlagValidator)\n",
      "        3    0.000    0.000    0.000    0.000 {method 'clear' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 _argument_parser.py:493(CsvListSerializer)\n",
      "        1    0.000    0.000    0.000    0.000 lazy_tensor_creator.py:27(LazyTensorCreator)\n",
      "        1    0.000    0.000    0.000    0.000 Transition.py:105(EpsilonTransition)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:432(usesTime)\n",
      "        1    0.000    0.000    0.000    0.000 typing.py:1205(kwargs)\n",
      "        1    0.000    0.000    0.000    0.000 core.py:3532(parseImpl)\n",
      "        1    0.000    0.000    0.000    0.000 event_file_writer.py:137(_AsyncWriter)\n",
      "        3    0.000    0.000    0.000    0.000 callback.py:76(on_train_batch_start)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'squeeze' of 'numpy.ndarray' objects}\n",
      "        2    0.000    0.000    0.000    0.000 fromnumeric.py:2508(_cumsum_dispatcher)\n",
      "        2    0.000    0.000    0.000    0.000 __init__.py:815(filter)\n",
      "        1    0.000    0.000    0.000    0.000 errors.py:120(ConfigIndexError)\n",
      "        1    0.000    0.000    0.000    0.000 DFAState.py:13(PredPrediction)\n",
      "        1    0.000    0.000    0.000    0.000 LexerATNSimulator.py:36(SimState)\n",
      "        1    0.000    0.000    0.000    0.000 _output.py:78(DirectoryOutput)\n",
      "        1    0.000    0.000    0.000    0.000 LexerAction.py:123(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 _argument_parser.py:42(_ArgumentParserCache)\n",
      "        2    0.000    0.000    0.000    0.000 dataloader.py:389(multiprocessing_context)\n",
      "        3    0.000    0.000    0.000    0.000 version.py:518(<lambda>)\n",
      "        1    0.000    0.000    0.000    0.000 Errors.py:101(NoViableAltException)\n",
      "        1    0.000    0.000    0.000    0.000 _pytorch_graph.py:121(GraphPy)\n",
      "        2    0.000    0.000    0.000    0.000 _pytree.py:480(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 ParserRuleContext.py:182(InterpreterRuleContext)\n",
      "        1    0.000    0.000    0.000    0.000 decoder.py:1035(_FieldSkipper)\n",
      "        1    0.000    0.000    0.000    0.000 type_checkers.py:104(TypeChecker)\n",
      "        1    0.000    0.000    0.000    0.000 LexerAction.py:88(LexerPushModeAction)\n",
      "        1    0.000    0.000    0.000    0.000 type_checkers.py:176(EnumValueChecker)\n",
      "        1    0.000    0.000    0.000    0.000 Errors.py:16(UnsupportedOperationException)\n",
      "        1    0.000    0.000    0.000    0.000 errors.py:72(InterpolationKeyError)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:37(as_bytes)\n",
      "        1    0.000    0.000    0.000    0.000 emitter.py:422(check_empty_sequence)\n",
      "        1    0.000    0.000    0.000    0.000 decoder.py:332(_DoubleDecoder)\n",
      "        2    0.000    0.000    0.000    0.000 hooks.py:90(on_validation_batch_start)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'union' of 'frozenset' objects}\n",
      "        1    0.000    0.000    0.000    0.000 gfile.py:87(StatData)\n",
      "        1    0.000    0.000    0.000    0.000 errors.py:48(UnsupportedValueType)\n",
      "        3    0.000    0.000    0.000    0.000 encoder.py:182(_FixedSizer)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'is_symlink' of 'posix.DirEntry' objects}\n",
      "        2    0.000    0.000    0.000    0.000 _argument_parser.py:100(parse)\n",
      "        1    0.000    0.000    0.000    0.000 model_summary.py:79(__del__)\n",
      "        2    0.000    0.000    0.000    0.000 callback.py:73(on_sanity_check_end)\n",
      "        4    0.000    0.000    0.000    0.000 flags.py:40(_wrap_define_function)\n",
      "        1    0.000    0.000    0.000    0.000 Chunk.py:23(TextChunk)\n",
      "        1    0.000    0.000    0.000    0.000 model_summary.py:134(layer_type)\n",
      "        3    0.000    0.000    0.000    0.000 callback.py:127(on_validation_epoch_end)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        2    0.000    0.000    0.000    0.000 fetchers.py:46(setup)\n",
      "        1    0.000    0.000    0.000    0.000 _argument_parser.py:136(ArgumentSerializer)\n",
      "        1    0.000    0.000    0.000    0.000 _validators_classes.py:127(MultiFlagsValidator)\n",
      "        1    0.000    0.000    0.000    0.000 event_file_writer.py:215(_AsyncWriterThread)\n",
      "        1    0.000    0.000    0.000    0.000 events.py:55(__init__)\n",
      "        3    0.000    0.000    0.000    0.000 precision.py:72(convert_input)\n",
      "        3    0.000    0.000    0.000    0.000 result.py:101(no_op)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen codecs>:186(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 trainer.py:1153(node_rank)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method from_iterable}\n",
      "        1    0.000    0.000    0.000    0.000 LexerAction.py:119(LexerPopModeAction)\n",
      "        1    0.000    0.000    0.000    0.000 app.py:86(_HelpfullFlag)\n",
      "        1    0.000    0.000    0.000    0.000 dtypes.py:119(is_numpy_compatible)\n",
      "        1    0.000    0.000    0.000    0.000 encoder.py:67(_TensorFlowWavEncoder)\n",
      "        1    0.000    0.000    0.000    0.000 emitter.py:792(write_stream_start)\n",
      "        2    0.000    0.000    0.000    0.000 _argument_parser.py:139(serialize)\n",
      "        1    0.000    0.000    0.000    0.000 version.py:98(InvalidVersion)\n",
      "        1    0.000    0.000    0.000    0.000 decoder.py:287(_FloatDecoder)\n",
      "        3    0.000    0.000    0.000    0.000 hooks.py:643(on_after_batch_transfer)\n",
      "        1    0.000    0.000    0.000    0.000 strategy.py:69(launcher)\n",
      "        1    0.000    0.000    0.000    0.000 checkpoint_connector.py:280(restore_training_state)\n",
      "        1    0.000    0.000    0.000    0.000 ATNDeserializer.py:518(<lambda>)\n",
      "        4    0.000    0.000    0.000    0.000 traitlets.py:1349(ignore)\n",
      "        2    0.000    0.000    0.000    0.000 tokenizer_13a.py:8(signature)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method math.isnan}\n",
      "        2    0.000    0.000    0.000    0.000 strategy.py:449(restore_checkpoint_after_setup)\n",
      "        1    0.000    0.000    0.000    0.000 fit_loop.py:154(_should_reload_train_dl)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1220(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 ATNState.py:207(PlusLoopbackState)\n",
      "        2    0.000    0.000    0.000    0.000 utils.py:380(<dictcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 formatters.py:689(_deferred_printers_default)\n",
      "        2    0.000    0.000    0.000    0.000 _base.py:643(__enter__)\n",
      "        1    0.000    0.000    0.000    0.000 context.py:197(get_start_method)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'pop' of 'set' objects}\n",
      "        1    0.000    0.000    0.000    0.000 ATNConfigSet.py:209(OrderedATNConfigSet)\n",
      "        1    0.000    0.000    0.000    0.000 _pytorch_graph.py:35(NodeBase)\n",
      "        2    0.000    0.000    0.000    0.000 tensor_shape.py:81(value)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'pack' of '_struct.Struct' objects}\n",
      "        2    0.000    0.000    0.000    0.000 progress_bar.py:60(sanity_check_description)\n",
      "        1    0.000    0.000    0.000    0.000 utilities.py:50(_parse_loop_limits)\n",
      "        3    0.000    0.000    0.000    0.000 strategy.py:469(handles_gradient_accumulation)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'flush' of '_io._IOBase' objects}\n",
      "        1    0.000    0.000    0.000    0.000 errors.py:36(KeyValidationError)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:202(_checkLevel)\n",
      "        1    0.000    0.000    0.000    0.000 errors.py:391(UnimplementedError)\n",
      "        2    0.000    0.000    0.000    0.000 tqdm.py:94(are_progress_bars_disabled)\n",
      "        3    0.000    0.000    0.000    0.000 callback.py:274(on_before_backward)\n",
      "        1    0.000    0.000    0.000    0.000 descriptor.py:68(DescriptorMetaclass)\n",
      "        1    0.000    0.000    0.000    0.000 core.py:3515(parseImpl)\n",
      "        2    0.000    0.000    0.000    0.000 core.py:769(parseImpl)\n",
      "        1    0.000    0.000    0.000    0.000 Tree.py:130(ErrorNodeImpl)\n",
      "        2    0.000    0.000    0.000    0.000 hooks.py:362(prepare_data)\n",
      "        1    0.000    0.000    0.000    0.000 checkpoint_connector.py:261(restore_model)\n",
      "        3    0.000    0.000    0.000    0.000 single_device.py:50(reduce)\n",
      "        1    0.000    0.000    0.000    0.000 Errors.py:126(InputMismatchException)\n",
      "        2    0.000    0.000    0.000    0.000 module.py:452(<dictcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 type_checkers.py:282(FloatValueChecker)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:1267(__init__)\n",
      "        3    0.000    0.000    0.000    0.000 single_device.py:81(is_global_zero)\n",
      "        1    0.000    0.000    0.000    0.000 Chunk.py:7(Chunk)\n",
      "        2    0.000    0.000    0.000    0.000 encoder.py:124(_SimpleSizer)\n",
      "        2    0.000    0.000    0.000    0.000 version.py:491(_parse_local_version)\n",
      "        1    0.000    0.000    0.000    0.000 ATNState.py:154(DecisionState)\n",
      "        1    0.000    0.000    0.000    0.000 writer.py:261(_check_caffe2_blob)\n",
      "        1    0.000    0.000    0.000    0.000 encoder.py:387(_SignedVarintEncoder)\n",
      "        1    0.000    0.000    0.000    0.000 errors.py:31(MissingMandatoryValue)\n",
      "        1    0.000    0.000    0.000    0.000 errors.py:78(InterpolationToMissingValueError)\n",
      "        1    0.000    0.000    0.000    0.000 _pytorch_graph.py:65(NodePy)\n",
      "        2    0.000    0.000    0.000    0.000 fromnumeric.py:2974(_prod_dispatcher)\n",
      "        1    0.000    0.000    0.000    0.000 ParseTreePatternMatcher.py:86(StartRuleDoesNotConsumeFullPattern)\n",
      "        1    0.000    0.000    0.000    0.000 errors.py:205(UnknownError)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:225(is_initialized)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'count' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 errors.py:373(OutOfRangeError)\n",
      "        1    0.000    0.000    0.000    0.000 descriptor.py:55(Error)\n",
      "        1    0.000    0.000    0.000    0.000 PredictionContext.py:71(calculateHashCode)\n",
      "        3    0.000    0.000    0.000    0.000 hooks.py:615(on_before_batch_transfer)\n",
      "        2    0.000    0.000    0.000    0.000 _flagvalues.py:149(_flags)\n",
      "        1    0.000    0.000    0.000    0.000 errors.py:54(ReadonlyConfigError)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:368(getMessage)\n",
      "        1    0.000    0.000    0.000    0.000 _exceptions.py:78(UnrecognizedFlagError)\n",
      "        2    0.000    0.000    0.000    0.000 std.py:162(colour)\n",
      "        1    0.000    0.000    0.000    0.000 gfile.py:66(register_filesystem)\n",
      "        1    0.000    0.000    0.000    0.000 errors.py:108(ConfigAttributeError)\n",
      "        1    0.000    0.000    0.000    0.000 emitter.py:797(write_stream_end)\n",
      "        1    0.000    0.000    0.000    0.000 message.py:39(Error)\n",
      "        1    0.000    0.000    0.000    0.000 errors.py:84(InterpolationValidationError)\n",
      "        1    0.000    0.000    0.000    0.000 wire_format.py:80(PackTag)\n",
      "        1    0.000    0.000    0.000    0.000 type_checkers.py:261(DoubleValueChecker)\n",
      "        1    0.000    0.000    0.000    0.000 PredictionContext.py:52(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 Errors.py:21(IllegalStateException)\n",
      "        2    0.000    0.000    0.000    0.000 tensorboard.py:145(save_dir)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'extend' of 'google._upb._message.RepeatedScalarContainer' objects}\n",
      "        1    0.000    0.000    0.000    0.000 type_checkers.py:125(TypeCheckerWithDefault)\n",
      "        1    0.000    0.000    0.000    0.000 errors.py:126(ConfigValueError)\n",
      "        3    0.000    0.000    0.000    0.000 callback.py:124(on_validation_epoch_start)\n",
      "        1    0.000    0.000    0.000    0.000 app.py:79(_HelpshortFlag)\n",
      "        1    0.000    0.000    0.000    0.000 Transition.py:141(AbstractPredicateTransition)\n",
      "        1    0.000    0.000    0.000    0.000 BufferedTokenStream.py:24(TokenStream)\n",
      "        1    0.000    0.000    0.000    0.000 ATNState.py:240(StarLoopEntryState)\n",
      "        1    0.000    0.000    0.000    0.000 cpp_message.py:49(GeneratedProtocolMessageType)\n",
      "        1    0.000    0.000    0.000    0.000 dataclasses.py:846(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 text_format.py:73(Error)\n",
      "        2    0.000    0.000    0.000    0.000 decoder.py:97(_VarintDecoder)\n",
      "        1    0.000    0.000    0.000    0.000 emitter.py:106(dispose)\n",
      "        1    0.000    0.000    0.000    0.000 event_file_writer.py:29(AtomicCounter)\n",
      "        1    0.000    0.000    0.000    0.000 type_checkers.py:110(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 configuration_utils.py:1091(<dictcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 raw_unicode_escape.py:31(StreamReader)\n",
      "        2    0.000    0.000    0.000    0.000 callback.py:92(on_train_epoch_start)\n",
      "        2    0.000    0.000    0.000    0.000 encoder.py:430(_SimpleEncoder)\n",
      "        1    0.000    0.000    0.000    0.000 errors.py:60(InterpolationResolutionError)\n",
      "        1    0.000    0.000    0.000    0.000 errors.py:292(PermissionDeniedError)\n",
      "        1    0.000    0.000    0.000    0.000 ATNState.py:251(LoopEndState)\n",
      "        1    0.000    0.000    0.000    0.000 CommonTokenFactory.py:29(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 ATNState.py:195(RuleStartState)\n",
      "        1    0.000    0.000    0.000    0.000 typing.py:2840(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 ATNState.py:189(RuleStopState)\n",
      "        1    0.000    0.000    0.000    0.000 ATNState.py:147(BasicState)\n",
      "        1    0.000    0.000    0.000    0.000 raw_unicode_escape.py:20(IncrementalEncoder)\n",
      "        1    0.000    0.000    0.000    0.000 errors.py:132(ConfigCycleDetectedException)\n",
      "        1    0.000    0.000    0.000    0.000 type_checkers.py:135(BoolValueChecker)\n",
      "        1    0.000    0.000    0.000    0.000 error.py:18(HParamsError)\n",
      "        1    0.000    0.000    0.000    0.000 errors.py:66(UnsupportedInterpolationType)\n",
      "        1    0.000    0.000    0.000    0.000 type_checkers.py:196(UnicodeValueChecker)\n",
      "        1    0.000    0.000    0.000    0.000 symbol_database.py:73(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 sampler.py:107(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 ATNState.py:227(StarBlockStartState)\n",
      "        3    0.000    0.000    0.000    0.000 enum.py:679(__bool__)\n",
      "        1    0.000    0.000    0.000    0.000 errors.py:501(raise_exception_on_not_ok_status)\n",
      "        1    0.000    0.000    0.000    0.000 descriptor_database.py:42(DescriptorDatabaseConflictingDefinitionError)\n",
      "        1    0.000    0.000    0.000    0.000 ATNState.py:176(BlockEndState)\n",
      "        1    0.000    0.000    0.000    0.000 errors.py:185(CancelledError)\n",
      "        1    0.000    0.000    0.000    0.000 type_checkers.py:153(IntValueChecker)\n",
      "        1    0.000    0.000    0.000    0.000 combined_loader.py:293(iterables)\n",
      "        1    0.000    0.000    0.000    0.000 errors.py:338(FailedPreconditionError)\n",
      "        1    0.000    0.000    0.000    0.000 errors.py:223(InvalidArgumentError)\n",
      "        1    0.000    0.000    0.000    0.000 _exceptions.py:29(Error)\n",
      "        1    0.000    0.000    0.000    0.000 ATNState.py:162(BlockStartState)\n",
      "        1    0.000    0.000    0.000    0.000 ATNState.py:260(TokensStartState)\n",
      "        1    0.000    0.000    0.000    0.000 ErrorListener.py:27(ConsoleErrorListener)\n",
      "        1    0.000    0.000    0.000    0.000 module.py:923(configure_callbacks)\n",
      "        1    0.000    0.000    0.000    0.000 ATNState.py:218(PlusBlockStartState)\n",
      "        1    0.000    0.000    0.000    0.000 typing.py:2922(_namedtuple_mro_entries)\n",
      "        1    0.000    0.000    0.000    0.000 unicode_escape.py:20(IncrementalEncoder)\n",
      "        2    0.000    0.000    0.000    0.000 dataclasses.py:179(__repr__)\n",
      "        1    0.000    0.000    0.000    0.000 ATNState.py:233(StarLoopbackState)\n",
      "        1    0.000    0.000    0.000    0.000 Errors.py:26(CancellationException)\n",
      "        1    0.000    0.000    0.000    0.000 spawn.py:43(get_executable)\n",
      "        1    0.000    0.000    0.000    0.000 errors.py:275(AlreadyExistsError)\n",
      "        1    0.000    0.000    0.000    0.000 tensor_util.py:184(_Message)\n",
      "        1    0.000    0.000    0.000    0.000 errors.py:355(AbortedError)\n",
      "        2    0.000    0.000    0.000    0.000 utils.py:424(_maybe_initialize_input_ids_for_generation)\n",
      "        1    0.000    0.000    0.000    0.000 typing.py:1150(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 descriptor.py:59(TypeTransformationError)\n",
      "        2    0.000    0.000    0.000    0.000 _flagvalues.py:152(flags_by_module_dict)\n",
      "        1    0.000    0.000    0.000    0.000 errors.py:257(NotFoundError)\n",
      "        1    0.000    0.000    0.000    0.000 CommonTokenFactory.py:13(TokenFactory)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'expandtabs' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 hooks.py:54(on_validation_end)\n",
      "        2    0.000    0.000    0.000    0.000 helpers.py:403(<lambda>)\n",
      "        1    0.000    0.000    0.000    0.000 errors.py:138(GrammarParseError)\n",
      "        2    0.000    0.000    0.000    0.000 callback.py:70(on_sanity_check_start)\n",
      "        1    0.000    0.000    0.000    0.000 errors.py:409(InternalError)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch.is_anomaly_check_nan_enabled}\n",
      "        2    0.000    0.000    0.000    0.000 dataclasses.py:842(_hash_set_none)\n",
      "        2    0.000    0.000    0.000    0.000 formatters.py:830(_check_return)\n",
      "        1    0.000    0.000    0.000    0.000 message.py:44(DecodeError)\n",
      "        1    0.000    0.000    0.000    0.000 typing.py:1126(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 errors.py:309(UnauthenticatedError)\n",
      "        1    0.000    0.000    0.000    0.000 Tree.py:14(Tree)\n",
      "        1    0.000    0.000    0.000    0.000 errors.py:424(UnavailableError)\n",
      "        1    0.000    0.000    0.000    0.000 process.py:37(current_process)\n",
      "        1    0.000    0.000    0.000    0.000 errors.py:323(ResourceExhaustedError)\n",
      "        1    0.000    0.000    0.000    0.000 _pytorch_graph.py:90(NodePyIO)\n",
      "        1    0.000    0.000    0.000    0.000 errors.py:243(DeadlineExceededError)\n",
      "        2    0.000    0.000    0.000    0.000 _flag.py:136(value)\n",
      "        1    0.000    0.000    0.000    0.000 local.py:359(readable)\n",
      "        1    0.000    0.000    0.000    0.000 ATNState.py:169(BasicBlockStartState)\n",
      "        1    0.000    0.000    0.000    0.000 descriptor_database.py:38(Error)\n",
      "        1    0.000    0.000    0.000    0.000 errors.py:438(DataLossError)\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method builtins.globals}\n",
      "        2    0.000    0.000    0.000    0.000 callback.py:64(on_fit_start)\n",
      "        1    0.000    0.000    0.000    0.000 strategy.py:567(on_validation_end)\n",
      "        1    0.000    0.000    0.000    0.000 hooks.py:242(on_validation_epoch_end)\n",
      "        1    0.000    0.000    0.000    0.000 raw_unicode_escape.py:24(IncrementalDecoder)\n",
      "        1    0.000    0.000    0.000    0.000 _exceptions.py:33(CantOpenFlagFileError)\n",
      "        2    0.000    0.000    0.000    0.000 {method '_is_owned' of '_thread.RLock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 unicode_escape.py:31(StreamReader)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'isdisjoint' of 'set' objects}\n",
      "        1    0.000    0.000    0.000    0.000 encoder.py:471(_ModifiedEncoder)\n",
      "        1    0.000    0.000    0.000    0.000 anomaly_mode.py:115(__enter__)\n",
      "        2    0.000    0.000    0.000    0.000 typing.py:2864(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:795(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 <string>:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 _pytorch_graph.py:110(NodePyOP)\n",
      "        1    0.000    0.000    0.000    0.000 unicode_escape.py:24(IncrementalDecoder)\n",
      "        1    0.000    0.000    0.000    0.000 type_checkers.py:249(Uint64ValueChecker)\n",
      "        2    0.000    0.000    0.000    0.000 jsonutil.py:52(encode_images)\n",
      "        1    0.000    0.000    0.000    0.000 strategy.py:547(on_train_start)\n",
      "        1    0.000    0.000    0.000    0.000 functional.py:102(initialize)\n",
      "        2    0.000    0.000    0.000    0.000 strategy.py:440(process_dataloader)\n",
      "        1    0.000    0.000    0.000    0.000 Tree.py:17(SyntaxTree)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _imp.exec_dynamic}\n",
      "        1    0.000    0.000    0.000    0.000 process.py:189(name)\n",
      "        1    0.000    0.000    0.000    0.000 logger.py:152(_add_prefix)\n",
      "        2    0.000    0.000    0.000    0.000 callback.py:211(on_validation_start)\n",
      "        2    0.000    0.000    0.000    0.000 _flagvalues.py:161(flags_by_module_id_dict)\n",
      "        1    0.000    0.000    0.000    0.000 type_checkers.py:232(Int32ValueChecker)\n",
      "        1    0.000    0.000    0.000    0.000 type_checkers.py:244(Int64ValueChecker)\n",
      "        1    0.000    0.000    0.000    0.000 raw_unicode_escape.py:28(StreamWriter)\n",
      "        1    0.000    0.000    0.000    0.000 callback.py:214(on_validation_end)\n",
      "        1    0.000    0.000    0.000    0.000 trainer.py:1487(min_epochs)\n",
      "        1    0.000    0.000    0.000    0.000 Lexer.py:25(TokenSource)\n",
      "        1    0.000    0.000    0.000    0.000 Errors.py:161(ParseCancellationException)\n",
      "        1    0.000    0.000    0.000    0.000 record_writer.py:23(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 optimizer.py:364(_validate_optimizers_attached)\n",
      "        1    0.000    0.000    0.000    0.000 optimizer.py:33(do_nothing_closure)\n",
      "        1    0.000    0.000    0.000    0.000 _exceptions.py:74(IllegalFlagValueError)\n",
      "        1    0.000    0.000    0.000    0.000 message.py:49(EncodeError)\n",
      "        1    0.000    0.000    0.000    0.000 strategy.py:579(on_train_batch_start)\n",
      "        2    0.000    0.000    0.000    0.000 single_device.py:90(broadcast)\n",
      "        1    0.000    0.000    0.000    0.000 Tree.py:20(ParseTree)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'join' of 'bytes' objects}\n",
      "        1    0.000    0.000    0.000    0.000 unicode_escape.py:28(StreamWriter)\n",
      "        1    0.000    0.000    0.000    0.000 progress_bar.py:64(train_description)\n",
      "        1    0.000    0.000    0.000    0.000 checkpoint_connector.py:311(restore_callbacks)\n",
      "        1    0.000    0.000    0.000    0.000 encoder.py:153(_ModifiedSizer)\n",
      "        1    0.000    0.000    0.000    0.000 precision.py:48(convert_module)\n",
      "        1    0.000    0.000    0.000    0.000 hooks.py:69(on_train_batch_start)\n",
      "        1    0.000    0.000    0.000    0.000 event_file_writer.py:102(get_logdir)\n",
      "        1    0.000    0.000    0.000    0.000 <string>:1(__create_fn__)\n",
      "        1    0.000    0.000    0.000    0.000 checkpoint_connector.py:249(restore_datamodule)\n",
      "        1    0.000    0.000    0.000    0.000 trainer.py:1483(max_epochs)\n",
      "        1    0.000    0.000    0.000    0.000 Tree.py:26(TerminalNode)\n",
      "        1    0.000    0.000    0.000    0.000 type_checkers.py:239(Uint32ValueChecker)\n",
      "        1    0.000    0.000    0.000    0.000 _exceptions.py:99(UnparsedFlagAccessError)\n",
      "        1    0.000    0.000    0.000    0.000 Tree.py:29(ErrorNode)\n",
      "        1    0.000    0.000    0.000    0.000 hooks.py:45(on_train_start)\n",
      "        1    0.000    0.000    0.000    0.000 strategy.py:551(on_validation_start)\n",
      "        1    0.000    0.000    0.000    0.000 Tree.py:23(RuleNode)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen codecs>:276(reset)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:1590(main_thread)\n",
      "        1    0.000    0.000    0.000    0.000 optimizer.py:328(_validate_scheduler_api)\n",
      "        1    0.000    0.000    0.000    0.000 hooks.py:209(on_train_epoch_start)\n",
      "        1    0.000    0.000    0.000    0.000 hooks.py:31(on_fit_start)\n",
      "        1    0.000    0.000    0.000    0.000 precision.py:39(connect)\n",
      "        1    0.000    0.000    0.000    0.000 callback.py:205(on_train_start)\n",
      "        1    0.000    0.000    0.000    0.000 _exceptions.py:107(FlagNameConflictsWithMethodError)\n",
      "        1    0.000    0.000    0.000    0.000 {method '__exit__' of 'posix.ScandirIterator' objects}\n",
      "        1    0.000    0.000    0.000    0.000 _exceptions.py:103(ValidationError)\n",
      "        1    0.000    0.000    0.000    0.000 callback.py:58(setup)\n",
      "        1    0.000    0.000    0.000    0.000 hooks.py:51(on_validation_start)\n",
      "        1    0.000    0.000    0.000    0.000 hooks.py:239(on_validation_epoch_start)\n",
      "        1    0.000    0.000    0.000    0.000 hooks.py:418(setup)\n",
      "        1    0.000    0.000    0.000    0.000 accelerator.py:29(setup)\n",
      "        1    0.000    0.000    0.000    0.000 pywrap_tensorflow.py:31(__getattr__)\n",
      "        1    0.000    0.000    0.000    0.000 strategy.py:253(_setup_model)\n",
      "        1    0.000    0.000    0.000    0.000 typing.py:2876(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 pywrap_tensorflow.py:35(TF_bfloat16_type)\n",
      "        1    0.000    0.000    0.000    0.000 enum.py:1180(_missing_)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1363(exec_module)"
     ]
    }
   ],
   "source": [
    "%%prun\n",
    "# Now we can train the model\n",
    "trainer.fit(model_pl, datamodule=data)\n",
    "# trainer.predict(model_pl, datamodule=data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
