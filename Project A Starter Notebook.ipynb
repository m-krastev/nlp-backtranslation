{"cells":[{"cell_type":"markdown","metadata":{"id":"ykGl7T2zUzT9"},"source":["## Setup\n","\n","Provided:\n","\n","- Pre-trained de-en models (100k, 500k, 1M) + SPM dict/model\n","- Pre-trained en-de models (100k, 500k, 1M) + SPM dict/model\n","- Pre-processed en:de train, dev, test data (100k, 500k, 1M)\n","- Raw+preprocessed mono en and mono de train data (50k)\n","- Raw+preprocessed parallel en:de FT train data (25k)\n","- Pre-processed en:de dev + test data (2k, 2k)\n","- Basic pre-processing script\n","\n","\n","You can train your own models and data, and are not obliged to use ours.\n"]},{"cell_type":"markdown","metadata":{"id":"bNPQfuJtToFW"},"source":["Make sure you use GPU env.\n","Go to `Runtime->Change runtime type` to change the runtime resources."]},{"cell_type":"markdown","metadata":{"id":"U3IC8PhHan2_"},"source":["First mount your google drive."]},{"cell_type":"markdown","metadata":{},"source":["Note to self: hyp (means hypothesis), i.e. the hypothetical translation; ref (means reference), i.e. the correct translation; src (means source), i.e. the original sentence."]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["env: l1=de\n","env: l2=en\n","env: SRC=de\n","env: TGT=en\n"]}],"source":["# Define the necessary variables that can be subbed in any templates because %env magic, when using $, __will substitute a PYTHON variable__ instead of a bash environment variable\n","SRC=\"de\"\n","TGT=\"en\"\n","%env SRC=$SRC\n","%env TGT=$TGT"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19821,"status":"ok","timestamp":1711973189892,"user":{"displayName":"Seth","userId":"14055004792161004132"},"user_tz":-120},"id":"jHu5w9CvM9jv","outputId":"9e317fcf-33bd-4064-cb5e-be0ca2f09dea"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","import os, sys\n","drive.mount('/content/drive/')"]},{"cell_type":"markdown","metadata":{"id":"yfyPoyYma3gS"},"source":["Install `torch` and `fairseq`. You can store binaries in your google drive, so you don't need to install it every time, do this however you like"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"KIm0gMEZQhke"},"outputs":[],"source":["# NOTE: HIGHLY Recommended to use Python@3.9  \n","# %python3 -m venv .venv --system-site-packages\n","# !source .venv/bin/activate\n","\n","# %env CWD=/content/drive/MyDrive/project-files\n","CWD=\".\"\n","#make sure to use older torch version. fairseq doesn't work well with torch2\n","# %pip install fairseq sacremoses subword_nmt\n","# %pip install --upgrade torch==1.12.1+cu113 torchvision==0.13.1+cu113 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu113\n","\n","# !git clone https://github.com/VarunGumma/fairseq\n","# !cd fairseq\n","# !pip install -e ./"]},{"cell_type":"markdown","metadata":{"id":"qOLcYuayF5l1"},"source":["## Training & Fine-tuning\n","\n","Training example - here we use the command line, but you can also use hydra config files if you prefer\n","\n"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"Jr-M_On7Q2WN"},"outputs":[{"name":"stdout","output_type":"stream","text":["env: path_2_data=Data/train-euro-news-big.de-en/bin\n"]}],"source":["# Path to binary data\n","# %env path_2_data=./Data/train-euro-news-big.$SRC-$TGT/bin\n","%env path_2_data=Data/train-euro-news-big.$SRC-$TGT/bin\n","# check you can train a model from scratch, --max-update=10 means it will stop training immediately\n","# !fairseq-train \\\n","#     \"$path_2_data\" \\\n","#     --arch transformer_wmt_en_de \\\n","#     --task translation \\\n","#     --share-decoder-input-output-embed \\\n","#     --optimizer adam \\\n","#     --adam-betas '(0.9, 0.98)' \\\n","#     --clip-norm 0.1 \\\n","#     --lr 0.0006 \\\n","#     --lr-scheduler inverse_sqrt \\\n","#     --warmup-updates 2500 \\\n","#     --warmup-init-lr 1e-07 \\\n","#     --stop-min-lr 1e-09 \\\n","#     --dropout 0.3 \\\n","#     --weight-decay 0.0001 \\\n","#     --criterion label_smoothed_cross_entropy \\\n","#     --label-smoothing 0.1 \\\n","#     --max-tokens 8192 \\\n","#     --max-update 2 \\\n","#     --update-freq 8 \\\n","#     --patience 10 \\\n","#     --scoring sacrebleu \\\n","#     --eval-bleu \\\n","#     --eval-bleu-args '{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}' \\\n","#     --eval-bleu-detok moses \\\n","#     --eval-bleu-remove-bpe \\\n","#     --eval-bleu-print-samples \\\n","#     --best-checkpoint-metric bleu \\\n","#     --maximize-best-checkpoint-metric \\\n","#     --save-interval-updates 2000 \\\n","#     --validate-interval-updates 2000 \\\n","#     --no-epoch-checkpoints \\\n","#     --keep-best-checkpoints 1 \\\n","#     --encoder-learned-pos \\\n","#     --save-dir Models/test-de-en \\\n","#     --bpe sentencepiece"]},{"cell_type":"markdown","metadata":{"id":"vW6MEOGVGPP0"},"source":["Fine-tuning: This is the same as training, but you load a trained model with `--finetune-from-model checkpoint_best.pt`. Also consider modifying the the learning rate warmup and batch size.\n"]},{"cell_type":"markdown","metadata":{"id":"JBc9sB34J3DS"},"source":["## Preprocessing\n","\n","Example preprocessing + subword training script\n","You may want to store the intermediate files in a tmp directory to avoid multiple copies. If using the provided models, use the SPM model + dictionary for any further preprocessing"]},{"cell_type":"code","execution_count":53,"metadata":{"id":"P-s521LbTZ6G"},"outputs":[{"name":"stdout","output_type":"stream","text":["env: src_train=./Data/it-mono/train.mono.de\n","env: tgt_train=./Data/it-mono/train.mono.en\n","env: databin=./Data/it-mono/bin/\n","env: train_file=./Data/it-mono/train.mono\n","env: dev_file=./Data/it-mono/dev\n","env: test_file=./Data/it-mono/test\n","env: spm=./Models/spm.model\n","Preprocessing data for de-en\n","Sentencepiece model: ./Models/spm.model\n","Source training data: ./Data/it-mono/train.mono.de\n","Target training data: ./Data/it-mono/train.mono.en\n","Train file: ./Data/it-mono/train.mono\n","Dev file: ./Data/it-mono/dev\n","Test file: ./Data/it-mono/test\n"]},{"name":"stdout","output_type":"stream","text":["100%|████████████████████████████████| 100000/100000 [00:03<00:00, 25646.34it/s]\n","100%|████████████████████████████████| 100000/100000 [00:03<00:00, 26946.38it/s]\n","100%|████████████████████████████████| 100000/100000 [00:03<00:00, 28946.77it/s]\n","100%|████████████████████████████████| 100000/100000 [00:04<00:00, 23013.41it/s]\n","100%|█████████████████████████████████████| 2000/2000 [00:00<00:00, 2169.53it/s]\n","100%|████████████████████████████████████| 2000/2000 [00:00<00:00, 33129.05it/s]\n","100%|█████████████████████████████████████| 2000/2000 [00:00<00:00, 2209.80it/s]\n","100%|████████████████████████████████████| 2000/2000 [00:00<00:00, 30850.00it/s]\n","100%|█████████████████████████████████████| 2000/2000 [00:00<00:00, 2040.00it/s]\n","100%|████████████████████████████████████| 2000/2000 [00:00<00:00, 31621.00it/s]\n","100%|█████████████████████████████████████| 2000/2000 [00:00<00:00, 2042.95it/s]\n","100%|████████████████████████████████████| 2000/2000 [00:00<00:00, 31205.65it/s]\n","processed 10000 lines\n","processed 20000 lines\n","processed 30000 lines\n","processed 40000 lines\n","processed 50000 lines\n","processed 60000 lines\n","processed 70000 lines\n","processed 80000 lines\n","processed 90000 lines\n","processed 100000 lines\n","skipped 0 empty lines\n","filtered 0 lines\n","skipped 0 empty lines\n","filtered 0 lines\n","skipped 0 empty lines\n","filtered 0 lines\n","2024-04-16 20:10:36 | INFO | fairseq_cli.preprocess | Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', scoring='bleu', task='translation', source_lang='de', target_lang='en', trainpref='./Data/it-mono/train.mono.tok.spm', validpref='./Data/it-mono/dev.tok.spm', testpref='./Data/it-mono/test.tok.spm', align_suffix=None, destdir='./Data/it-mono/bin/', thresholdtgt=0, thresholdsrc=0, tgtdict='./Data/it-mono/dict.en.txt', srcdict='./Data/it-mono/dict.de.txt', nwordstgt=-1, nwordssrc=-1, alignfile=None, dataset_impl='mmap', joined_dictionary=False, only_source=False, padding_factor=8, workers=20, dict_only=False)\n","2024-04-16 20:10:36 | INFO | fairseq_cli.preprocess | [de] Dictionary: 32016 types\n","2024-04-16 20:10:47 | INFO | fairseq_cli.preprocess | [de] ./Data/it-mono/train.mono.tok.spm.de: 100000 sents, 2110185 tokens, 0.182% replaced (by <unk>)\n","2024-04-16 20:10:47 | INFO | fairseq_cli.preprocess | [de] Dictionary: 32016 types\n","2024-04-16 20:10:53 | INFO | fairseq_cli.preprocess | [de] ./Data/it-mono/dev.tok.spm.de: 2000 sents, 43767 tokens, 0.165% replaced (by <unk>)\n","2024-04-16 20:10:53 | INFO | fairseq_cli.preprocess | [de] Dictionary: 32016 types\n","2024-04-16 20:10:59 | INFO | fairseq_cli.preprocess | [de] ./Data/it-mono/test.tok.spm.de: 2000 sents, 41598 tokens, 0.231% replaced (by <unk>)\n","2024-04-16 20:10:59 | INFO | fairseq_cli.preprocess | [en] Dictionary: 32016 types\n","2024-04-16 20:11:09 | INFO | fairseq_cli.preprocess | [en] ./Data/it-mono/train.mono.tok.spm.en: 100000 sents, 1873945 tokens, 0.0113% replaced (by <unk>)\n","2024-04-16 20:11:09 | INFO | fairseq_cli.preprocess | [en] Dictionary: 32016 types\n","2024-04-16 20:11:15 | INFO | fairseq_cli.preprocess | [en] ./Data/it-mono/dev.tok.spm.en: 2000 sents, 38263 tokens, 0.00261% replaced (by <unk>)\n","2024-04-16 20:11:15 | INFO | fairseq_cli.preprocess | [en] Dictionary: 32016 types\n","2024-04-16 20:11:21 | INFO | fairseq_cli.preprocess | [en] ./Data/it-mono/test.tok.spm.en: 2000 sents, 36224 tokens, 0.00276% replaced (by <unk>)\n","2024-04-16 20:11:21 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to ./Data/it-mono/bin/\n"]}],"source":["# Preprocess monolingual data\n","%env src_train=./Data/it-mono/train.mono.$SRC\n","%env tgt_train=./Data/it-mono/train.mono.$TGT\n","\n","%env databin=./Data/it-mono/bin/\n","%env train_file=./Data/it-mono/train.mono\n","%env dev_file=./Data/it-mono/dev\n","%env test_file=./Data/it-mono/test\n","\n","# apply SPM\n","%env spm=./Models/spm.model\n","\n","!bash scripts/preprocess.sh\n","!bash scripts/binarize.sh --only-source"]},{"cell_type":"code","execution_count":54,"metadata":{"id":"xVvPoZYiVEG0"},"outputs":[{"name":"stdout","output_type":"stream","text":["env: src_train=./Data/it-parallel/train.ft.de\n","env: tgt_train=./Data/it-parallel/train.ft.en\n","env: databin=./Data/it-parallel/bin/\n","env: train_file=./Data/it-parallel/train.parallel\n","env: dev_file=./Data/it-parallel/dev\n","env: test_file=./Data/it-parallel/test\n","env: spm=./Models/spm.model\n","Preprocessing data for de-en\n","Sentencepiece model: ./Models/spm.model\n","Source training data: ./Data/it-parallel/train.ft.de\n","Target training data: ./Data/it-parallel/train.ft.en\n","Train file: ./Data/it-parallel/train.parallel\n","Dev file: ./Data/it-parallel/dev\n","Test file: ./Data/it-parallel/test\n"]},{"name":"stdout","output_type":"stream","text":["100%|██████████████████████████████████| 20000/20000 [00:01<00:00, 14630.34it/s]\n","100%|██████████████████████████████████| 20000/20000 [00:00<00:00, 39292.03it/s]\n","100%|██████████████████████████████████| 20000/20000 [00:01<00:00, 15582.79it/s]\n","100%|██████████████████████████████████| 20000/20000 [00:00<00:00, 31766.86it/s]\n","100%|█████████████████████████████████████| 2000/2000 [00:00<00:00, 2017.79it/s]\n","100%|████████████████████████████████████| 2000/2000 [00:00<00:00, 30292.97it/s]\n","100%|█████████████████████████████████████| 2000/2000 [00:00<00:00, 2051.97it/s]\n","100%|████████████████████████████████████| 2000/2000 [00:00<00:00, 31881.54it/s]\n","100%|█████████████████████████████████████| 2000/2000 [00:01<00:00, 1990.74it/s]\n","100%|████████████████████████████████████| 2000/2000 [00:00<00:00, 31292.14it/s]\n","100%|█████████████████████████████████████| 2000/2000 [00:00<00:00, 2046.00it/s]\n","100%|████████████████████████████████████| 2000/2000 [00:00<00:00, 27626.18it/s]\n","processed 10000 lines\n","processed 20000 lines\n","skipped 0 empty lines\n","filtered 0 lines\n","skipped 0 empty lines\n","filtered 0 lines\n","skipped 0 empty lines\n","filtered 0 lines\n","2024-04-16 20:12:21 | INFO | fairseq_cli.preprocess | Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', scoring='bleu', task='translation', source_lang='de', target_lang='en', trainpref='./Data/it-parallel/train.parallel.tok.spm', validpref='./Data/it-parallel/dev.tok.spm', testpref='./Data/it-parallel/test.tok.spm', align_suffix=None, destdir='./Data/it-parallel/bin/', thresholdtgt=0, thresholdsrc=0, tgtdict='./Data/it-mono/dict.en.txt', srcdict='./Data/it-mono/dict.de.txt', nwordstgt=-1, nwordssrc=-1, alignfile=None, dataset_impl='mmap', joined_dictionary=False, only_source=False, padding_factor=8, workers=20, dict_only=False)\n","2024-04-16 20:12:22 | INFO | fairseq_cli.preprocess | [de] Dictionary: 32016 types\n","2024-04-16 20:12:30 | INFO | fairseq_cli.preprocess | [de] ./Data/it-parallel/train.parallel.tok.spm.de: 20000 sents, 429230 tokens, 0.167% replaced (by <unk>)\n","2024-04-16 20:12:30 | INFO | fairseq_cli.preprocess | [de] Dictionary: 32016 types\n","2024-04-16 20:12:36 | INFO | fairseq_cli.preprocess | [de] ./Data/it-parallel/dev.tok.spm.de: 2000 sents, 43767 tokens, 0.165% replaced (by <unk>)\n","2024-04-16 20:12:36 | INFO | fairseq_cli.preprocess | [de] Dictionary: 32016 types\n","2024-04-16 20:12:44 | INFO | fairseq_cli.preprocess | [de] ./Data/it-parallel/test.tok.spm.de: 2000 sents, 41598 tokens, 0.231% replaced (by <unk>)\n","2024-04-16 20:12:44 | INFO | fairseq_cli.preprocess | [en] Dictionary: 32016 types\n","2024-04-16 20:12:52 | INFO | fairseq_cli.preprocess | [en] ./Data/it-parallel/train.parallel.tok.spm.en: 20000 sents, 373732 tokens, 0.011% replaced (by <unk>)\n","2024-04-16 20:12:52 | INFO | fairseq_cli.preprocess | [en] Dictionary: 32016 types\n","2024-04-16 20:12:59 | INFO | fairseq_cli.preprocess | [en] ./Data/it-parallel/dev.tok.spm.en: 2000 sents, 38263 tokens, 0.00261% replaced (by <unk>)\n","2024-04-16 20:12:59 | INFO | fairseq_cli.preprocess | [en] Dictionary: 32016 types\n","2024-04-16 20:13:06 | INFO | fairseq_cli.preprocess | [en] ./Data/it-parallel/test.tok.spm.en: 2000 sents, 36224 tokens, 0.00276% replaced (by <unk>)\n","2024-04-16 20:13:06 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to ./Data/it-parallel/bin/\n"]}],"source":["# repeat preprocessing for parallel FT data\n","%env src_train=./Data/it-parallel/train.ft.$SRC\n","%env tgt_train=./Data/it-parallel/train.ft.$TGT\n","%env databin=./Data/it-parallel/bin/\n","\n","%env train_file=./Data/it-parallel/train.parallel\n","%env dev_file=./Data/it-parallel/dev\n","%env test_file=./Data/it-parallel/test\n","\n","# apply SPM\n","%env spm=./Models/spm.model\n","\n","!bash scripts/preprocess.sh\n","!bash scripts/binarize.sh\n","# etc"]},{"cell_type":"markdown","metadata":{"id":"_AtnUVYNtW96"},"source":["If you want to train models from scratch and experiment with different subword segmentation settings, you can train BPE using `subword-nmt learn-joint-bpe-and-vocab` then `subword-nmt apply-bpe`, or train a SentencePiece model with the provided `spm_train.py` file below are examples of training BPE or SPM vocabularies."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jq6v8rX0f1xC"},"outputs":[],"source":["# TODO: Pray I don't need to do this.\n","\n","# # preprocessing - example for BPE training\n","# %env src_train=/content/drive/MyDrive/data-bin/it/train.mono.en\n","# %env tgt_train=/content/drive/MyDrive/data-bin/it/train.mono.de\n","# %env databin=/content/drive/MyDrive/data-bin/it/\n","\n","# %env bpe_train_file=$train_file.bpe\n","\n","# %env train_file=/content/drive/MyDrive/data-bin/it/train.mono.tok\n","# %env codes_file=/content/drive/MyDrive/data-bin/it/train.mono.codes\n","# %env vocab_file=/content/drive/MyDrive/data-bin/it/train.mono.vocab\n","\n","# %env dev_file=/content/drive/MyDrive/data-bin/it/dev.tok\n","# %env test_file=/content/drive/MyDrive/data-bin/it/test.tok\n","\n","# ######## train SPM example #########\n","# !python ./spm_train.py --input=\"$train_file.$SRC,$train_file.$TGT\" \\\n","#     --vocab_size=32000 \\\n","#     --character_coverage=1.0 \\\n","#     --num_threads=8 \\\n","#     --split_digits \\\n","#     --model_prefix=\"$train_file.spm\" \\\n","#     --model_type=unigram \\\n","#     --bos_id=0 --pad_id=1 --eos_id=2 --unk_id=3\n"]},{"cell_type":"markdown","metadata":{"id":"dif-DV4qLbeE"},"source":["## Generation & Evaluation\n","\n","Generation standardly involves running inference using a trained model on a given test set. This test set must be segmented and binarised using the same vocabulary as the model (important if you want to test on other test sets or in different languages).\n","\n","For evaluation, we show below how to get BLEU scores (a standard, if uninformative, MT metric)."]},{"cell_type":"code","execution_count":55,"metadata":{"id":"lm6h5gjjLdmj"},"outputs":[{"name":"stdout","output_type":"stream","text":["env: TEST=it-mono\n","env: MODEL=big-de-en\n","env: OUTPUT_DIR=./tests\n","Generating translations for de-en on it-mono\n","Model: big-de-en\n","Output directory: ./tests\n"]},{"name":"stdout","output_type":"stream","text":["2024-04-16 20:13:57 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': './Models/big-de-en/checkpoint_best.pt', 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': None, 'batch_size': 128, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 128, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False}, 'task': {'_name': 'translation', 'data': 'Data/it-mono/bin', 'source_lang': 'de', 'target_lang': 'en', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n","2024-04-16 20:13:57 | INFO | fairseq.tasks.translation | [de] dictionary: 32016 types\n","2024-04-16 20:13:57 | INFO | fairseq.tasks.translation | [en] dictionary: 32016 types\n","2024-04-16 20:13:57 | INFO | fairseq_cli.generate | loading model(s) from ./Models/big-de-en/checkpoint_best.pt\n","2024-04-16 20:13:59 | INFO | fairseq.data.data_utils | loaded 2,000 examples from: Data/it-mono/bin/test.de-en.de\n","2024-04-16 20:13:59 | INFO | fairseq.data.data_utils | loaded 2,000 examples from: Data/it-mono/bin/test.de-en.en\n","2024-04-16 20:13:59 | INFO | fairseq.tasks.translation | Data/it-mono/bin test de-en 2000 examples\n","2024-04-16 20:23:45 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n","2024-04-16 20:23:45 | INFO | fairseq_cli.generate | Translated 2,000 sentences (37,806 tokens) in 577.3s (3.46 sentences/s, 65.49 tokens/s)\n","/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n","  warnings.warn('resource_tracker: There appear to be %d '\n"]}],"source":["# set experiment variables\n","# careful: test set must match model - because of different spm dictionaries\n","# %env TEST=news-euro-half\n","%env TEST=it-mono\n","%env MODEL=big-$SRC-$TGT\n","%env OUTPUT_DIR=./tests\n","\n","!bash scripts/generate.sh\n","!bash scripts/evaluate.sh\n","\n","# other metrics: comet, beer, your own ensemble, etc.\n","# TODO: I'd like to add COMET at some point."]},{"cell_type":"markdown","metadata":{"id":"DTPNH_DNLuQ6"},"source":["## Project Code\n","\n","When generating for backtranslation, you'll first want to evaluate the quality on a parallel test set (as above). Then backtranslate the monolingual training set using `--gen-subset train`, extract the source and hypotheses, apply some data filtering/selection methods, and preprocess into a training dataset for forward translation.\n","\n","We recommend splitting these up into different steps, but present it here together for clarity.\n","\n","You can choose your desired hyperparameters, including decoding strategy, data ratios, BT model, etc.\n","\n","Always save and label your outputs clearly! `backtranslate1-en-de-test21.eval` is not going to be very helpful when you're performing your analyses later on. But `iwslt300k.selection=len.dec=greedy.ft=20k.test=it` will be more useful."]},{"cell_type":"code","execution_count":62,"metadata":{"id":"eDN80bHJO-kO"},"outputs":[{"name":"stdout","output_type":"stream","text":["env: DATA=it-mono\n","Generating translations for de-en on it-mono\n","Model: big-de-en\n","Output directory: Data//generation-big-de-en\n"]},{"name":"stdout","output_type":"stream","text":["2024-04-16 21:14:26 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': './Models/big-de-en/checkpoint_best.pt', 'post_process': 'sentencepiece', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': None, 'batch_size': 128, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 128, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'train', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False}, 'task': {'_name': 'translation', 'data': 'Data/it-mono/bin', 'source_lang': 'de', 'target_lang': 'en', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n","2024-04-16 21:14:26 | INFO | fairseq.tasks.translation | [de] dictionary: 32016 types\n","2024-04-16 21:14:26 | INFO | fairseq.tasks.translation | [en] dictionary: 32016 types\n","2024-04-16 21:14:26 | INFO | fairseq_cli.generate | loading model(s) from ./Models/big-de-en/checkpoint_best.pt\n","2024-04-16 21:14:28 | INFO | fairseq.data.data_utils | loaded 100,000 examples from: Data/it-mono/bin/train.de-en.de\n","2024-04-16 21:14:28 | INFO | fairseq.data.data_utils | loaded 100,000 examples from: Data/it-mono/bin/train.de-en.en\n","2024-04-16 21:14:28 | INFO | fairseq.tasks.translation | Data/it-mono/bin train de-en 100000 examples\n","2024-04-16 21:14:28 | WARNING | fairseq.tasks.fairseq_task | 11 samples have invalid sizes and will be skipped, max_positions=(1024, 1024), first few sample ids=[11807, 88920, 11403, 45979, 90161, 46709, 25808, 26674, 79574, 91193]\n","2024-04-17 04:30:46 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n","2024-04-17 04:30:46 | INFO | fairseq_cli.generate | Translated 99,989 sentences (1,903,107 tokens) in 25930.7s (3.86 sentences/s, 73.39 tokens/s)\n","/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n","  warnings.warn('resource_tracker: There appear to be %d '\n"]}],"source":["# evaluate reverse model on test set(s)\n","\n","# data selection before backtranslation\n","# ....\n","\n","# preprocessing - apply trained spm.model to selected train.mono subset\n","\n","\n","# then binarise with fixed dictionaries\n","\n","# backtranslation generation with reverse model + extract source + hypotheses\n","%env DATA=it-mono\n","!source scripts/generate_train.sh Data/\n","\n","# MK: We don't do that vvv\n","# data selection after backtranslation\n","\n","\n","# combine fine-tuning data (or some subset) with bt data, preprocess with fixed dictionaries\n","\n","# train forward translation model\n","\n","# evaluate\n"]},{"cell_type":"code","execution_count":66,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["env: src_train=./Data/generation-big-de-en/it-mono-de-en.src\n","env: tgt_train=./Data/generation-big-de-en/it-mono-de-en.hyp\n"]},{"name":"stderr","output_type":"stream","text":["Python(28779) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n","Python(28783) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"]},{"name":"stdout","output_type":"stream","text":["env: train_file=./Data/generation-big-de-en/train\n","env: dev_file=./Data/generation-big-de-en/dev\n","env: test_file=./Data/generation-big-de-en/test\n","Preprocessing data for de-en\n","Sentencepiece model: ./Models/spm.model\n","Source training data: ./Data/generation-big-de-en/it-mono-de-en.src\n","Target training data: ./Data/generation-big-de-en/it-mono-de-en.hyp\n","Train file: ./Data/generation-big-de-en/train\n","Dev file: ./Data/generation-big-de-en/dev\n","Test file: ./Data/generation-big-de-en/test\n"]},{"name":"stderr","output_type":"stream","text":["Python(28787) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"]},{"name":"stdout","output_type":"stream","text":["100%|██████████████████████████████████| 99989/99989 [00:02<00:00, 40386.87it/s]\n","100%|██████████████████████████████████| 99989/99989 [00:02<00:00, 44359.89it/s]\n","100%|██████████████████████████████████| 99989/99989 [00:02<00:00, 40291.63it/s]\n","100%|██████████████████████████████████| 99989/99989 [00:02<00:00, 42493.58it/s]\n","100%|█████████████████████████████████████| 2000/2000 [00:00<00:00, 3064.12it/s]\n","100%|████████████████████████████████████| 2000/2000 [00:00<00:00, 45411.08it/s]\n","100%|█████████████████████████████████████| 2000/2000 [00:00<00:00, 3078.55it/s]\n","100%|████████████████████████████████████| 2000/2000 [00:00<00:00, 42488.16it/s]\n","100%|█████████████████████████████████████| 2000/2000 [00:00<00:00, 2943.79it/s]\n","100%|████████████████████████████████████| 2000/2000 [00:00<00:00, 40846.52it/s]\n","100%|█████████████████████████████████████| 2000/2000 [00:00<00:00, 3091.45it/s]\n","100%|████████████████████████████████████| 2000/2000 [00:00<00:00, 43989.66it/s]\n","processed 10000 lines\n","processed 20000 lines\n","processed 30000 lines\n","processed 40000 lines\n","processed 50000 lines\n","processed 60000 lines\n","processed 70000 lines\n","processed 80000 lines\n","processed 90000 lines\n","skipped 0 empty lines\n","filtered 0 lines\n","skipped 0 empty lines\n","filtered 0 lines\n","skipped 0 empty lines\n","filtered 0 lines\n"]},{"name":"stderr","output_type":"stream","text":["Python(28862) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"]},{"name":"stdout","output_type":"stream","text":["2024-04-17 10:47:06 | INFO | fairseq_cli.preprocess | Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', scoring='bleu', task='translation', source_lang='de', target_lang='en', trainpref='./Data/generation-big-de-en/train.tok.spm', validpref='./Data/generation-big-de-en/dev.tok.spm', testpref='./Data/generation-big-de-en/test.tok.spm', align_suffix=None, destdir='./Data/generation-big-de-en/bin', thresholdtgt=0, thresholdsrc=0, tgtdict='./Data/it-mono/dict.en.txt', srcdict='./Data/it-mono/dict.de.txt', nwordstgt=-1, nwordssrc=-1, alignfile=None, dataset_impl='mmap', joined_dictionary=False, only_source=False, padding_factor=8, workers=20, dict_only=False)\n","2024-04-17 10:47:07 | INFO | fairseq_cli.preprocess | [de] Dictionary: 32016 types\n","2024-04-17 10:47:15 | INFO | fairseq_cli.preprocess | [de] ./Data/generation-big-de-en/train.tok.spm.de: 99989 sents, 2132132 tokens, 0.0% replaced (by <unk>)\n","2024-04-17 10:47:15 | INFO | fairseq_cli.preprocess | [de] Dictionary: 32016 types\n","2024-04-17 10:47:21 | INFO | fairseq_cli.preprocess | [de] ./Data/generation-big-de-en/dev.tok.spm.de: 2000 sents, 43767 tokens, 0.165% replaced (by <unk>)\n","2024-04-17 10:47:21 | INFO | fairseq_cli.preprocess | [de] Dictionary: 32016 types\n","2024-04-17 10:47:26 | INFO | fairseq_cli.preprocess | [de] ./Data/generation-big-de-en/test.tok.spm.de: 2000 sents, 41598 tokens, 0.231% replaced (by <unk>)\n","2024-04-17 10:47:26 | INFO | fairseq_cli.preprocess | [en] Dictionary: 32016 types\n","2024-04-17 10:47:35 | INFO | fairseq_cli.preprocess | [en] ./Data/generation-big-de-en/train.tok.spm.en: 99989 sents, 1930599 tokens, 0.0% replaced (by <unk>)\n","2024-04-17 10:47:35 | INFO | fairseq_cli.preprocess | [en] Dictionary: 32016 types\n","2024-04-17 10:47:40 | INFO | fairseq_cli.preprocess | [en] ./Data/generation-big-de-en/dev.tok.spm.en: 2000 sents, 38263 tokens, 0.00261% replaced (by <unk>)\n","2024-04-17 10:47:40 | INFO | fairseq_cli.preprocess | [en] Dictionary: 32016 types\n","2024-04-17 10:47:45 | INFO | fairseq_cli.preprocess | [en] ./Data/generation-big-de-en/test.tok.spm.en: 2000 sents, 36224 tokens, 0.00276% replaced (by <unk>)\n","2024-04-17 10:47:45 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to ./Data/generation-big-de-en/bin\n","env: model_save_folder=\"./Models/it-mono-de-en\"\n"]},{"name":"stderr","output_type":"stream","text":["Python(29041) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"]},{"name":"stdout","output_type":"stream","text":["2024-04-17 10:47:49 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 0, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 8192, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 2000, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 8192, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 2, 'stop_time_hours': 0.0, 'clip_norm': 0.1, 'sentence_avg': False, 'update_freq': [8], 'lr': [0.0006], 'stop_min_lr': 1e-09, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '\"./Models/it-mono-de-en\"', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': 1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': 10, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='label_smoothed_cross_entropy', tokenizer=None, bpe='sentencepiece', optimizer='adam', lr_scheduler='inverse_sqrt', scoring='sacrebleu', task='translation', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=8192, batch_size=None, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=2000, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=8192, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='transformer_wmt_en_de', max_epoch=0, max_update=2, stop_time_hours=0, clip_norm=0.1, sentence_avg=False, update_freq=[8], lr=[0.0006], stop_min_lr=1e-09, use_bmuf=False, skip_remainder_batch=False, save_dir='\"./Models/it-mono-de-en\"', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=2000, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='bleu', maximize_best_checkpoint_metric=True, patience=10, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='./Data/generation-big-de-en/bin', source_lang=None, target_lang=None, load_alignments=False, left_pad_source=True, left_pad_target=False, upsample_primary=-1, truncate_source=False, num_batch_buckets=0, eval_bleu=True, eval_bleu_args='{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_tokenized_bleu=False, eval_bleu_remove_bpe='@@ ', eval_bleu_print_samples=True, label_smoothing=0.1, report_accuracy=False, ignore_prefix_size=0, sentencepiece_model='???', sentencepiece_enable_sampling=False, sentencepiece_alpha=None, adam_betas='(0.9, 0.98)', adam_eps=1e-08, weight_decay=0.0001, use_old_adam=False, fp16_adam_stats=False, warmup_updates=2500, warmup_init_lr=1e-07, sacrebleu_tokenizer='13a', sacrebleu_lowercase=False, sacrebleu_char_level=False, share_decoder_input_output_embed=True, dropout=0.3, encoder_learned_pos=True, no_seed_provided=False, encoder_embed_path=None, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_attention_heads=8, encoder_normalize_before=False, decoder_embed_path=None, decoder_embed_dim=512, decoder_ffn_embed_dim=2048, decoder_layers=6, decoder_attention_heads=8, decoder_normalize_before=False, decoder_learned_pos=False, attention_dropout=0.0, activation_dropout=0.0, activation_fn='relu', adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, share_all_embeddings=False, no_token_positional_embeddings=False, adaptive_input=False, no_cross_attention=False, cross_self_attention=False, decoder_output_dim=512, decoder_input_dim=512, no_scale_embedding=False, layernorm_embedding=False, tie_adaptive_weights=False, checkpoint_activations=False, offload_activations=False, encoder_layers_to_keep=None, decoder_layers_to_keep=None, encoder_layerdrop=0, decoder_layerdrop=0, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, _name='transformer_wmt_en_de'), 'task': {'_name': 'translation', 'data': './Data/generation-big-de-en/bin', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0006]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 2500, 'warmup_init_lr': 1e-07, 'lr': [0.0006]}, 'scoring': {'_name': 'sacrebleu', 'sacrebleu_tokenizer': 13a, 'sacrebleu_lowercase': False, 'sacrebleu_char_level': False}, 'bpe': {'_name': 'sentencepiece', 'sentencepiece_model': '???', 'sentencepiece_enable_sampling': False, 'sentencepiece_alpha': None}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n","2024-04-17 10:47:49 | INFO | fairseq.tasks.translation | [de] dictionary: 32016 types\n","2024-04-17 10:47:49 | INFO | fairseq.tasks.translation | [en] dictionary: 32016 types\n","2024-04-17 10:47:50 | INFO | fairseq_cli.train | TransformerModel(\n","  (encoder): TransformerEncoderBase(\n","    (dropout_module): FairseqDropout()\n","    (embed_tokens): Embedding(32016, 512, padding_idx=1)\n","    (embed_positions): LearnedPositionalEmbedding(1026, 512, padding_idx=1)\n","    (layers): ModuleList(\n","      (0): TransformerEncoderLayerBase(\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (dropout_module): FairseqDropout()\n","        (activation_dropout_module): FairseqDropout()\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (1): TransformerEncoderLayerBase(\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (dropout_module): FairseqDropout()\n","        (activation_dropout_module): FairseqDropout()\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (2): TransformerEncoderLayerBase(\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (dropout_module): FairseqDropout()\n","        (activation_dropout_module): FairseqDropout()\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (3): TransformerEncoderLayerBase(\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (dropout_module): FairseqDropout()\n","        (activation_dropout_module): FairseqDropout()\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (4): TransformerEncoderLayerBase(\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (dropout_module): FairseqDropout()\n","        (activation_dropout_module): FairseqDropout()\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (5): TransformerEncoderLayerBase(\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (dropout_module): FairseqDropout()\n","        (activation_dropout_module): FairseqDropout()\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","    )\n","  )\n","  (decoder): TransformerDecoderBase(\n","    (dropout_module): FairseqDropout()\n","    (embed_tokens): Embedding(32016, 512, padding_idx=1)\n","    (embed_positions): SinusoidalPositionalEmbedding()\n","    (layers): ModuleList(\n","      (0): TransformerDecoderLayerBase(\n","        (dropout_module): FairseqDropout()\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (activation_dropout_module): FairseqDropout()\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (1): TransformerDecoderLayerBase(\n","        (dropout_module): FairseqDropout()\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (activation_dropout_module): FairseqDropout()\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (2): TransformerDecoderLayerBase(\n","        (dropout_module): FairseqDropout()\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (activation_dropout_module): FairseqDropout()\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (3): TransformerDecoderLayerBase(\n","        (dropout_module): FairseqDropout()\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (activation_dropout_module): FairseqDropout()\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (4): TransformerDecoderLayerBase(\n","        (dropout_module): FairseqDropout()\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (activation_dropout_module): FairseqDropout()\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (5): TransformerDecoderLayerBase(\n","        (dropout_module): FairseqDropout()\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (activation_dropout_module): FairseqDropout()\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","    )\n","    (output_projection): Linear(in_features=512, out_features=32016, bias=False)\n","  )\n",")\n","2024-04-17 10:47:50 | INFO | fairseq_cli.train | task: TranslationTask\n","2024-04-17 10:47:50 | INFO | fairseq_cli.train | model: TransformerModel\n","2024-04-17 10:47:50 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion\n","2024-04-17 10:47:50 | INFO | fairseq_cli.train | num. shared model params: 96,350,208 (num. trained: 96,350,208)\n","2024-04-17 10:47:50 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n","2024-04-17 10:47:50 | INFO | fairseq.data.data_utils | loaded 2,000 examples from: ./Data/generation-big-de-en/bin/valid.de-en.de\n","2024-04-17 10:47:50 | INFO | fairseq.data.data_utils | loaded 2,000 examples from: ./Data/generation-big-de-en/bin/valid.de-en.en\n","2024-04-17 10:47:50 | INFO | fairseq.tasks.translation | ./Data/generation-big-de-en/bin valid de-en 2000 examples\n","2024-04-17 10:47:50 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n","2024-04-17 10:47:50 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n","2024-04-17 10:47:50 | INFO | fairseq_cli.train | max tokens per device = 8192 and max sentences per device = None\n","2024-04-17 10:47:50 | INFO | fairseq.trainer | Preparing to load checkpoint \"./Models/it-mono-de-en\"/checkpoint_last.pt\n","2024-04-17 10:47:50 | INFO | fairseq.trainer | No existing checkpoint found \"./Models/it-mono-de-en\"/checkpoint_last.pt\n","2024-04-17 10:47:50 | INFO | fairseq.trainer | loading train data for epoch 1\n","2024-04-17 10:47:50 | INFO | fairseq.data.data_utils | loaded 99,989 examples from: ./Data/generation-big-de-en/bin/train.de-en.de\n","2024-04-17 10:47:50 | INFO | fairseq.data.data_utils | loaded 99,989 examples from: ./Data/generation-big-de-en/bin/train.de-en.en\n","2024-04-17 10:47:50 | INFO | fairseq.tasks.translation | ./Data/generation-big-de-en/bin train de-en 99989 examples\n","2024-04-17 10:47:50 | WARNING | fairseq.tasks.fairseq_task | 1 samples have invalid sizes and will be skipped, max_positions=(1024, 1024), first few sample ids=[60972]\n","2024-04-17 10:47:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 44\n","epoch 001:   0%|                                         | 0/44 [00:00<?, ?it/s]2024-04-17 10:47:50 | INFO | fairseq.trainer | begin training epoch 1\n","2024-04-17 10:47:50 | INFO | fairseq_cli.train | Start iterating over samples\n","/Users/Matey/project/nlp2/.venv/lib/python3.9/site-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n","  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n","^C\n"]}],"source":["# src is the original data\n","%env src_train=./Data/generation-big-de-en/it-mono-de-en.src\n","# tgt is the backtranslated data\n","%env tgt_train=./Data/generation-big-de-en/it-mono-de-en.hyp\n","\n","!cp ./Data/it-mono/test* ./Data/generation-big-de-en/\n","!cp ./Data/it-mono/dev* ./Data/generation-big-de-en/\n","\n","%env train_file=./Data/generation-big-de-en/train\n","%env dev_file=./Data/generation-big-de-en/dev\n","%env test_file=./Data/generation-big-de-en/test\n","!bash scripts/preprocess.sh\n","!bash scripts/binarize.sh --only-source\n","\n","%env model_save_folder=\"./Models/it-mono-de-en\"\n","!fairseq-train \\\n","    \"./Data/generation-big-de-en/bin\" \\\n","    --finetune_from_checkpoint \"./Models/big-${SRC}-${TGT}/checkpoint_best.pt\" \\\n","    --arch transformer_wmt_en_de \\\n","    --task translation \\\n","    --share-decoder-input-output-embed \\\n","    --optimizer adam \\\n","    --adam-betas '(0.9, 0.98)' \\\n","    --clip-norm 0.1 \\\n","    --lr 0.0003 \\\n","    --lr-scheduler inverse_sqrt \\\n","    --warmup-updates 2500 \\\n","    --warmup-init-lr 1e-07 \\\n","    --stop-min-lr 1e-09 \\\n","    --dropout 0.3 \\\n","    --weight-decay 0.0001 \\\n","    --criterion label_smoothed_cross_entropy \\\n","    --label-smoothing 0.1 \\\n","    --max-tokens 8192 \\\n","    --max-update 2 \\\n","    --update-freq 8 \\\n","    --patience 10 \\\n","    --scoring sacrebleu \\\n","    --eval-bleu \\\n","    --eval-bleu-args '{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}' \\\n","    --eval-bleu-detok moses \\\n","    --eval-bleu-remove-bpe \\\n","    --eval-bleu-print-samples \\\n","    --best-checkpoint-metric bleu \\\n","    --maximize-best-checkpoint-metric \\\n","    --save-interval-updates 2000 \\\n","    --validate-interval-updates 2000 \\\n","    --no-epoch-checkpoints \\\n","    --keep-best-checkpoints 1 \\\n","    --encoder-learned-pos \\\n","    --save-dir $model_save_folder \\\n","    --bpe sentencepiece\n"]},{"cell_type":"markdown","metadata":{"id":"PUzBgs7UPnLu"},"source":["If you prefer to write a bash script in colab, e.g. to combine repetitive preprocessing steps, here's an example of how you can do that:\n"]},{"cell_type":"markdown","metadata":{"id":"7ZTwSZYZbVu2"},"source":["### Advanced\n","If you're going to modify fairseq, there are two ways of doing this: either install fairseq + clone the extension repo, or clone fairseq and install as editable.\n","For 1, clone the repo you are going to work with. You need to fork the project repo https://github.com/afeena/fairseq_easy_extend.git. This has files for RL learning and non-autoregressive Transformers (which you're welcome to try out but isn't relevant to the current project). However if you're looking to implement (dynamic) curriculum learning, we recommend creating a new task (remember to declare and init the task). This is a fairly involved modification.\n","For 2, uncomment the code below."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nmzh1htqenRO"},"outputs":[],"source":["# ! git clone https://github.com/facebookresearch/fairseq\n","# ! cd fairseq && pip install -e .\n","# import os\n","# os.chdir('/content')\n","# os.environ['PYTHONPATH'] += \":/content/fairseq/\"\n","# ! echo $PYTHONPATH\n","\n","import os\n","!git clone https://github.com/afeena/fairseq_easy_extend.git #here change to your own repo\n","os.chdir(\"fairseq_easy_extend\")"]},{"cell_type":"markdown","metadata":{"id":"VwVS7FFCbi0o"},"source":["The example config is for baseline cmlm training, add `checkpoint.restore_file=<path to checkpoint>` and `checkpoint.reset_optimizer=True` for finetuning. You need to change hyperparameters for fine-tuning!\n","Also, set `checkpoint.save_dir=<path>`"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"qi5zKkI4aDn2"},"outputs":[{"name":"stdout","output_type":"stream","text":["mkdir: /content/drive/MyDrive: No such file or directory\n"]},{"name":"stderr","output_type":"stream","text":["2024-04-13 12:35:56 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n"]},{"name":"stdout","output_type":"stream","text":["/Users/Matey/project/nlp2/.venv/bin/python: can't open file '/Users/Matey/project/nlp2/train.py': [Errno 2] No such file or directory\n","ls: /content/drive/MyDrive/data-bin/test-de-en: No such file or directory\n"]}],"source":["!path_2_data=/content/drive/MyDrive/data-bin/iwslt14.tokenized.de-en\n","!exp=test-de-en\n","!mkdir \"/content/drive/MyDrive/data-bin/$exp\"\n","import fairseq\n","!python train.py --config-dir \"/content/fairseq_easy_extend/fairseq_easy_extend/models/nat/\" --config-name \"cmlm_config.yaml\" \\\n","task.data=/content/drive/MyDrive/data-bin/test-de-en\n","!ls /content/drive/MyDrive/data-bin/test-de-en"]},{"cell_type":"markdown","metadata":{"id":"77ESrB1VbzIE"},"source":["Training of the model. You can change parameters in your config file or override directly"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FfLWVYsEOupn"},"outputs":[],"source":["!python train.py --config-dir \"/content/fairseq_easy_extend/fairseq_easy_extend/models/nat/\" --config-name \"cmlm_config.yaml\" \\\n","task.data=/content/drive/MyDrive/NLP2-2023-ET/iwslt14.tokenized.de-en"]},{"cell_type":"markdown","metadata":{"id":"NRhAVoWXNYDs"},"source":["Fine-tuning example"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t1UCXgv-NXi4"},"outputs":[],"source":["!python train.py --config-dir \"/content/fairseq_easy_extend/fairseq_easy_extend/models/nat/\" --config-name \"cmlm_config.yaml\" \\\n","task.data=/content/drive/MyDrive/NLP2-2023-ET/iwslt14.tokenized.de-en \\\n","checkpoint.restore_file=/content/drive/MyDrive/NLP2-2023-ET/checkpoint_best.pt \\\n","checkpoint.reset_optimizer=True"]}],"metadata":{"colab":{"collapsed_sections":["7ZTwSZYZbVu2"],"provenance":[{"file_id":"1t7LCd5hv7EYU4DXvYMYX6NK26KX2SGp4","timestamp":1710492311762},{"file_id":"1cS_1rURJ1Yeslh7UsgzDOZEnLOIJ8jib","timestamp":1710430420322},{"file_id":"1kK9onr-XLWpIRyl-6SGHEu0nPAd8HWBZ","timestamp":1709893248787},{"file_id":"1fOYshWDKTKdpCHvH1MNndupxJ4AqalsD","timestamp":1681300516269}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":0}
